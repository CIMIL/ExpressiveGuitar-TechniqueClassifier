{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cAJRnwSBQNbQ"
      },
      "source": [
        "# Test model generator\n",
        "Code that generate tensorflow-lite models to test the C++ inference code.  \n",
        "Models are saved to the `test-tflite-models` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.4.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "print(\"Tensorflow version: \" + tf.version.VERSION)\n",
        "\n",
        "HOMEBASE = './'\n",
        "OUTPUT_FOLDER = os.path.join(HOMEBASE,'test_models')\n",
        "if not os.path.exists(OUTPUT_FOLDER) and os.path.isdir(OUTPUT_FOLDER):\n",
        "    os.mkdir(OUTPUT_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class CustomNetwork():\n",
        "#     def __init__(self, number_of_conv:int, filters_per_conv:list, kernel_sizes_per_conv:list, \n",
        "#                  pool_layers:list, pool_sizes_per_conv:list, \n",
        "#                  number_of_dense:int, dense_units:list, dropout_rates:list, activations:list, \n",
        "#                  batchnorm_after_layer:list,\n",
        "#                  input_shape:list, output_shape:int):\n",
        "#         self.number_of_conv = number_of_conv\n",
        "#         self.filters_per_conv = filters_per_conv\n",
        "#         assert len(self.filters_per_conv) == self.number_of_conv\n",
        "#         self.kernel_sizes_per_conv = kernel_sizes_per_conv\n",
        "#         assert len(self.kernel_sizes_per_conv) == self.number_of_conv\n",
        "#         self.pool_sizes_per_conv = pool_sizes_per_conv\n",
        "#         assert len(self.pool_sizes_per_conv) == self.number_of_conv\n",
        "#         self.pool_layers = pool_layers\n",
        "#         assert len(self.pool_layers) == self.number_of_conv\n",
        "\n",
        "#         self.number_of_dense = number_of_dense\n",
        "#         self.dense_units = dense_units\n",
        "#         assert len(self.dense_units) == self.number_of_dense\n",
        "#         self.dropout_rates = dropout_rates\n",
        "#         assert len(self.dropout_rates) == self.number_of_dense\n",
        "#         self.activations = activations\n",
        "#         assert len(self.activations) == self.number_of_dense\n",
        "\n",
        "#         self.batchnorm_after_layer = batchnorm_after_layer\n",
        "#         assert len(self.batchnorm_after_layer) == self.number_of_dense + self.number_of_conv\n",
        "\n",
        "#         self.input_shape = input_shape\n",
        "#         self.output_shape = output_shape\n",
        "\n",
        "#     def _get_conv_unit(filters:int, kernel_size:int, activation:str, pool_size:int, pool_layer:bool, batchnorm:bool, input_shape:tuple = None):\n",
        "    \n",
        "#         if input_shape is not None:\n",
        "#             res = [tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, input_shape=input_shape)]\n",
        "#         else:\n",
        "#             res = [tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation=activation)]\n",
        "\n",
        "#         res += [tf.keras.layers.BatchNormalization(),  \n",
        "#                 tf.keras.layers.MaxPooling1D(pool_size=2)]\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1Be14IPJTg_4"
      },
      "outputs": [],
      "source": [
        "def define_model_architecture(num_classes:int, input_shape:tuple, conv:int, num_of_dense:int = 0, dense_node_count:int= 0, model_name:str= \"test_model\",force_in_shape=False, _verbose = False):\n",
        "    # tf.keras.backend.set_floatx('float32')\n",
        "\n",
        "    sequential_structure = []\n",
        "    if len(input_shape) == 2:\n",
        "        convLayer = tf.keras.layers.Conv2D\n",
        "        maxpoolLayer = tf.keras.layers.MaxPooling2D\n",
        "        avgpoolLayer = tf.keras.layers.AveragePooling2D\n",
        "        if force_in_shape:\n",
        "            input_shape = (input_shape[0], input_shape[1], 1)\n",
        "    elif len(input_shape) == 1:\n",
        "        convLayer = tf.keras.layers.Conv1D\n",
        "        maxpoolLayer = tf.keras.layers.MaxPooling1D\n",
        "        avgpoolLayer = tf.keras.layers.AveragePooling1D\n",
        "        if force_in_shape:\n",
        "            input_shape = (input_shape[0], 1)\n",
        "    else:\n",
        "        raise ValueError('Input shape must be either 1 or 2 dimensional. Got: %s'%str(input_shape))\n",
        "\n",
        "    if conv > 0:\n",
        "        for i in range(conv):\n",
        "            if i == 0 and force_in_shape:\n",
        "                sequential_structure.append(convLayer(filters=2, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "                print('Adding input shape: %s'%str(input_shape))\n",
        "            else:\n",
        "                sequential_structure.append(convLayer(filters=2, kernel_size=3, activation='relu'))\n",
        "\n",
        "            sequential_structure += [tf.keras.layers.BatchNormalization()]\n",
        "            sequential_structure += [maxpoolLayer(pool_size=2)]\n",
        "\n",
        "        sequential_structure += [tf.keras.layers.Flatten(),\n",
        "                                 tf.keras.layers.Dropout(0.5)]\n",
        "\n",
        "    for i in range(num_of_dense):\n",
        "        if i == 0 and conv == 0 and force_in_shape:\n",
        "            sequential_structure += [tf.keras.layers.Dense(dense_node_count,activation='relu',\n",
        "                                                           kernel_initializer='he_uniform',\n",
        "                                                           input_shape=input_shape)]\n",
        "            print('Adding input shape: %s'%str(input_shape))\n",
        "        else:\n",
        "            sequential_structure += [tf.keras.layers.Dense(dense_node_count,activation='relu',\n",
        "                                                        kernel_initializer='he_uniform')]\n",
        "        sequential_structure += [tf.keras.layers.BatchNormalization(),\n",
        "                                 tf.keras.layers.Dropout(0.5)]\n",
        "\n",
        "    sequential_structure += [tf.keras.layers.Dense(num_classes)]               \n",
        "\n",
        "    model = tf.keras.models.Sequential(sequential_structure)\n",
        "\n",
        "    model._name = model_name\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_loss():\n",
        "    return tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3kOMPQBTXVXb"
      },
      "outputs": [],
      "source": [
        "def compile_model(model,optimizer,loss_fn,_verbose = False):\n",
        "    opt = None\n",
        "    if optimizer[\"method\"] == \"sgd\":\n",
        "        opt = tf.keras.optimizers.SGD(learning_rate = optimizer[\"learning_rate\"], momentum=optimizer[\"momentum\"])\n",
        "    elif optimizer[\"method\"] == \"adam\":\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate = optimizer[\"learning_rate\"])\n",
        "    else:\n",
        "        raise Exception(\"Optimizer method not supported\")\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss=loss_fn,\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    if _verbose:\n",
        "        print(\"Model compiled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TFLite conversion function\n",
        "def convert2tflite(tf_model_dir,tflite_model_dir = None,model_name=\"model\",quantization=None,dataset=None, _verbose = False):\n",
        "    assert (quantization==None or quantization==\"dynamic\" or quantization==\"float-fallback\" or quantization==\"full\")\n",
        "    # Convert the model saved in the previous step.\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_dir)\n",
        "    if _verbose:\n",
        "        print(\"Model loaded\")\n",
        "    if quantization is not None:\n",
        "        if _verbose:\n",
        "            print(\"Quantization: %s\"%quantization)\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        if quantization == \"full\" or quantization==\"float-fallback\":\n",
        "            assert dataset is not None\n",
        "            def representative_dataset_gen():\n",
        "                for data in tf.data.Dataset.from_tensor_slices((dataset)).batch(1).take(100):\n",
        "                    yield [tf.dtypes.cast(data, tf.float32)]\n",
        "            converter.representative_dataset = representative_dataset_gen\n",
        "        if quantization == \"full\":\n",
        "            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "            converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "            converter.inference_output_type = tf.int8  # or tf.uint8\n",
        "        if quantization == \"dynamic\":\n",
        "            assert dataset is None\n",
        "\n",
        "    tflite_model = converter.convert()\n",
        "    if _verbose:\n",
        "        print(\"Model converted\")\n",
        "\n",
        "    # Save the TF Lite model.\n",
        "    if tflite_model_dir is None:\n",
        "        if _verbose:\n",
        "            print(\"Saving model to: %s\"%tf_model_dir)\n",
        "        TF_MODEL_PATH = tf_model_dir + \"/\" + model_name + '.tflite'\n",
        "    else:\n",
        "        if _verbose:\n",
        "            print(\"Saving model to: %s\"%tflite_model_dir)\n",
        "        TF_MODEL_PATH = tflite_model_dir + \"/\" + model_name + '.tflite'\n",
        "\n",
        "    if _verbose:\n",
        "        print(\"Model saved\")\n",
        "    with tf.io.gfile.GFile(TF_MODEL_PATH, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    return TF_MODEL_PATH\n",
        "\n",
        "## USAGE\n",
        "# model_path = MODELFOLDER + \"/\" + RUN_NAME + \"/fold_1\"\n",
        "# convert2tflite(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_model_params = {\n",
        "    \"input_shape\": (10,10),\n",
        "    \"conv\": 1,\n",
        "    \"num_of_dense\": 1,\n",
        "    \"dense_node_count\": 10,\n",
        "    \"model_name\": \"conv2d_1\",\n",
        "    \"num_classes\": 8\n",
        "}\n",
        "\n",
        "def save_test_model(test_model_params, mode='train'):\n",
        "    assert test_model_params['input_shape'] is not None\n",
        "    assert mode in ['train', 'define_input_shape'], \"mode must be either 'train' or 'define_input_shape'\"\n",
        "\n",
        "    model = define_model_architecture(num_classes=test_model_params['num_classes'],\n",
        "                                      input_shape = test_model_params['input_shape'],\n",
        "                                      conv = test_model_params['conv'],\n",
        "                                      num_of_dense = test_model_params['num_of_dense'],\n",
        "                                      dense_node_count  = test_model_params['dense_node_count'],\n",
        "                                      model_name = test_model_params['model_name'],\n",
        "                                      force_in_shape = mode == 'define_input_shape',\n",
        "                                      _verbose = True)\n",
        "    \n",
        "    compile_model(model,{\"method\":\"adam\",\"learning_rate\":0.001},get_loss(),True)\n",
        "\n",
        "    if mode == 'train':\n",
        "        dataTo1DConv = lambda x: np.expand_dims(x,axis = -1)\n",
        "        dataTo2DConv = lambda x,n,m: np.expand_dims(x.reshape((len(x),n,m)),axis = -1)\n",
        "\n",
        "        tx = np.random.rand(5, *test_model_params['input_shape'])\n",
        "        if len(test_model_params['input_shape']) == 1 and test_model_params['conv'] > 0:\n",
        "            tx = dataTo1DConv(tx)\n",
        "        elif len(test_model_params['input_shape']) == 2 and test_model_params['conv'] > 0:\n",
        "            tx = dataTo2DConv(tx, *test_model_params['input_shape'])\n",
        "            print('tx.shape:',tx.shape)\n",
        "\n",
        "        ty = np.random.randint(0, 8, 5)\n",
        "\n",
        "        # Force training on CPU\n",
        "        with tf.device('/cpu:0'):\n",
        "            print('Traning with input shape: %s and first layer of type'%str(tx.shape), model.layers[0].__class__.__name__)\n",
        "            model.fit(tx, ty, epochs=10, batch_size=32)\n",
        "\n",
        "    model.summary()\n",
        "    # Print input shape to first layer\n",
        "    print('Input shape: %s'%str(model.layers[0].input_shape))\n",
        "\n",
        "    ORIG_PATH = os.path.join(OUTPUT_FOLDER, test_model_params['model_name'], 'original')\n",
        "    model.save(ORIG_PATH)\n",
        "\n",
        "    mpath = convert2tflite(ORIG_PATH, tflite_model_dir = os.path.dirname(ORIG_PATH), model_name = test_model_params['model_name'], _verbose=True)\n",
        "    return mpath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding input shape: (10, 1)\n",
            "Model compiled\n",
            "Model: \"conv1d_define_input_shape\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 8, 2)              8         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8, 2)              8         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 4, 2)              0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                90        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 88        \n",
            "=================================================================\n",
            "Total params: 234\n",
            "Trainable params: 210\n",
            "Non-trainable params: 24\n",
            "_________________________________________________________________\n",
            "Input shape: (None, 10, 1)\n",
            "INFO:tensorflow:Assets written to: ./test_models/conv1d_define_input_shape/original/assets\n",
            "Model loaded\n",
            "Model converted\n",
            "Saving model to: ./test_models/conv1d_define_input_shape\n",
            "Model saved\n",
            "Model compiled\n",
            "Traning with input shape: (5, 10, 1) and first layer of type Conv1D\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 2.4641 - accuracy: 0.2000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3409 - accuracy: 0.2000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2798 - accuracy: 0.2000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.8073 - accuracy: 0.4000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.9973 - accuracy: 0.4000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.1372 - accuracy: 0.2000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8810 - accuracy: 0.2000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9417 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5334 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4276 - accuracy: 0.2000\n",
            "Model: \"conv1d_train\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 8, 2)              8         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 2)              8         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 4, 2)              0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                90        \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 88        \n",
            "=================================================================\n",
            "Total params: 234\n",
            "Trainable params: 210\n",
            "Non-trainable params: 24\n",
            "_________________________________________________________________\n",
            "Input shape: (None, 10, 1)\n",
            "INFO:tensorflow:Assets written to: ./test_models/conv1d_train/original/assets\n",
            "Model loaded\n",
            "Model converted\n",
            "Saving model to: ./test_models/conv1d_train\n",
            "Model saved\n",
            "Model compiled\n",
            "(5, 10, 10, 1)\n",
            "Traning with input shape: (5, 10, 10, 1) and first layer of type Conv2D\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 1.9523 - accuracy: 0.2000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7244 - accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3046 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.6796 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8126 - accuracy: 0.2000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6220 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.0170 - accuracy: 0.2000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.4680 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2443 - accuracy: 0.4000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.9942 - accuracy: 0.2000\n",
            "Model: \"conv2d_train\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 8, 8, 2)           20        \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 2)           8         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 2)           0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 8)                 88        \n",
            "=================================================================\n",
            "Total params: 486\n",
            "Trainable params: 462\n",
            "Non-trainable params: 24\n",
            "_________________________________________________________________\n",
            "Input shape: (None, 10, 10, 1)\n",
            "INFO:tensorflow:Assets written to: ./test_models/conv2d_train/original/assets\n",
            "Model loaded\n",
            "Model converted\n",
            "Saving model to: ./test_models/conv2d_train\n",
            "Model saved\n",
            "Adding input shape: (10, 10, 1)\n",
            "Model compiled\n",
            "Model: \"conv2d_define_input_shape\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 8, 8, 2)           20        \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 2)           8         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 2)           0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 8)                 88        \n",
            "=================================================================\n",
            "Total params: 486\n",
            "Trainable params: 462\n",
            "Non-trainable params: 24\n",
            "_________________________________________________________________\n",
            "Input shape: (None, 10, 10, 1)\n",
            "INFO:tensorflow:Assets written to: ./test_models/conv2d_define_input_shape/original/assets\n",
            "Model loaded\n",
            "Model converted\n",
            "Saving model to: ./test_models/conv2d_define_input_shape\n",
            "Model saved\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/home/cimil-01/Develop/deep-classf-runtime-wrappers/TFLiteWrapper2.4.1/data/conv2d_define_input_shape.tflite'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def prepend_reshape_to_input(model, verbose=False):\n",
        "    new_in_shape = None\n",
        "    if isinstance(model.layers[0],tf.keras.layers.Conv2D):\n",
        "        shape = model.layers[0].input_shape[1:]\n",
        "        if verbose:\n",
        "            print('shape',shape)\n",
        "        new_in_shape = (shape[0]*shape[1],)\n",
        "        if verbose:\n",
        "            print('new_in_shape',new_in_shape)\n",
        "        new_reshape_layer = tf.keras.layers.Reshape(shape, input_shape=new_in_shape)\n",
        "    elif isinstance(model.layers[0],tf.keras.layers.Conv1D):\n",
        "        shape = model.layers[0].input_shape[1:]\n",
        "        new_in_shape = (shape[0],)\n",
        "        new_reshape_layer = tf.keras.layers.Reshape(shape, input_shape=new_in_shape)\n",
        "    else:\n",
        "        strtype = str(type(model.layers[0]))\n",
        "        strtype = strtype.split('.')[-1]\n",
        "        if verbose:\n",
        "            raise Exception('You might not need reshaping with first layer of type: %s'%(strtype))\n",
        "\n",
        "    # print('Reshaper %s > %s'%(model.layers[0].input_shape,new_reshape_layer.output_shape))\n",
        "\n",
        "    new_model = tf.keras.Sequential()\n",
        "    new_model.add(new_reshape_layer)\n",
        "    new_model.add(model)\n",
        "\n",
        "    #compile the model\n",
        "    # new_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    if verbose:\n",
        "        new_model.summary()\n",
        "    # test with fake input  \n",
        "    if verbose:\n",
        "        print('New input shape: ',new_in_shape)\n",
        "\n",
        "\n",
        "    fakedata = np.random.sample(new_in_shape[0]).reshape((-1,1)).T\n",
        "    with tf.device('/cpu:0'):\n",
        "        e = new_model(fakedata).numpy()\n",
        "\n",
        "    return new_model\n",
        "curpath = save_test_model(copy.deepcopy(test_model_params), mode='train')\n",
        "assert curpath is not None and os.path.exists(curpath), \"Model not saved\"\n",
        "shutil.copyfile(curpath,os.path.join(os.path.expanduser('~/Develop/deep-classf-runtime-wrappers/TFLiteWrapper2.4.1/data/'), os.path.basename(curpath)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_model_params = {\n",
        "    \"input_shape\": (10,10),\n",
        "    \"conv\": 1,\n",
        "    \"num_of_dense\": 1,\n",
        "    \"dense_node_count\": 10,\n",
        "    \"model_name\": \"_\",\n",
        "    \"num_classes\": 8\n",
        "}\n",
        "\n",
        "test_model_params['model_name'] = \"conv2d_train\"\n",
        "curpath = save_test_model(copy.deepcopy(test_model_params), mode='train')\n",
        "assert curpath is not None and os.path.exists(curpath), \"Model not saved\"\n",
        "shutil.copyfile(curpath,os.path.join(os.path.expanduser('~/Develop/deep-classf-runtime-wrappers/TFLiteWrapper2.4.1/data/'), os.path.basename(curpath)))\n",
        "\n",
        "\n",
        "test_model_params['model_name'] = \"conv2d_define_input_shape\"\n",
        "curpath = save_test_model(copy.deepcopy(test_model_params), mode='define_input_shape')\n",
        "assert curpath is not None and os.path.exists(curpath), \"Model not saved\"\n",
        "shutil.copyfile(curpath,os.path.join(os.path.expanduser('~/Develop/deep-classf-runtime-wrappers/TFLiteWrapper2.4.1/data/'), os.path.basename(curpath)))\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uLTufCRmlpIW",
        "4pBrSDphxyxL"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf-fix",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "bbba7bb91c842039e47232619da588d5d39cf0384ecb01581f802e1efeb502cf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
