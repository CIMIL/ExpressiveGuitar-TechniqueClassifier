{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAJRnwSBQNbQ"
      },
      "source": [
        "# Expressive Guitar Technique classifier\n",
        "Ph.D. research project of [Domenico Stefani](work.domenicostefani.com)  \n",
        "This notebook loads a dataset of feature vectors extracted from **pitched** and **percussive** sounds recorded with many acoustic guitars.\n",
        "The techniques/classes recorded are:  \n",
        "\n",
        "0.    **Kick**      (Palm on lower body)\n",
        "1.    **Snare 1**   (All fingers on lower side)\n",
        "2.    **Tom**       (Thumb on higher body)\n",
        "3.    **Snare 2**   (Fingers on the muted strings, over the end\n",
        "of the fingerboard)\n",
        "___\n",
        "4.    **Natural Harmonics** (Stop strings from playing the dominant frequency, letting harmonics ring)\n",
        "5.    **Palm Mute** (Muting partially the strings with the palm\n",
        "of the pick hand)\n",
        "6.    **Pick Near Bridge** (Playing toward the bridge/saddle)\n",
        "7.    **Pick Over the Soundhole** (Playing over the sound hole)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a2ha_JDqV9I"
      },
      "source": [
        "## Import modules and mount drive folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yPrPhmjHk-kc"
      },
      "outputs": [],
      "source": [
        "# Choose ClassificationTask task\n",
        "from enum import Enum\n",
        "class ClassificationTask(Enum):\n",
        "    FULL_8_CLASS_PROBLEM,BINARY_PERCUSSIVE_PITCHED,PERCUSSIVE_4_ONLY,PITCHED_4_ONLY,PERCUSSIVE_PLUS_PITCHED_CLASS,ONE_GUITARIST_FULL = ((1,'full'), (2,'binary'), (3,'perc'), (4,'pitch'), (5,'perc+pitch'), (6,'one-guit-full'))\n",
        "class FeatureSelection(Enum):\n",
        "    NONE,MANUAL_VARIABLES,MANUAL_LIST,AUTO_ANOVA,AUTO_RELIEF = (0, 1, 2, 3, 4)\n",
        "class FeatureWindowSize(Enum):\n",
        "    s4800_SAMPLES_100ms, s704_Samples_14ms = (1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_task = ClassificationTask.FULL_8_CLASS_PROBLEM\n",
        "# classification_task = ClassificationTask.BINARY_PERCUSSIVE_PITCHED\n",
        "# classification_task = ClassificationTask.PERCUSSIVE_4_ONLY\n",
        "# classification_task = ClassificationTask.PERCUSSIVE_PLUS_PITCHED_CLASS\n",
        "# classification_task = ClassificationTask.ONE_GUITARIST_FULL\n",
        "\n",
        "# FEATURE_SELECTION = FeatureSelection.MANUAL_VARIABLES\n",
        "# FEATURE_SELECTION = FeatureSelection.MANUAL_LIST\n",
        "FEATURE_SELECTION = FeatureSelection.AUTO_ANOVA #ANOVA: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html\n",
        "# FEATURE_SELECTION = FeatureSelection.AUTO_RELIEF\n",
        "\n",
        "# FEATURE_WINDOW_SIZE = FeatureWindowSize.s4800_SAMPLES_100ms\n",
        "FEATURE_WINDOW_SIZE = FeatureWindowSize.s704_Samples_14ms\n",
        "DROP_ADDITIONAL_CEPSTRUM_FROM_BIG_WINDOW = True\n",
        "\n",
        "# SCALER_TO_USE = 'StandardScaler'\n",
        "SCALER_TO_USE = 'MinMaxScaler'\n",
        "\n",
        "#import sklearn scalers\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "if SCALER_TO_USE == 'StandardScaler':\n",
        "    SCALER_TO_USE = StandardScaler()\n",
        "elif SCALER_TO_USE == 'MinMaxScaler':\n",
        "    SCALER_TO_USE = MinMaxScaler()\n",
        "\n",
        "TRAIN_FINAL_MODEL = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VuprRjSbkuh3"
      },
      "outputs": [],
      "source": [
        "# Install module for the ReliefF feature selection\n",
        "# !pip install skrebate\n",
        "# !pip install tensorboard\n",
        "# !pip3 install pickle5\n",
        "# !pip3 install tensorflow==2.4.1\n",
        "# !pip3 install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.5.0\n",
            "Imblearn version: 0.9.0\n",
            "Not running on CoLab\n"
          ]
        }
      ],
      "source": [
        "REQUIRE_GPU = False\n",
        "DO_SAVE_TENSORBOARD_LOGS = False \n",
        "DO_SAVE_FOLD_MODELS = False \n",
        "CUSTOM_PLAYER_K_FOLD = True         # Very important, this ditches the k-fold stratified random shuffle, and creates as many splits as the guitar players, separating natural groups\n",
        "DROP_EXTRA_PERCUSSIVE_SOUNDS = True # If true, drop the data from files that have 'extra' in the filename, which otherwise make the dataset unbalanced\n",
        "\n",
        "\n",
        "USE_TENSORBOARD = False\n",
        "\n",
        "if FEATURE_WINDOW_SIZE == FeatureWindowSize.s4800_SAMPLES_100ms:\n",
        "    USE_AUGMENTED_DATA = False\n",
        "elif FEATURE_WINDOW_SIZE == FeatureWindowSize.s704_Samples_14ms:\n",
        "    USE_AUGMENTED_DATA = True\n",
        "else:\n",
        "    raise ValueError('Invalid feature window size')\n",
        "# USE_AUGMENTED_DATA = False\n",
        "DROP_EXTRA_PERCUSSIVE_SOUNDS_FROMAUG = False\n",
        "\n",
        "DO_NORMALIZE_DATA = True\n",
        "\n",
        "DO_NORMALIZE_FOR_FEATURE_SELECTION = True\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "if USE_TENSORBOARD:\n",
        "    %load_ext tensorboard\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "from sys import executable as sys_executable\n",
        "from sys import argv as sys_argv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from time import strftime, time\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from bz2 import BZ2File # To open compressed data\n",
        "import re\n",
        "import shutil\n",
        "import imblearn\n",
        "from sklearn.metrics import confusion_matrix as sk_conf_matrix\n",
        "from sklearn.metrics import classification_report as sk_class_report\n",
        "\n",
        "print(\"Tensorflow version: \" + tf.version.VERSION)\n",
        "print('Imblearn version:',imblearn.__version__)\n",
        "\n",
        "global_random_state = 42\n",
        "np.random.seed(global_random_state)\n",
        "tf.random.set_seed(global_random_state)\n",
        "\n",
        "COLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if COLAB:\n",
        "    print('Running on CoLab')\n",
        "    #Connect and mount the drive folder that contains the train dataset and the output folder\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive', force_remount=False)\n",
        "\n",
        "    HOMEBASE = os.path.join('/content','gdrive','MyDrive','dottorato','Publications','02-IEEE-RTEmbeddedTimbreClassification(submitted)','Classifier')\n",
        "    THISDIR = \"/content/\"\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    HOMEBASE = \".\"\n",
        "    THISDIR = \"./\"\n",
        "DATAFOLDER = os.path.join(HOMEBASE,\"data/phase3\")\n",
        "MODELFOLDER = os.path.join(HOMEBASE,\"output\")\n",
        "\n",
        "RELIEF_CACHE_FILEPATH = os.path.join(DATAFOLDER,'relief_cache.pickle')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sY_34JvX6uFT"
      },
      "outputs": [],
      "source": [
        "def is_notebook() -> bool:\n",
        "    try:\n",
        "        shell = get_ipython().__class__.__name__\n",
        "        if shell == 'ZMQInteractiveShell':\n",
        "            return True   # Jupyter notebook or qtconsole\n",
        "        elif shell == 'TerminalInteractiveShell':\n",
        "            return False  # Terminal running IPython\n",
        "        else:\n",
        "            return False  # Other type (?)\n",
        "    except NameError:\n",
        "        return False      # Probably standard Python interpreter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7qyEuAk6uFV"
      },
      "source": [
        "## Enforce GPU usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9BxHBUDQPXKS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "\n",
        "for device in physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "print(physical_devices)\n",
        "if REQUIRE_GPU:\n",
        "  assert len(tf.config.experimental.list_physical_devices('GPU')) >= 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8ZMbpx2eM2G"
      },
      "source": [
        "## Check Real avaliable GRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8lSUK12K6uFW"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def pip_install(package):\n",
        "    subprocess.check_call([executable, \"-m\", \"pip\", \"install\", package])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R_8hnGH7eL_T"
      },
      "outputs": [],
      "source": [
        "CHECK_GRAM = False\n",
        "\n",
        "if CHECK_GRAM:\n",
        "    # memory footprint support libraries/code\n",
        "    os.symlink('/opt/bin/nvidia-smi','/usr/bin/nvidia-smi')\n",
        "    pip_install('gputil')\n",
        "    pip_install('psutil')\n",
        "    pip_install('humanize')\n",
        "    import psutil\n",
        "    import humanize\n",
        "    import os\n",
        "    import GPUtil as GPU\n",
        "    GPUs = GPU.getGPUs()\n",
        "    # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "    gpu = GPUs[0]\n",
        "    def printm():\n",
        "        process = psutil.Process(os.getpid())\n",
        "        print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "        print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "    printm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2hdmJnSsEOM"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CozyQAQgznvK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from file: onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20221201-182312_REALTIMEdataset-phase3PROCESSED_FEATURES.pickle\n",
            "Reading dataset from pickle...\n",
            "Successfully Loaded!\n",
            "It took 1.0s to load from regular pickle\n",
            "Dataset loaded!\n"
          ]
        }
      ],
      "source": [
        "if FEATURE_WINDOW_SIZE == FeatureWindowSize.s4800_SAMPLES_100ms:\n",
        "    DATASET_FILENAME = 'onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20221206-165551_SUPERLONGdataset-phase3PROCESSED_FEATURES.pickle'\n",
        "elif FEATURE_WINDOW_SIZE == FeatureWindowSize.s704_Samples_14ms:\n",
        "    DATASET_FILENAME = 'onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20221201-182312_REALTIMEdataset-phase3PROCESSED_FEATURES.pickle'\n",
        "else:\n",
        "    raise ValueError('Invalid FeatureWindowSize \"%s\"'%FeatureWindowSize.name)\n",
        "\n",
        "print('Loading dataset from file:',DATASET_FILENAME)\n",
        "\n",
        "\n",
        "if os.path.splitext(DATASET_FILENAME)[1] == '.bz2':\n",
        "    print(\"Reading dataset from compressed pickle...\")\n",
        "    DATASET_PATH = os.path.join(DATAFOLDER,DATASET_FILENAME)\n",
        "    startime = time()\n",
        "    ifile = BZ2File(DATASET_PATH,'rb')\n",
        "    featuredataset = pickle.load(ifile)\n",
        "    ifile.close()\n",
        "    print('Successfully Loaded!\\nIt took %.1fs to load from compressed pickle' % (time()-startime))\n",
        "elif os.path.splitext(DATASET_FILENAME)[1] == '.pickle':\n",
        "    print(\"Reading dataset from pickle...\")\n",
        "    DATASET_PATH = os.path.join(DATAFOLDER,DATASET_FILENAME)\n",
        "    startime = time()\n",
        "    with open(DATASET_PATH,'rb') as pf:\n",
        "        featuredataset = pickle.load(pf)\n",
        "    print('Successfully Loaded!\\nIt took %.1fs to load from regular pickle' % (time()-startime))\n",
        "else:\n",
        "    raise Exception(\"Extension %s not supported!\" % os.path.splitext(DATASET_FILENAME)[1])\n",
        "print('Dataset loaded!')\n",
        "# display(featuredataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "EXPECTED_DATASED_SIZE = 23303"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading file metaplus_onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20221125-144015_gainaug-phase3-aug1PROCESSED_FEATURES.pickle\n",
            "Loading file metaplus_onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20221125-163857_gainaug-phase3-aug4PROCESSED_FEATURES.pickle\n",
            "Loading file metaplus_onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20221125-152410_gainaug-phase3-aug2PROCESSED_FEATURES.pickle\n",
            "Loading file metaplus_onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20221125-160225_gainaug-phase3-aug3PROCESSED_FEATURES.pickle\n",
            "Loaded 92293 augmented samples\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "augmented_featuredataset_list = []\n",
        "if USE_AUGMENTED_DATA:\n",
        "    augmented_data_paths = glob(os.path.join(DATAFOLDER,'augmented_data','*.pickle'))\n",
        "    for augmented_data_path in augmented_data_paths:\n",
        "        print(\"Loading file %s\" % os.path.basename(augmented_data_path))\n",
        "        with open(augmented_data_path,'rb') as pf:\n",
        "            augmented_featuredataset_list.append(pickle.load(pf))\n",
        "    augmented_featuredataset = pd.concat(augmented_featuredataset_list, ignore_index=True)\n",
        "    print(\"Loaded %d augmented samples\" % len(augmented_featuredataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E1rKcNy5RqZ"
      },
      "source": [
        "### Drop features that we have found to be problematic with feature selection and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Uhip8r7F4sSv"
      },
      "outputs": [],
      "source": [
        "def drop_unused_features(features_df: pd.DataFrame, inplace = False) -> pd.DataFrame:\n",
        "    if not inplace:\n",
        "        res_df = features_df.copy()\n",
        "    else:\n",
        "        res_df = features_df\n",
        "    if 'attackTime_peaksamp'       not in res_df.columns.to_list() or\\\n",
        "       'attackTime_attackStartIdx' not in res_df.columns.to_list() or\\\n",
        "       'peakSample_index'          not in res_df.columns.to_list():\n",
        "       raise Exception(\"The features dataframe does not contain the required columns!\")\n",
        "\n",
        "    res_df.drop(columns=['attackTime_peaksamp',\\\n",
        "                                'attackTime_attackStartIdx',\\\n",
        "                                'peakSample_index'], inplace=True)\n",
        "    return res_df\n",
        "\n",
        "featuredataset = drop_unused_features(featuredataset)\n",
        "if USE_AUGMENTED_DATA:\n",
        "    augmented_featuredataset = drop_unused_features(augmented_featuredataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "if DROP_ADDITIONAL_CEPSTRUM_FROM_BIG_WINDOW:\n",
        "\n",
        "    # Largest cepstrum now:\n",
        "    larg_ceps = max([int(e.split('_')[-1]) for e in featuredataset.columns.to_list() if 'cepstrum' in e])\n",
        "    # Max xepstrum coeff. of smallest window (704 samples)\n",
        "    smallest_ceps = 704//2+1\n",
        "\n",
        "    featuredataset.drop(columns=[f'cepstrum_{v}' for v in range(smallest_ceps+1,larg_ceps + 1)], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['meta_audiofilePath', 'meta_onsetGroundTruthLabelTime',\n",
              "       'meta_onsetDetectionTime', 'meta_featureComputationTime',\n",
              "       'meta_featureExtractionWindowSize', 'meta_sampleRate', 'meta_blockSize',\n",
              "       'meta_extractiondate', 'meta_expressive_technique_id',\n",
              "       'attackTime_value',\n",
              "       ...\n",
              "       'mfcc_31', 'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36',\n",
              "       'mfcc_37', 'mfcc_38', 'peakSample_value', 'zeroCrossing'],\n",
              "      dtype='object', length=504)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "featuredataset.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0xh-UknklQy"
      },
      "source": [
        "### If specified, drop extra percussive recorded data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WvUB_btbklQy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping 2237 additional percussive recordings because \"DROP_EXTRA_PERCUSSIVE_SOUNDS\" was specified.\n",
            "Dataset shape after dropping extra percussive recordings: (21066, 504)\n"
          ]
        }
      ],
      "source": [
        "if FEATURE_WINDOW_SIZE == FeatureWindowSize.s704_Samples_14ms:\n",
        "    assert featuredataset.shape == (EXPECTED_DATASED_SIZE, 504)\n",
        "if DROP_EXTRA_PERCUSSIVE_SOUNDS:\n",
        "    to_drop_count = np.count_nonzero(featuredataset.meta_audiofilePath.str.contains(\"additional-500\").values)\n",
        "    if to_drop_count >= 0:\n",
        "        print('Dropping %d additional percussive recordings because \"DROP_EXTRA_PERCUSSIVE_SOUNDS\" was specified.'%(to_drop_count))\n",
        "        featuredataset = featuredataset[~featuredataset.meta_audiofilePath.str.contains(\"additional-500\")].reset_index(drop=True)\n",
        "        print('Dataset shape after dropping extra percussive recordings: %s'%(str(featuredataset.shape)))\n",
        "    if FEATURE_WINDOW_SIZE == FeatureWindowSize.s704_Samples_14ms:\n",
        "        assert featuredataset.shape == (EXPECTED_DATASED_SIZE-2237, 504)\n",
        "\n",
        "\n",
        "if USE_AUGMENTED_DATA and DROP_EXTRA_PERCUSSIVE_SOUNDS_FROMAUG:\n",
        "    augmented_featuredataset_dr = augmented_featuredataset.copy()\n",
        "    to_drop_count_aug = np.count_nonzero(augmented_featuredataset.meta_augmentation_source.str.contains(\"additional-500\").values)\n",
        "    if to_drop_count_aug >= 0:\n",
        "        print('Dropping %d additional percussive recordings because \"DROP_EXTRA_PERCUSSIVE_SOUNDS\" was specified.'%(to_drop_count_aug))\n",
        "        augmented_featuredataset_dr = augmented_featuredataset[~augmented_featuredataset.meta_augmentation_source.str.contains(\"additional-500\")].reset_index(drop=True)\n",
        "        print('Dataset shape after dropping extra percussive recordings: %s'%(str(augmented_featuredataset_dr.shape)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-HN56MAc5kjA"
      },
      "outputs": [],
      "source": [
        "# Extract separate DFs\n",
        "from typing import Tuple\n",
        "\n",
        "# Divide dataset into metadata, features and labels\n",
        "def divide_dataset(features_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    metadata = features_df.filter(regex='^meta_',axis=1)\n",
        "    labels = features_df.meta_expressive_technique_id\n",
        "    features = features_df.loc[:,[col for col in features_df.columns if col not in metadata.columns]]\n",
        "    # Convert to numeric formats where possible (somehow convert_dtypes doesn't work [https://stackoverflow.com/questions/65915048/pandas-convert-dtypes-not-working-on-numbers-marked-as-objects])\n",
        "    metadata = metadata.apply(pd.to_numeric, errors='ignore')\n",
        "    labels = labels.apply(pd.to_numeric, errors='ignore')\n",
        "    features = features.apply(pd.to_numeric, errors='ignore')\n",
        "    return metadata, features, labels\n",
        "\n",
        "metadata, features, labels = divide_dataset(featuredataset)\n",
        "assert metadata.shape[1] == 9\n",
        "if FEATURE_WINDOW_SIZE == FeatureWindowSize.s704_Samples_14ms:\n",
        "    assert features.shape[1] == 495\n",
        "elif FEATURE_WINDOW_SIZE == FeatureWindowSize.s4800_SAMPLES_100ms:\n",
        "    assert features.shape[1] == 2543\n",
        "\n",
        "if USE_AUGMENTED_DATA:\n",
        "    metadata_aug, features_aug, labels_aug = divide_dataset(augmented_featuredataset_dr if DROP_EXTRA_PERCUSSIVE_SOUNDS_FROMAUG else augmented_featuredataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "X1iiyTkcYKFi"
      },
      "outputs": [],
      "source": [
        "def get_classes_description(classftask: ClassificationTask):\n",
        "    if classification_task == ClassificationTask.FULL_8_CLASS_PROBLEM:\n",
        "        classes_desk = {0:\"Kick\",1:\"Snare 1\",2:\"Tom\",3:\"Snare 2\",4:\"Natural Harmonics\",5:\"Palm Mute\",6:\"Pick Near Bridge\",7:\"Pick Over the Soundhole\"}\n",
        "    elif classification_task == ClassificationTask.BINARY_PERCUSSIVE_PITCHED:\n",
        "        classes_desk = {0:\"Percussive\",1:\"Pitched\"}\n",
        "    elif classification_task == ClassificationTask.PERCUSSIVE_4_ONLY:\n",
        "        classes_desk = {0:\"Kick\", 1:\"Snare 1\", 2:\"Tom\", 3:\"Snare 2\"}\n",
        "    elif classification_task == ClassificationTask.PITCHED_4_ONLY:\n",
        "        classes_desk = {0:\"Natural Harmonics\", 1:\"Palm Mute\", 2:\"Pick Near Bridge\", 3:\"Pick Over the Soundhole\"}\n",
        "    elif classification_task == ClassificationTask.PERCUSSIVE_PLUS_PITCHED_CLASS:\n",
        "        classes_desk = {0:\"Kick\", 1:\"Snare 1\", 2:\"Tom\", 3:\"Snare 2\", 4:\"Pitched\"}\n",
        "    elif classification_task == ClassificationTask.ONE_GUITARIST_FULL:\n",
        "        classes_desk = {0:\"Kick\",1:\"Snare 1\",2:\"Tom\",3:\"Snare 2\",4:\"Natural Harmonics\",5:\"Palm Mute\",6:\"Pick Near Bridge\",7:\"Pick Over the Soundhole\"}\n",
        "    else:\n",
        "        raise Exception('The Classification Task selected is not supported')\n",
        "    classes = list(classes_desk.keys())\n",
        "    return classes,classes_desk\n",
        "\n",
        "def filter_dataset(tofilt_features,tofilt_labels,tofilt_metadata,classftask: ClassificationTask, hardcoded_sizes_test = False):\n",
        "    if classification_task == ClassificationTask.FULL_8_CLASS_PROBLEM:\n",
        "        pass\n",
        "    elif classification_task == ClassificationTask.BINARY_PERCUSSIVE_PITCHED:\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "        if hardcoded_sizes_test:\n",
        "            assert len(tofilt_features) == EXPECTED_DATASED_SIZE-2237\n",
        "        tofilt_labels = tofilt_labels.replace([0,1,2,3],[0,0,0,0])\n",
        "        tofilt_labels = tofilt_labels.replace([4,5,6,7],[1,1,1,1])\n",
        "    elif classification_task == ClassificationTask.PERCUSSIVE_4_ONLY:\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "        if hardcoded_sizes_test:\n",
        "            assert len(tofilt_features) == EXPECTED_DATASED_SIZE-2237\n",
        "        filtered_idxs = tofilt_labels < 4\n",
        "        tofilt_features = tofilt_features[filtered_idxs]\n",
        "        tofilt_labels = tofilt_labels[filtered_idxs]\n",
        "        tofilt_metadata = tofilt_metadata[filtered_idxs].copy()\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "        if hardcoded_sizes_test:\n",
        "            assert len(tofilt_features) == 1620\n",
        "    elif classification_task == ClassificationTask.PITCHED_4_ONLY:\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "        if hardcoded_sizes_test:\n",
        "            assert len(tofilt_features) == EXPECTED_DATASED_SIZE-2237\n",
        "        filtered_idxs = tofilt_labels >= 4\n",
        "        tofilt_features = tofilt_features[filtered_idxs]\n",
        "        tofilt_metadata = tofilt_metadata[filtered_idxs].copy()\n",
        "        tofilt_labels = tofilt_labels[filtered_idxs]\n",
        "        tofilt_labels = tofilt_labels.replace([4,5,6,7],[0,1,2,3])\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "        if hardcoded_sizes_test:\n",
        "            assert len(tofilt_features) == EXPECTED_DATASED_SIZE-2237-1620\n",
        "    elif classification_task == ClassificationTask.PERCUSSIVE_PLUS_PITCHED_CLASS:\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "        if hardcoded_sizes_test:\n",
        "            assert len(tofilt_features) == EXPECTED_DATASED_SIZE-2237\n",
        "        tofilt_labels = tofilt_labels.replace([5,6,7],[4,4,4])\n",
        "    elif classification_task == ClassificationTask.ONE_GUITARIST_FULL:\n",
        "\n",
        "        filtered_idxs = tofilt_features['']\n",
        "        # tofilt_features = tofilt_features[filtered_idxs]\n",
        "        # tofilt_labels = tofilt_labels[filtered_idxs]\n",
        "        # tofilt_metadata = tofilt_metadata[filtered_idxs].copy()\n",
        "        # assert len(tofilt_features) == len(tofilt_labels)\n",
        "        # if hardcoded_sizes_test:\n",
        "        #     assert len(tofilt_features) == 1620\n",
        "    else:\n",
        "        raise Exception('The Classification Task selected is not supported')\n",
        "\n",
        "\n",
        "    tofilt_features.reset_index(drop=True,inplace=True)\n",
        "    tofilt_labels.reset_index(drop=True,inplace=True)\n",
        "    tofilt_metadata.reset_index(drop=True,inplace=True)\n",
        "\n",
        "    return tofilt_features, tofilt_labels, tofilt_metadata\n",
        "\n",
        "original_dataset_features = features.copy()\n",
        "dataset_labels = labels.copy()\n",
        "dataset_metadata = metadata.copy()\n",
        "\n",
        "CLASSES,CLASSES_DESC = get_classes_description(classification_task)\n",
        "original_dataset_features,dataset_labels,dataset_metadata = filter_dataset(original_dataset_features,dataset_labels,dataset_metadata,classification_task,hardcoded_sizes_test=True if FEATURE_WINDOW_SIZE == FeatureWindowSize.s704_Samples_14ms else False)\n",
        "if USE_AUGMENTED_DATA:\n",
        "    features_aug,labels_aug,metadata_aug = filter_dataset(features_aug,labels_aug,metadata_aug,classification_task,hardcoded_sizes_test=False)\n",
        "    assert len(np.sort(CLASSES)) == len(np.sort(pd.unique(labels_aug))) and np.equal(np.sort(CLASSES),np.sort(pd.unique(labels_aug))).all()\n",
        "\n",
        "assert len(np.sort(CLASSES)) == len(np.sort(pd.unique(dataset_labels))) and np.equal(np.sort(CLASSES),np.sort(pd.unique(dataset_labels))).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['acoustic_guitar_percussive_keybed_1_25_f_LucTur2_20201215.wav'\n",
            " 'acoustic_guitar_percussive_keybed_1_25_f_LucTur2_20201215.wav'\n",
            " 'acoustic_guitar_percussive_keybed_1_25_f_LucTur2_20201215.wav' ...\n",
            " 'acoustic_guitar_pitched_allstring6_soundholepick_p_LucTur2_20201215.wav'\n",
            " 'acoustic_guitar_pitched_allstring6_soundholepick_p_LucTur2_20201215.wav'\n",
            " 'acoustic_guitar_pitched_allstring6_soundholepick_p_LucTur2_20201215.wav']\n"
          ]
        }
      ],
      "source": [
        "print(metadata[metadata['meta_audiofilePath'].str.contains('LucTur2')]['meta_audiofilePath'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "H_JEEbL-mcJ-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset \"Main datase\" read\n",
            "| Entries: 21066\n",
            "╰─ Features: 495\n",
            "Dataset \"Augmented data\" read\n",
            "| Entries: 92293\n",
            "╰─ Features: 495\n"
          ]
        }
      ],
      "source": [
        "if USE_AUGMENTED_DATA:\n",
        "    for dat,name in [(original_dataset_features,'Main datase'),(features_aug,'Augmented data')]:\n",
        "        print('Dataset \"'+name+'\" read')\n",
        "        print(\"| Entries: \"+str(dat.shape[0]))\n",
        "        print(\"╰─ Features: \"+str(dat.shape[1]))\n",
        "\n",
        "original_feature_number = original_dataset_features.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "v2gv9fFFavMz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4aa23cac1ee24f27bb04f4aa5631e99329a3a965b9ba960aee8f8c65880c289f\n"
          ]
        }
      ],
      "source": [
        "# Compute has of the dataset files.\n",
        "# This are used to cache precomputed feature selection with ReliefF (Which is rather slow)\n",
        "import hashlib\n",
        " \n",
        "dataset_sha256_hash = hashlib.sha256()\n",
        "with open(DATASET_PATH,\"rb\") as fy:\n",
        "    for byte_block in iter(lambda: fy.read(4096),b\"\"):    # Read and update hash string value in blocks of 4K\n",
        "        dataset_sha256_hash.update(byte_block)\n",
        "dataset_sha256_hash = dataset_sha256_hash.hexdigest()\n",
        "\n",
        "print(dataset_sha256_hash)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3ND_A4d6uFT"
      },
      "source": [
        "## Parse Command Line arguments\n",
        "\n",
        "*_Important_*: If you are running this from a jupyter Notebook, change the run parameters at the end of the next cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVHOAmQ-6uFU"
      },
      "outputs": [],
      "source": [
        "args = None\n",
        "if not is_notebook() and not COLAB:\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser(description='Train the expressive guitar technique classifier.')\n",
        "\n",
        "    def featnum_type(x):\n",
        "        (MIN,MAX) = (1,495)\n",
        "        if x == 'all':\n",
        "            return x\n",
        "        x = int(x)\n",
        "        if x < MIN or x > MAX:\n",
        "            raise argparse.ArgumentTypeError(\"Feature parameter must either 'all' or a number be between {} and {}\".format(MIN, MAX))\n",
        "        return x\n",
        "    def netdepth_type(x):\n",
        "        (MIN,MAX) = (0,20) \n",
        "        x = int(x)\n",
        "        if x < MIN or x > MAX:\n",
        "            raise argparse.ArgumentTypeError(\"Network depth must be between {} and {}\".format(MIN, MAX))\n",
        "        return x\n",
        "    def netwidth_type(x):\n",
        "        (MIN,MAX) = (1,2000) \n",
        "        x = int(x)\n",
        "        if x < MIN or x > MAX:\n",
        "            raise argparse.ArgumentTypeError(\"Network width must be between {} and {}\".format(MIN, MAX))\n",
        "        return x\n",
        "    def dropout_type(x):\n",
        "        (MIN,MAX) = (0,1) \n",
        "        x = float(x)\n",
        "        if x < MIN or x > MAX:\n",
        "            raise argparse.ArgumentTypeError(\"Dropout Rate must be between {} and {}\".format(MIN, MAX))\n",
        "        return x\n",
        "    def aggressiveness_type(x):\n",
        "        (MIN,MAX) = (0,1) \n",
        "        x = float(x)\n",
        "        if x < MIN or x > MAX:\n",
        "            raise argparse.ArgumentTypeError(\"Oversampling aggressiveness value must be between {} and {}\".format(MIN, MAX))\n",
        "        return x\n",
        "    def lr_type(x):\n",
        "        (MIN,MAX) = (0,1) \n",
        "        x = float(x)\n",
        "        if x < MIN or x > MAX:\n",
        "            raise argparse.ArgumentTypeError(\"Learning rate must be between {} and {}\".format(MIN, MAX))\n",
        "        return x\n",
        "    def batchsize_type(x):\n",
        "        (MIN,MAX) = (1,4096) \n",
        "        x = int(x)\n",
        "        if x < MIN or x > MAX:\n",
        "            raise argparse.ArgumentTypeError(\"Batchsize must be between {} and {}\".format(MIN, MAX))\n",
        "        return x\n",
        "    def epochs_type(x):\n",
        "        (MIN,MAX) = (1,10000) \n",
        "        x = int(x)\n",
        "        if x < MIN or x > MAX:\n",
        "            raise argparse.ArgumentTypeError(\"Epoch number must be between {} and {}\".format(MIN, MAX))\n",
        "        return x\n",
        "    def kfold_type(x):\n",
        "        (MIN,MAX) = (1,20) \n",
        "        x = int(x)\n",
        "        if x < MIN or x > MAX:\n",
        "            raise argparse.ArgumentTypeError(\"KFOLD size must be between {} and {}\".format(MIN, MAX))\n",
        "        return x\n",
        "    def c1d_type(x):\n",
        "        (MIN,MAX) = (0,5) \n",
        "        x = int(x)\n",
        "        if x < MIN or x > MAX:\n",
        "            raise argparse.ArgumentTypeError(\"Number of conv1d layers must be between {} and {}\".format(MIN, MAX))\n",
        "        return x\n",
        "\n",
        "    # class RangedInt():\n",
        "\n",
        "\n",
        "    # def ranged_int_type(x,_min,_max):\n",
        "    #     x = int(x)\n",
        "    #     if x < _min or x > _max:\n",
        "    #         raise argparse.ArgumentTypeError(\"Value must be an integer number between {} and {}\".format(_min, _max))\n",
        "    #     return x\n",
        "\n",
        "    # def ranged_float_type(x,_min,_max):\n",
        "    #     x = float(x)\n",
        "    #     if x < _min or x > _max:\n",
        "    #         raise argparse.ArgumentTypeError(\"Value must be a real number between {} and {}\".format(_min, _max))\n",
        "    #     return x\n",
        "\n",
        "    parser.add_argument('-f',  '--features',      default='all',     type=featnum_type,   help='Number of features to use for training [1-495] (default: 80)')\n",
        "    parser.add_argument('-d',  '--net-depth',     default=3,      type=netdepth_type,  help='Number of dense layers in the network [0-20] (default: 3)')\n",
        "    parser.add_argument('-w',  '--net-width',     default=100,    type=netwidth_type,  help='Number of layers in the FFNN [1-2000] (default: 100)')\n",
        "    parser.add_argument('-dr', '--dropout',       default=0.15,   type=dropout_type,   help='Dropout amount [0-1] (default: 0.15)')\n",
        "    parser.add_argument('-lr', '--learning-rate', default=0.0001, type=lr_type,        help='Learning rate [0-1] (default: 0.0001)')\n",
        "    parser.add_argument('-bs', '--batchsize',     default=256,    type=batchsize_type, help='Learning rate [1-4096] (default: 256)')\n",
        "    parser.add_argument('-e',  '--epochs',        default=1000,   type=epochs_type,    help='Learning rate [1-10000] (default: 1000)')\n",
        "    parser.add_argument('-k',  '--k-folds',       default=5,      type=kfold_type,     help='K of K-folds [1-20] (default: 5)')\n",
        "    parser.add_argument('-os', '--oversampling',  action='store_true', help='Perform oversampling')\n",
        "    parser.add_argument('-osagg', '--oversampling-aggressiveness',  default=0.2,   type=aggressiveness_type,   help='Oversampling aggressiveness [0-1] (default: 0.2)')\n",
        "    parser.add_argument('-c1d',   '--conv1d',     default=0,      type=c1d_type,     help='Number of conv1D layers at the beginning [1-5] (default: 0)')\n",
        "    parser.add_argument('-ck',    '--conv1d-kernels',     default='',      type=ascii,     help='Comma-separated list of kernel sizes for conv1D layers (es: 3,5,7)')\n",
        "    parser.add_argument('-cs',    '--conv1d-strides',     default='',      type=ascii,     help='Comma-separated list of strides for conv1D layers (es: 1,1,1)')\n",
        "    parser.add_argument('-cf',    '--conv1d-filters',     default='',      type=ascii,     help='Comma-separated list of filters for conv1D layers (es: 32,64,128)')\n",
        "    parser.add_argument('-c1dact','--conv1d-activations', default='',  type=ascii,     help='Comma-separated list of activations for conv1D layers (es: relu,relu,relu)')\n",
        "    parser.add_argument('-pl','--pool_layers', default='',  type=ascii,     help='Comma-separated list of pool layers. Use \"N\" for none, \"M\" for max-pooling and \"A\" for average pooling  (es: M,N,M)')\n",
        "    parser.add_argument('-v', '--verbose',        action='store_true', help='increase output verbosity')\n",
        "    args = parser.parse_args()\n",
        "    args = vars(args)\n",
        "else:\n",
        "\n",
        "    \"\"\"\n",
        "    ████████████████████████████████████████████████████████████████████████████████████████████████████\n",
        "    █████████████████████████████     ██     ██     ██     ██ ███ ██     ███████████████████████████████\n",
        "    █████████████████████████████ ███ ██ ███ ██ ███ ██ ███ ██  █  ██ ███████████████████████████████████\n",
        "    █████████████████████████████ ███ ██ ███ ██ ███ ██ ███ ██ █ █ ██ ███████████████████████████████████\n",
        "    █████████████████████████████     ██     ██     ██     ██ ███ ██     ███████████████████████████████\n",
        "    █████████████████████████████ ██████ ███ ██ ██ ███ ███ ██ ███ ██████ ███████████████████████████████\n",
        "    █████████████████████████████ ██████ ███ ██ ███ ██ ███ ██ ███ ██████ ███████████████████████████████\n",
        "    █████████████████████████████ ██████ ███ ██ ███ ██ ███ ██ ███ ██     ███████████████████████████████\n",
        "    ████████████████████████████████████████████████████████████████████████████████████████████████████\n",
        "    \"\"\"\n",
        "    \n",
        "    #-------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
        "    \"\"\" +-----------------------------------------------------------------------------------------------+                                 #\n",
        "    #   |    CHANGE THE VALUES HERE IF RUNNING THE TRAINING FROM A JUPYTER NOTEBOOK (e.g., on Colab)    |                                 #\n",
        "    #   + ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ +                                 #\n",
        "    \"\"\" #↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓#\n",
        "    args = {'features':      'all', \n",
        "            'net_depth':     0, \n",
        "            'net_width':     64, \n",
        "            'dropout':       0.2,\n",
        "            'learning_rate': 0.0005,\n",
        "            'batchsize':     1024,\n",
        "            'epochs':        120,\n",
        "            'k_folds':       5,\n",
        "            'oversampling':  True,\n",
        "            'oversampling_aggressiveness':  0,\n",
        "            'conv1d':        4,\n",
        "            'conv1d_kernels': '5,5,5,5',\n",
        "            'conv1d_strides': '3,2,1,1',\n",
        "            'conv1d_filters': '4,4,8,16',\n",
        "            'conv1d_activations': 'relu,relu,relu,relu',\n",
        "            'pool_layers': 'M,A,N,M',\n",
        "            'verbose':       False}\n",
        "    #↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑#\n",
        "    \"\"\" + ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ +                                 #\n",
        "    #   |    CHANGE THE VALUES HERE IF RUNNING THE TRAINING FROM A JUPYTER NOTEBOOK (e.g., on Colab)    |                                 #\n",
        "    #   +-----------------------------------------------------------------------------------------------+                                 #\n",
        "    \"\"\"#----------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "args['conv1d_kernels'] = args['conv1d_kernels'].strip(\"'\")\n",
        "args['conv1d_filters'] = args['conv1d_filters'].strip(\"'\")\n",
        "args['conv1d_activations'] = args['conv1d_activations'].strip(\"'\")\n",
        "args['conv1d_strides'] = args['conv1d_strides'].strip(\"'\")\n",
        "\n",
        "KERNEL_SIZES = [int(x) for x in args['conv1d_kernels'].split(',')] if args['conv1d'] > 1 else [int(args['conv1d_kernels'])] if args['conv1d'] == 1 else []\n",
        "print('KERNEL_SIZES: ', KERNEL_SIZES)\n",
        "FILTERS = [int(x) for x in args['conv1d_filters'].split(',')] if args['conv1d'] > 1 else [int(args['conv1d_filters'])] if args['conv1d'] == 1 else []\n",
        "print('FILTERS: ', FILTERS)\n",
        "CONV_ACTIVATIONS = args['conv1d_activations'].split(',')    if args['conv1d'] > 1 else [args['conv1d_activations']] if args['conv1d'] == 1 else []\n",
        "CONV_ACTIVATIONS = [e if e.lower() != 'none' else None for e in CONV_ACTIVATIONS]\n",
        "print('CONV_ACTIVATIONS: ', CONV_ACTIVATIONS)\n",
        "STRIDES = [int(x) for x in args['conv1d_strides'].split(',')] if args['conv1d'] > 1 else [int(args['conv1d_strides'])] if args['conv1d'] == 1 else []\n",
        "print('STRIDES: ', STRIDES)\n",
        "POOL_LAYERS = args['pool_layers'].split(',') if args['conv1d'] > 1 else [args['pool_layers']] if args['conv1d'] == 1 else []\n",
        "#Pooling layers must be one of 'M', 'N', or 'A' \n",
        "assert all([e in ['M','N','A'] for e in POOL_LAYERS]), \"Pooling layers must be one of 'M', 'N', or 'A'\"\n",
        "print('POOL_LAYERS: ', POOL_LAYERS)\n",
        "\n",
        "POOL_SIZES = [2]*args['conv1d'] # TODO: parameterize this as well\n",
        "\n",
        "assert len(KERNEL_SIZES)     == args['conv1d'], \"The number of kernel sizes must be equal to the number of conv1d layers ({} != {})\".format(len(KERNEL_SIZES), args['conv1d'])\n",
        "assert len(FILTERS)          == args['conv1d'], \"The number of filters must be equal to the number of conv1d layers ({} != {})\".format(len(FILTERS), args['conv1d'])\n",
        "assert len(CONV_ACTIVATIONS) == args['conv1d'], \"The number of activations must be equal to the number of conv1d layers ({} != {})\".format(len(CONV_ACTIVATIONS), args['conv1d'])\n",
        "assert len(STRIDES)          == args['conv1d'], \"The number of strides must be equal to the number of conv1d layers ({} != {})\".format(len(STRIDES), args['conv1d'])\n",
        "assert len(POOL_LAYERS)      == args['conv1d'], \"The number of pool layers must be equal to the number of conv1d layers ({} != {})\".format(len(POOL_LAYERS), args['conv1d'])\n",
        "# raise Exception('STOP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31865"
            ]
          },
          "execution_count": 723,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "# call garbage collector to free up memory\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjF3Cif5zr1p"
      },
      "source": [
        "## Subset features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--hCfGHKZK98"
      },
      "outputs": [],
      "source": [
        "def get_manual_selected_features(data):\n",
        "    print (\"Subsetting features...\")\n",
        "    columns_to_keep = []\n",
        "    # if USE_ATTACKTIME_PEAKSAMP:\n",
        "    #     columns_to_keep.append(\"attackTime_peaksamp\")\n",
        "    # if USE_ATTACKTIME_ATTACKSTARTIDX:\n",
        "    #     columns_to_keep.append(\"attackTime_attackStartIdx\")\n",
        "    if USE_ATTACKTIME_VALUE:\n",
        "        columns_to_keep.append(\"attackTime_value\")\n",
        "    if USE_BARKSPECBRIGHTNESS:\n",
        "        columns_to_keep.append(\"barkSpecBrightness\")\n",
        "    if USE_PEAKSAMPLE_VALUE:\n",
        "        columns_to_keep.append(\"peakSample_value\")\n",
        "    # if USE_PEAKSAMPLE_INDEX:\n",
        "    #     columns_to_keep.append(\"peakSample_index\")\n",
        "    if USE_ZEROCROSSING:\n",
        "        columns_to_keep.append(\"zeroCrossing\")\n",
        "\n",
        "    assert USE_BARKSPEC <= 50 and USE_BARKSPEC >= 0 and USE_BFCC <= 49 and USE_BFCC >= 0 and USE_CEPSTRUM <= 353 and USE_CEPSTRUM >= 0 and USE_MFCC <= 37 and USE_MFCC >= 0\n",
        "\n",
        "    if USE_BARKSPEC > 0:\n",
        "        columns_to_keep += ['barkSpec_'+str(i+1) for i in range(USE_BARKSPEC)]\n",
        "    if USE_BFCC > 0:\n",
        "        columns_to_keep += ['bfcc_'+str(i+2) for i in range(USE_BFCC)]  # +2 is correct here since we want to skip the first normalized coefficient\n",
        "    if USE_CEPSTRUM > 0:\n",
        "        columns_to_keep += ['cepstrum_'+str(i+1) for i in range(USE_CEPSTRUM)]\n",
        "    if USE_MFCC > 0:\n",
        "        columns_to_keep += ['mfcc_'+str(i+2) for i in range(USE_MFCC)]  # +2 is correct here since we want to skip the first normalized coefficient\n",
        "\n",
        "    return columns_to_keep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agcUWSWVbokS"
      },
      "outputs": [],
      "source": [
        "# # To Compeltely reset RelieFF cache\n",
        "# with open(RELIEF_CACHE_FILEPATH, 'wb') as rcf:\n",
        "#     pickle.dump(set(), rcf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBDXJV0dnx2W"
      },
      "outputs": [],
      "source": [
        "# how_many_examples_per_class =10\n",
        "# subselection = list(range(0,how_many_examples_per_class))+\\\n",
        "#                list(range(600,600+how_many_examples_per_class))+\\\n",
        "#                list(range(1100,1100+how_many_examples_per_class))+\\\n",
        "#                list(range(1400,1400+how_many_examples_per_class))+\\\n",
        "#                list(range(1900,1900+how_many_examples_per_class))+\\\n",
        "#                list(range(3000,3000+how_many_examples_per_class))+\\\n",
        "#                list(range(9000,9000+how_many_examples_per_class))+\\\n",
        "#                list(range(14000,14000+how_many_examples_per_class))\n",
        "\n",
        "# testprova_dataset_features = original_dataset_features.iloc[subselection]\n",
        "# testprova_dataset_labels = dataset_labels.iloc[subselection]\n",
        "import os, platform, subprocess, re\n",
        "\n",
        "def get_processor_name():\n",
        "    if platform.system() == \"Windows\":\n",
        "        return platform.processor()\n",
        "    elif platform.system() == \"Darwin\":\n",
        "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin'\n",
        "        command =\"sysctl -n machdep.cpu.brand_string\"\n",
        "        return subprocess.check_output(command).strip()\n",
        "    elif platform.system() == \"Linux\":\n",
        "        command = \"cat /proc/cpuinfo\"\n",
        "        all_info = subprocess.check_output(command, shell=True).decode().strip()\n",
        "        for line in all_info.split(\"\\n\"):\n",
        "            if \"model name\" in line:\n",
        "                return re.sub( \".*model name.*:\", \"\", line,1)\n",
        "    return \"\"\n",
        "\n",
        "class ReliefCacheElem(dict):\n",
        "\n",
        "    PRINT_HASH = False\n",
        "\n",
        "    def __init__(self,dataset_sha256,n_neighbors,relieff_top_features,relieff_feature_importances,time_of_computation):\n",
        "        self.dataset_sha256 = dataset_sha256\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.relieff_top_features = relieff_top_features\n",
        "        self.relieff_feature_importances = relieff_feature_importances\n",
        "        self.date = strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
        "\n",
        "        self.cpu_info = get_processor_name()\n",
        "        self.time_of_computation = time_of_computation\n",
        "\n",
        "    def __key(self):\n",
        "        return tuple([self.dataset_sha256,\n",
        "                     self.n_neighbors,\n",
        "                     str(self.relieff_top_features),\n",
        "                     str(self.relieff_feature_importances)])\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.__key())\n",
        "\n",
        "    def __str__(self):\n",
        "        res = '{date: '+self.date+', n_neighbors:'+str(self.n_neighbors)\n",
        "        \n",
        "        if self.PRINT_HASH:\n",
        "            res += 'dataset_sha256:'+str(self.dataset_sha256)+','\n",
        "\n",
        "        res += 'cpu_info:'+str(self.cpu_info)+','\n",
        "        res += 'time_of_computation:'+str(self.time_of_computation)+','\n",
        "        res += '}'\n",
        "        return res\n",
        "\n",
        "def relieff_selection(X:list,y:list,n_features,n_neighbors,relief_cache_filepath,verbose_ = True):\n",
        "    relief_data_X = X\n",
        "    relief_data_y = y\n",
        "    # First check if result is already cached\n",
        "    ## Load Cache\n",
        "    relief_cache = None\n",
        "\n",
        "    ##----------------------------------------------##\n",
        "    if not os.path.exists(relief_cache_filepath):\n",
        "        raise Exception(\"RELIEF CACHE NOT FOUND at '\"+relief_cache_filepath+\"'! Comment exception to create empty cache\")\n",
        "        with open(relief_cache_filepath, 'wb') as rcf:\n",
        "            pickle.dump(set(), rcf)\n",
        "    ##----------------------------------------------##\n",
        "\n",
        "    with open(relief_cache_filepath,'rb') as rcf:\n",
        "        relief_cache = pickle.load(rcf)\n",
        "        if verbose_: \n",
        "            print('Loaded Relief cache ('+str(len(relief_cache))+' solutions)')\n",
        "    # Check if present\n",
        "    for cache_elem in relief_cache:\n",
        "        if cache_elem.dataset_sha256 == dataset_sha256_hash and\\\n",
        "           cache_elem.n_neighbors == n_neighbors:\n",
        "            if verbose_:\n",
        "                print(\"Result found in cache!\")\n",
        "            return cache_elem.relieff_top_features[:n_features]\n",
        "    \n",
        "    # If not present, compute\n",
        "    if verbose_:\n",
        "        print(\"Result NOT found in cache, computing now... (might take a long while)\")\n",
        "    \n",
        "    from skrebate import ReliefF\n",
        "    r = ReliefF(n_neighbors=n_neighbors,verbose=verbose_)\n",
        "    \n",
        "    start_fit = time()\n",
        "    r.fit(X=relief_data_X,y=relief_data_y)\n",
        "    top_features = r.top_features_\n",
        "    feature_importances = r.feature_importances_\n",
        "    stop_fit = time()\n",
        "\n",
        "    if verbose_:\n",
        "        print(\"Done. Now storing in cache...\")\n",
        "\n",
        "    savedata = ReliefCacheElem(\n",
        "        dataset_sha256 = dataset_sha256_hash,\n",
        "        n_neighbors = n_neighbors,\n",
        "        relieff_top_features = top_features,\n",
        "        relieff_feature_importances = feature_importances,\n",
        "        time_of_computation = stop_fit - start_fit)\n",
        "    relief_cache.add(savedata)\n",
        "    with open(relief_cache_filepath, 'wb') as rcf:\n",
        "        pickle.dump(relief_cache, rcf)\n",
        "\n",
        "    if verbose_:\n",
        "        print(\"Done.\")\n",
        "\n",
        "    return top_features[:n_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oas8vnnMQ0uP"
      },
      "outputs": [],
      "source": [
        "if FEATURE_SELECTION == FeatureSelection.AUTO_RELIEF:\n",
        "    with open(RELIEF_CACHE_FILEPATH,'rb') as rcf:\n",
        "        relief_cache = pickle.load(rcf)\n",
        "        print(len(relief_cache),'cached relief runs:')\n",
        "\n",
        "        if len(relief_cache) != 0:\n",
        "            samedataset = [e for e in relief_cache if e.dataset_sha256 == dataset_sha256_hash]\n",
        "            print('('+str(len(samedataset))+'/'+str(len(relief_cache)), 'are from the same dataset)')\n",
        "            if len(samedataset) != len(relief_cache):\n",
        "                raise Exception('Some of the cached results are from a different dataset!')\n",
        "            for i,e in enumerate(relief_cache):\n",
        "                print(i,':',e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVkiDFjjztbM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features reduced automatically (FeatureSelection.NONE) from 495 to : 495\n"
          ]
        }
      ],
      "source": [
        "if args['features'] == 'all':\n",
        "    FEATURE_SELECTION = FeatureSelection.NONE\n",
        "    AUTO_FEATURE_NUMBER = len(original_dataset_features.columns)\n",
        "    print\n",
        "else:\n",
        "    AUTO_FEATURE_NUMBER = args['features']    # If FEATURE_SELECTION is AUTO_ANOVA or AUTO_RELIEF, select this number of features automatically\n",
        "\n",
        "assert AUTO_FEATURE_NUMBER > 0, 'Number of features must be > 0'\n",
        "assert AUTO_FEATURE_NUMBER <= len(original_dataset_features.columns), 'Number of features is bigger than the number of columns in dataset ({} > {})'.format(AUTO_FEATURE_NUMBER,len(original_dataset_features.columns))\n",
        "\n",
        "if FEATURE_SELECTION != FeatureSelection.NONE and DO_NORMALIZE_FOR_FEATURE_SELECTION:\n",
        "    print('Normalizing data for feature selection...')\n",
        "    feature_dataset_for_selection = original_dataset_features.to_numpy()\n",
        "    feature_dataset_for_selection = SCALER_TO_USE.fit_transform(feature_dataset_for_selection)\n",
        "    # print('example row' + str(feature_dataset_for_selection[0]))\n",
        "    (relief_data_X,relief_data_y) = (feature_dataset_for_selection,dataset_labels.values.ravel())\n",
        "    print('Done.')\n",
        "else:\n",
        "    feature_dataset_for_selection = original_dataset_features.to_numpy()\n",
        "    (relief_data_X,relief_data_y) = (original_dataset_features.values,dataset_labels.values.ravel())\n",
        "\n",
        "\n",
        "if FEATURE_SELECTION == FeatureSelection.NONE:\n",
        "    selected_features = original_dataset_features.columns\n",
        "elif FEATURE_SELECTION == FeatureSelection.MANUAL_VARIABLES:\n",
        "    ''' Features '''\n",
        "    USE_ATTACKTIME_VALUE = True\n",
        "    USE_BARKSPECBRIGHTNESS = True\n",
        "    USE_PEAKSAMPLE_VALUE = True\n",
        "    USE_ZEROCROSSING = False\n",
        "\n",
        "    USE_BARKSPEC = 40 # Number in range [0-50]\n",
        "    USE_BFCC = 40     # Number in range [0-50]\n",
        "    USE_CEPSTRUM = 60 # Number in range [0-353]\n",
        "    USE_MFCC = 30     # Number in range [0-38]\n",
        "\n",
        "    selected_features = get_manual_selected_features(original_dataset_features)\n",
        "elif FEATURE_SELECTION == FeatureSelection.MANUAL_LIST:\n",
        "    selected_features = ['attackTime_value', 'barkSpecBrightness', 'barkSpec_1', 'barkSpec_2', 'barkSpec_3', 'barkSpec_4', 'barkSpec_5', 'barkSpec_6', 'barkSpec_7', 'barkSpec_8', 'barkSpec_9', 'barkSpec_10', 'barkSpec_11', 'barkSpec_12', 'barkSpec_13', 'barkSpec_14', 'barkSpec_15', 'barkSpec_16', 'barkSpec_17', 'barkSpec_18', 'barkSpec_19', 'barkSpec_20', 'barkSpec_21', 'barkSpec_22', 'barkSpec_23', 'barkSpec_24', 'barkSpec_25', 'barkSpec_26', 'barkSpec_27', 'barkSpec_28', 'barkSpec_29', 'barkSpec_30', 'barkSpec_31', 'barkSpec_32', 'barkSpec_33', 'barkSpec_34', 'barkSpec_35', 'barkSpec_36', 'barkSpec_37', 'barkSpec_38', 'barkSpec_39', 'barkSpec_40', 'barkSpec_41', 'barkSpec_42', 'barkSpec_43', 'barkSpec_44', 'barkSpec_45', 'barkSpec_46', 'barkSpec_47', 'barkSpec_48', 'barkSpec_49', 'barkSpec_50', 'bfcc_2', 'bfcc_3', 'bfcc_4', 'bfcc_5', 'bfcc_6', 'bfcc_7', 'bfcc_8', 'bfcc_9', 'bfcc_10', 'bfcc_11', 'bfcc_12', 'bfcc_13', 'bfcc_15', 'bfcc_16', 'bfcc_17', 'bfcc_18', 'bfcc_19', 'bfcc_20', 'bfcc_21', 'bfcc_25', 'bfcc_26', 'bfcc_27', 'bfcc_28', 'bfcc_29', 'bfcc_30', 'bfcc_31', 'bfcc_35', 'bfcc_36', 'bfcc_37', 'bfcc_39', 'bfcc_40', 'bfcc_42', 'bfcc_43', 'bfcc_44', 'bfcc_45', 'bfcc_46', 'bfcc_48', 'cepstrum_1', 'cepstrum_2', 'cepstrum_3', 'cepstrum_4', 'cepstrum_5', 'cepstrum_6', 'cepstrum_7', 'cepstrum_8', 'cepstrum_9', 'cepstrum_10', 'cepstrum_11', 'cepstrum_12', 'cepstrum_13', 'cepstrum_14', 'cepstrum_15', 'cepstrum_16', 'cepstrum_17', 'cepstrum_18', 'cepstrum_19', 'cepstrum_20', 'cepstrum_21', 'cepstrum_22', 'cepstrum_23', 'cepstrum_24', 'cepstrum_25', 'cepstrum_26', 'cepstrum_27', 'cepstrum_28', 'cepstrum_29', 'cepstrum_30', 'cepstrum_31', 'cepstrum_32', 'cepstrum_33', 'cepstrum_34', 'cepstrum_35', 'cepstrum_36', 'cepstrum_37', 'cepstrum_41', 'cepstrum_42', 'cepstrum_43', 'cepstrum_44', 'cepstrum_45', 'cepstrum_46', 'cepstrum_47', 'cepstrum_48', 'cepstrum_49', 'cepstrum_54', 'cepstrum_56', 'cepstrum_59', 'cepstrum_60', 'cepstrum_67', 'cepstrum_72', 'cepstrum_86', 'cepstrum_87', 'cepstrum_108', 'cepstrum_164', 'cepstrum_205', 'cepstrum_206', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'mfcc_14', 'mfcc_15', 'mfcc_16', 'mfcc_17', 'mfcc_18', 'mfcc_19', 'mfcc_20', 'mfcc_21', 'mfcc_22', 'mfcc_23', 'mfcc_24', 'mfcc_25', 'mfcc_26', 'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36', 'peakSample_value', 'zeroCrossing']\n",
        "elif FEATURE_SELECTION == FeatureSelection.AUTO_ANOVA:\n",
        "    if original_dataset_features.shape[1] != original_feature_number:\n",
        "        raise ValueError(\"ERROR: please import dataset again since you are trying to subset an already processed feature set (\"+str(dataset_features.shape[1])+\"<\"+str(original_feature_number)+\")\")\n",
        "\n",
        "    # ANOVA feature selection for numeric input and categorical output (https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/#:~:text=Feature%20selection%20is%20the%20process,the%20performance%20of%20the%20model)\n",
        "    from sklearn.feature_selection import SelectKBest\n",
        "    from sklearn.feature_selection import f_classif\n",
        "    \n",
        "    fs = SelectKBest(score_func=f_classif, k=AUTO_FEATURE_NUMBER) # Define feature selection\n",
        "    X_selected = fs.fit_transform(feature_dataset_for_selection, dataset_labels.to_numpy().ravel())                         # Apply feature selection\n",
        "    support = fs.get_support(indices=True)                      # Extract selected indexes\n",
        "    selected_features = original_dataset_features.columns[support].tolist()\n",
        "    print(str(AUTO_FEATURE_NUMBER)+\" best features:\" + str(selected_features))\n",
        "elif FEATURE_SELECTION == FeatureSelection.AUTO_RELIEF:\n",
        "    support = relieff_selection(relief_data_X,relief_data_y,AUTO_FEATURE_NUMBER,n_neighbors=5,relief_cache_filepath=RELIEF_CACHE_FILEPATH,verbose_= True)\n",
        "    selected_features = original_dataset_features.columns[support].tolist()\n",
        "    print(str(AUTO_FEATURE_NUMBER)+\" best features:\" + str(selected_features))\n",
        "else:\n",
        "    raise Exception(\"ERROR! This type of feature selection is not supported\")\n",
        "\n",
        "dataset_features = original_dataset_features.copy().loc[:,selected_features]\n",
        "if USE_AUGMENTED_DATA:\n",
        "    features_aug = features_aug.copy().loc[:,selected_features]\n",
        "print(\"Features reduced \"+('manually' if (FEATURE_SELECTION == FeatureSelection.MANUAL_LIST or FEATURE_SELECTION == FeatureSelection.MANUAL_VARIABLES) else 'automatically')+\" (\"+str(FEATURE_SELECTION)+\") from \"+str(original_feature_number)+\" to : \"+str(dataset_features.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxb5oNdswky3"
      },
      "source": [
        "## Evaluate class support\n",
        "(What percentage of dataset entries represent each class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOwPsK_h5r3q"
      },
      "outputs": [],
      "source": [
        "DO_PRINT_SUPPORT = False\n",
        "def printSupport (labels_ds):\n",
        "    binc = np.bincount(np.reshape(labels_ds,labels_ds.size))\n",
        "    for i in range(binc.size):\n",
        "        print(\"Class \" + str(i) + \" support: \" + str(\"{:.2f}\".format(binc[i]/sum(binc) * 100)) + \"%\")\n",
        "        \n",
        "if DO_PRINT_SUPPORT:\n",
        "    printSupport(dataset_labels.to_numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w196aHu6YqnH"
      },
      "source": [
        "# Define model architecture,\n",
        "Loss, optimizer and compile model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class CustomNetwork():\n",
        "#     def __init__(self, number_of_conv:int, filters_per_conv:list, kernel_sizes_per_conv:list, \n",
        "#                  pool_layers:list, pool_sizes_per_conv:list, \n",
        "#                  number_of_dense:int, dense_units:list, dropout_rates:list, activations:list, \n",
        "#                  batchnorm_after_layer:list,\n",
        "#                  input_shape:list, output_shape:int):\n",
        "#         self.number_of_conv = number_of_conv\n",
        "#         self.filters_per_conv = filters_per_conv\n",
        "#         assert len(self.filters_per_conv) == self.number_of_conv\n",
        "#         self.kernel_sizes_per_conv = kernel_sizes_per_conv\n",
        "#         assert len(self.kernel_sizes_per_conv) == self.number_of_conv\n",
        "#         self.pool_sizes_per_conv = pool_sizes_per_conv\n",
        "#         assert len(self.pool_sizes_per_conv) == self.number_of_conv\n",
        "#         self.pool_layers = pool_layers\n",
        "#         assert len(self.pool_layers) == self.number_of_conv\n",
        "\n",
        "#         self.number_of_dense = number_of_dense\n",
        "#         self.dense_units = dense_units\n",
        "#         assert len(self.dense_units) == self.number_of_dense\n",
        "#         self.dropout_rates = dropout_rates\n",
        "#         assert len(self.dropout_rates) == self.number_of_dense\n",
        "#         self.activations = activations\n",
        "#         assert len(self.activations) == self.number_of_dense\n",
        "\n",
        "#         self.batchnorm_after_layer = batchnorm_after_layer\n",
        "#         assert len(self.batchnorm_after_layer) == self.number_of_dense + self.number_of_conv\n",
        "\n",
        "#         self.input_shape = input_shape\n",
        "#         self.output_shape = output_shape\n",
        "\n",
        "#     def _get_conv_unit(filters:int, kernel_size:int, activation:str, pool_size:int, pool_layer:bool, batchnorm:bool, input_shape:tuple = None):\n",
        "    \n",
        "#         if input_shape is not None:\n",
        "#             res = [tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, input_shape=input_shape)]\n",
        "#         else:\n",
        "#             res = [tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation=activation)]\n",
        "\n",
        "#         res += [tf.keras.layers.BatchNormalization(),  \n",
        "#                 tf.keras.layers.MaxPooling1D(pool_size=2)]\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Be14IPJTg_4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:14: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:14: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "/tmp/ipykernel_513425/1519820083.py:14: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if POOL_LAYERS[i] is not 'N':\n",
            "/tmp/ipykernel_513425/1519820083.py:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if POOL_LAYERS[i] is 'M':\n",
            "/tmp/ipykernel_513425/1519820083.py:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif POOL_LAYERS[i] is 'A':\n"
          ]
        }
      ],
      "source": [
        "def define_model_architecture(num_classes:int, _verbose = False):\n",
        "    tf.keras.backend.set_floatx('float32')\n",
        "\n",
        "    sequential_structure = []\n",
        "    if args['conv1d'] > 0:\n",
        "        for i in range(args['conv1d']):\n",
        "            if i == 0:\n",
        "                sequential_structure.append(tf.keras.layers.Conv1D(filters=FILTERS[i], kernel_size=KERNEL_SIZES[i], strides=STRIDES[i], activation=CONV_ACTIVATIONS[i], input_shape=(AUTO_FEATURE_NUMBER,1)))\n",
        "            else:\n",
        "                sequential_structure.append(tf.keras.layers.Conv1D(filters=FILTERS[i], kernel_size=KERNEL_SIZES[i], strides=STRIDES[i], activation=CONV_ACTIVATIONS[i]))\n",
        "            \n",
        "            sequential_structure += [tf.keras.layers.BatchNormalization()]\n",
        "\n",
        "            if POOL_LAYERS[i] is not 'N':\n",
        "                if POOL_LAYERS[i] is 'M':\n",
        "                    sequential_structure += [tf.keras.layers.MaxPooling1D(pool_size=POOL_SIZES[i])]\n",
        "                elif POOL_LAYERS[i] is 'A':\n",
        "                    sequential_structure += [tf.keras.layers.AveragePooling1D(pool_size=POOL_SIZES[i])]\n",
        "\n",
        "        sequential_structure += [tf.keras.layers.Flatten(),\n",
        "                                 tf.keras.layers.Dropout(args['dropout'])]\n",
        "\n",
        "    for i in range(args['net_depth']):\n",
        "        sequential_structure += [tf.keras.layers.Dense(args['net_width'],activation='relu',\n",
        "                                                       kernel_initializer='he_uniform'),    #   X   |           |         |\n",
        "                                 tf.keras.layers.BatchNormalization(),                      #       |     X     |         |\n",
        "                                 tf.keras.layers.Dropout(args['dropout'])                   #       |           |    X    |\n",
        "                                ]\n",
        "\n",
        "    sequential_structure += [tf.keras.layers.Dense(num_classes)]               \n",
        "\n",
        "    model = tf.keras.models.Sequential(sequential_structure)\n",
        "\n",
        "    model._name = \"guitar_timbre_classifier_\" + strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "    # tf.keras.utils.vis_utils.plot_model(model, show_shapes=True, show_layer_names=True)\n",
        "    # TODO:fix\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_loss():\n",
        "    return tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "PREVIEW_MODEL = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "# import tf.keras.backend as K\n",
        "from tensorflow.keras import backend as K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kOMPQBTXVXb"
      },
      "outputs": [],
      "source": [
        "def compile_model(model,optimizer,loss_fn,_verbose = False):\n",
        "    opt = None\n",
        "    if optimizer[\"method\"] == \"sgd\":\n",
        "        opt = tf.keras.optimizers.SGD(learning_rate = optimizer[\"learning_rate\"], momentum=optimizer[\"momentum\"])\n",
        "    elif optimizer[\"method\"] == \"adam\":\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate = optimizer[\"learning_rate\"])\n",
        "    else:\n",
        "        raise Exception(\"Optimizer method not supported\")\n",
        "\n",
        "    def recall(y_true, y_pred, c):\n",
        "        y_true = K.flatten(y_true)\n",
        "        pred_c = K.cast(K.equal(K.argmax(y_pred, axis=-1), c), K.floatx())\n",
        "        true_c = K.cast(K.equal(y_true, c), K.floatx())\n",
        "        true_positives = K.sum(pred_c * true_c)\n",
        "        possible_postives = K.sum(true_c)\n",
        "        return true_positives / (possible_postives + K.epsilon())\n",
        "\n",
        "\n",
        "    def precision(y_true, y_pred, c):\n",
        "        y_true = K.flatten(y_true)\n",
        "        pred_c = K.cast(K.equal(K.argmax(y_pred, axis=-1), c), K.floatx())\n",
        "        true_c = K.cast(K.equal(y_true, c), K.floatx())\n",
        "        true_positives = K.sum(pred_c * true_c)\n",
        "        pred_positives = K.sum(pred_c)\n",
        "        return true_positives / (pred_positives + K.epsilon())\n",
        "\n",
        "    def recall_class(theclass:int):\n",
        "        funk = lambda y_true, y_pred: recall(y_true, y_pred, theclass)\n",
        "        funk.__name__ = 'recall_c' + str(theclass)\n",
        "        return funk\n",
        "\n",
        "    # model.compile(optimizer=opt,\n",
        "    #               loss=loss_fn,\n",
        "    #               metrics=['accuracy',\n",
        "    #                         recall_class(0),\n",
        "    #                         recall_class(1),\n",
        "    #                         recall_class(2),\n",
        "    #                         recall_class(3),\n",
        "    #                         recall_class(4),\n",
        "    #                         recall_class(5),\n",
        "    #                         recall_class(6),\n",
        "    #                         recall_class(7)])\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss=loss_fn,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    #----------------------------------------------------------#\n",
        "    # Why did we not add here a custom metric for F1-SCORE?    #\n",
        "    # In particular, we wanted ** Macro Average - F1-score **  #\n",
        "    # which is the (non-weighted) average of the F1-score for  #\n",
        "    # each class.                                              #\n",
        "    # Thus is a relevnt metric for our problem, since we have  #\n",
        "    # class imbalance.                                         #\n",
        "    #                                                          #\n",
        "    # The issue seems to be the way that tensorflow handles    #\n",
        "    # metric computation.                                      #\n",
        "    # The metric is computed for each batch, and then the      #\n",
        "    # average is computed.                                     #\n",
        "    # Also, custom metrics seems to require the use of tensor  #\n",
        "    # operations, and converting to numpy arrays does not seem #\n",
        "    # to be supported FOR COMPUTATIONS                         #\n",
        "    # https://stackoverflow.com/a/52659570                     #\n",
        "    # https://stackoverflow.com/a/52659570/10930862            #\n",
        "    #----------------------------------------------------------#\n",
        "    \n",
        "    if _verbose:\n",
        "        print(\"Model compiled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc66NhrugHsG"
      },
      "source": [
        "# Save Models and Info functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Vbu_AA6dhUU"
      },
      "outputs": [],
      "source": [
        "def save_model_info(model,optimizer,final_cross_validation_results,folds,metrics,outpath, fold_zerobased = None, smote_strategy = None):\n",
        "    info_filename = '/info.txt' if fold_zerobased is None else '/info_fold_'+str(fold_zerobased+1)+'.txt'\n",
        "    assert not (final_cross_validation_results and (fold_zerobased is not None))\n",
        "\n",
        "    with open(outpath + info_filename, \"w\") as f:\n",
        "        if not is_notebook():\n",
        "            f.write('Execution command:\\n')\n",
        "            f.write(\" \".join(sys_argv[:])+'\\n')\n",
        "        else:\n",
        "            f.write('Trained with the jupyter notebook (not the script version)\\n')\n",
        "        f.write(\"\\n\\n\")\n",
        "\n",
        "        if DO_OVERSAMPLING:\n",
        "            f.write(\"Oversampling (SMOTE) with aggressiveness: \"+str(OVERSAMPLING_AGGRESSIVENESS)+'\\n')\n",
        "            if smote_strategy is not None:\n",
        "                f.write(\"SMOTE strategy: \"+str(smote_strategy)+'\\n')\n",
        "            else:\n",
        "                f.write(\"SMOTE strategy: \"+str(SMOTE_STRATEGY)+')\\n')\n",
        "        else:\n",
        "            f.write('NOT performing Oversampling'+'\\n')\n",
        "\n",
        "        if USE_AUGMENTED_DATA:\n",
        "            f.write('Using augmented data'+'\\n')\n",
        "            f.write('Augmented audio file paths: ' + ','.join([os.path.basename(x) for x in augmented_data_paths])+'\\n')\n",
        "            f.write('Loaded '+str(len(augmented_featuredataset))+' augmented samples'+'\\n')\n",
        "            f.write('Used '+str(len(features_aug))+' augmented samples after filtering the dataset'+'\\n')\n",
        "\n",
        "            if fold_zerobased is not None:\n",
        "                f.write('Augmented data used in this fold: '+str(len(train_aug_indexes[fold_zerobased]))+'\\n')\n",
        "            else:\n",
        "                f.write('Augmented data used for all splits: \\n')\n",
        "                for split_idx in train_aug_indexes:\n",
        "                    f.write(str(len(train_aug_indexes[split_idx]))+'\\n')\n",
        "\n",
        "\n",
        "        f.write(\"\\n\\n\")\n",
        "\n",
        "        if fold_zerobased is not None:\n",
        "            f.write(\"FOLD [\"+str(fold_zerobased+1)+\"/\"+str(folds)+\"]\\n\\n\")\n",
        "        f.write(\"Summary:\\n\")\n",
        "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "        f.write(\"\\n\\n\")\n",
        "        f.write('Data read from file '+DATASET_FILENAME+'\\n')\n",
        "        if FEATURE_WINDOW_SIZE == FeatureWindowSize.s4800_SAMPLES_100ms:\n",
        "            f.write('Window size of 4800 samples (100ms)\\n')\n",
        "        elif FEATURE_WINDOW_SIZE == FeatureWindowSize.s704_Samples_14ms:\n",
        "            f.write('Window size of 704 samples (~14ms)\\n')\n",
        "        else:\n",
        "            raise ValueError('Invalid FeatureWindowSize \"%s\"'%FeatureWindowSize.name)\n",
        "\n",
        "        f.write(\"\\n\\n\")\n",
        "        f.write(\"+--| Features: \\n\")\n",
        "        f.write('Number of features selected: '+str(len(selected_features))+'\\n')\n",
        "        f.write('Selected features: '+str(selected_features)+'\\n')\n",
        "        f.write('Feature Selection method: '+str(FEATURE_SELECTION)+'\\n')\n",
        "        f.write(\"\\n\\n\")\n",
        "        if DO_NORMALIZE_DATA:\n",
        "            f.write(\"Data was normalized. Find the parameters at the end of the file, and the scaler in the pickle file 'scaler.pickle'\\n\")\n",
        "        else:\n",
        "            f.write(\"Data was NOT normalized\")\n",
        "        f.write(\"\\n\\n\")\n",
        "        f.write('Run arguments: '+str(args)+'\\n')\n",
        "        f.write(\"\\n\\n\")\n",
        "        f.write(\"Optimizer: \" + optimizer[\"method\"])\n",
        "        if optimizer[\"method\"] == \"sgd\":\n",
        "            f.write(\" lr: \" + str(optimizer[\"learning_rate\"]) + \" momentum: \" + str(optimizer[\"momentum\"]))\n",
        "        elif optimizer[\"method\"] == \"adam\":\n",
        "            f.write(\" lr: \" + str(optimizer[\"learning_rate\"]))\n",
        "        else:\n",
        "            assert(False) # If triggered check new optimizer and add case\n",
        "        f.write(\"\\n\\n\")\n",
        "        if final_cross_validation_results:\n",
        "            f.write(\"Trained for \" + str(args['epochs']) + \" epochs and with_batch size '\" + str(args['batchsize']) + \"'\" + \" epochs for each fold (\"+str(folds)+\"-foldCrossValidation)\\n\")\n",
        "            f.write(\"Single results in the folds directories\\n\")\n",
        "            f.write('\\n\\n-------- Average results --------\\n\\n')\n",
        "        else:\n",
        "            f.write(\"Trained for \" + str(args['epochs']) + \" epochs and with_batch size '\" + str(args['batchsize']) + \"'\" + \" epochs\\n\")\n",
        "\n",
        "            if fold_zerobased is not None:\n",
        "                f.write('(K-Fold cross validation run (fold '+str(fold_zerobased+1)+'/' +str(folds)+ '))\\n')\n",
        "            else:\n",
        "                f.write('(Single run, NO k-fold cross validation)\\n')\n",
        "\n",
        "        for metric in metrics.keys():\n",
        "            value = metrics[metric] if fold_zerobased is None else metrics[metric][fold_zerobased]\n",
        "            f.write(str(metric) + \":\\n\" + str(value) + \"\\n\\n\")\n",
        "        f.close()\n",
        "\n",
        "    # Copy Tensorboard Logs\n",
        "    if fold_zerobased == None and DO_SAVE_TENSORBOARD_LOGS:\n",
        "        LOGPATH=outpath+\"/tensorboardlogs\"\n",
        "        shutil.copytree('./logs', LOGPATH)\n",
        "\n",
        "    if not COLAB and fold_zerobased == None:\n",
        "        # Copy script or notebook depending on the execution environment\n",
        "        script_path = None\n",
        "        if is_notebook():\n",
        "            script_path = 'expressive-technique-classifier-phase3.ipynb'\n",
        "            pass #TODO: make this work\n",
        "        else:\n",
        "            script_path = os.path.realpath(__file__)\n",
        "        shutil.copyfile(script_path, os.path.join(outpath, 'backup_'+os.path.basename(script_path)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0iA0sVlINRz"
      },
      "source": [
        "# Prepare Logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTVv1XlUOgBh"
      },
      "outputs": [],
      "source": [
        "if os.path.exists('./logs'):\n",
        "    shutil.rmtree('./logs', ignore_errors=True) #Clear logs if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2NMIioKEYyP"
      },
      "outputs": [],
      "source": [
        "def start_tensorboard(tb_dir,logname):\n",
        "    log_dir = tb_dir\n",
        "    if logname is not None: \n",
        "        log_dir += logname\n",
        "    return tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "tb_dir = \"logs/fit/\"\n",
        "# %tensorboard --logdir $tb_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY1u63rqX7fn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(train_metric, validation_metric, title, xlabel, ylabel, filename=None, show = False):\n",
        "    fig, ax = plt.subplots(figsize=(5, 3))\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.plot(train_metric)\n",
        "    ax.plot(validation_metric)\n",
        "    ax.legend(['Training','Validation'])\n",
        "    if show:\n",
        "        fig.show()\n",
        "    if filename is not None:\n",
        "        plt.savefig(filename+\".pdf\",bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qExZCK5ipvaa"
      },
      "source": [
        "F1-Score on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hBHvhH2punc"
      },
      "outputs": [],
      "source": [
        "def macroweighted_f1(y_true,y_pred):\n",
        "    f1scores = []\n",
        "    numSamples = []\n",
        "    for selclass in CLASSES:\n",
        "        classSelection = (y_true == (np.ones(np.shape(y_true)[0])*selclass))\n",
        "        numSamples.append(sum(classSelection))\n",
        "        classPrediction = (y_pred == (np.ones(np.shape(y_true)[0])*selclass))\n",
        "        true_positives = np.sum(np.logical_and(classSelection,(y_true == y_pred)))\n",
        "\n",
        "        precision = 1.0 * true_positives / np.sum(classPrediction)\n",
        "        recall = 1.0 * true_positives / np.sum(classSelection)\n",
        "        f1score = 2 /((1/precision)+(1/recall))\n",
        "        f1scores.append(f1score)\n",
        "    macroWeightedF1 = sum(np.array(f1scores) * np.array(numSamples)) / sum(numSamples)\n",
        "    return macroWeightedF1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SQi2z0Hw2Km"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_pred,_verbose = False):\n",
        "    accuracy = np.sum(y_pred == y_true)/np.shape(y_true)[0]\n",
        "    f1mw = macroweighted_f1(y_true,y_pred)\n",
        "    confusion_matrix = sk_conf_matrix(y_true, y_pred)\n",
        "    \n",
        "    assert len(y_true) == len(y_pred), 'The \"y_true\" and \"y_pred\" arrays have a different length' \n",
        "\n",
        "    assert len(np.unique(y_true)) >= len(np.unique(y_pred)) \n",
        "    assert np.isin(np.unique(y_pred),np.unique(y_true)).all(), 'Some classes in y_pred are not in y_true ('+str(np.setdiff1d(y_pred,y_true))+')'\n",
        "    \n",
        "    classification_report = sk_class_report(y_true, y_pred, digits=6,target_names = CLASSES_DESC.values(),output_dict=True)\n",
        "    printable_classification_report = sk_class_report(y_true, y_pred, digits=4,target_names = CLASSES_DESC.values())\n",
        "\n",
        "    if _verbose:\n",
        "        print(\"Test Accuracy: \" + str(accuracy) + \"\\nTest macro_weighted_avg f1-score: \" + str(f1mw)+'\\n'+str(confusion_matrix)+'\\n'+str(printable_classification_report))\n",
        "\n",
        "    return accuracy, f1mw, confusion_matrix, classification_report, printable_classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEGBYnUF1vXn"
      },
      "source": [
        "# Prepare TFLite conversion and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAvtjWCwxx1I"
      },
      "outputs": [],
      "source": [
        "# TFLite conversion function\n",
        "def convert2tflite(tf_model_dir,tflite_model_dir = None,model_name=\"model\",quantization=None,dataset=None):\n",
        "    assert (quantization==None or quantization==\"dynamic\" or quantization==\"float-fallback\" or quantization==\"full\")\n",
        "    # Convert the model saved in the previous step.\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_dir)\n",
        "    if quantization is not None:\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        if quantization == \"full\" or quantization==\"float-fallback\":\n",
        "            assert dataset is not None\n",
        "            def representative_dataset():\n",
        "                for data in tf.data.Dataset.from_tensor_slices((dataset)).batch(1).take(100):\n",
        "                    yield [tf.dtypes.cast(data, tf.float32)]\n",
        "            converter.representative_dataset = representative_dataset\n",
        "        if quantization == \"full\":\n",
        "            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "            converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "            converter.inference_output_type = tf.int8  # or tf.uint8\n",
        "        if quantization == \"dynamic\":\n",
        "            assert dataset is None\n",
        "\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the TF Lite model.\n",
        "    if tflite_model_dir is None:\n",
        "        TF_MODEL_PATH = tf_model_dir + \"/\" + model_name + '.tflite'\n",
        "    else:\n",
        "        TF_MODEL_PATH = tflite_model_dir + \"/\" + model_name + '.tflite'\n",
        "\n",
        "    with tf.io.gfile.GFile(TF_MODEL_PATH, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "## USAGE\n",
        "# model_path = MODELFOLDER + \"/\" + RUN_NAME + \"/fold_1\"\n",
        "# convert2tflite(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6wGuSE91syp"
      },
      "outputs": [],
      "source": [
        "def test_tflite_model(model_path,X_test,y_test,first_layer_is_conv,verbose_test = False):\n",
        "    tflite_interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "    input_details = tflite_interpreter.get_input_details()[0]\n",
        "    output_details = tflite_interpreter.get_output_details()[0]\n",
        "    \n",
        "    if verbose_test:\n",
        "        print(\"+--------------------------------------------+\\n| Testing the TF lite model saved            |\\n+--------------------------------------------+\\n\")\n",
        "        print(\"[Model loaded]\\n\")\n",
        "        print(\"\\n== Input details ==\\nname:\"+ str(input_details['name']) + \"\\nshape:\"+str(input_details['shape']) +  \"\\ntype:\"+str(input_details['dtype']))\n",
        "        print(\"\\n== Output details ==\\nname:\"+str(output_details['name']) + \"\\nshape:\"+str(output_details['shape']) + \"\\ntype:\"+str(output_details['dtype']))\n",
        "        print(\"+--------------------------------------------+\\n| Testing on TEST set...                     |\\n+--------------------------------------------+\\n\")\n",
        "    \n",
        "    tflite_interpreter.allocate_tensors()\n",
        "    y_pred = list()\n",
        "    for i in range(X_test.shape[0]):\n",
        "        extracted_test_sample = np.array(X_test[i:i+1]).astype(np.float32)\n",
        "        \n",
        "        # Quantize inputs if necessary (full uint model)\n",
        "        if input_details['dtype'] is np.int8:\n",
        "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "            extracted_test_sample = (extracted_test_sample / input_scale + input_zero_point).astype(np.int8)\n",
        "\n",
        "        if first_layer_is_conv:\n",
        "            input_tensor = np.expand_dims(extracted_test_sample,axis=2).astype(input_details[\"dtype\"])\n",
        "        else:\n",
        "            input_tensor = extracted_test_sample\n",
        "\n",
        "        if verbose_test:\n",
        "            print(\"Setting \"+str(input_tensor.shape)+\" \"+str(input_tensor.dtype)+\" as input\")\n",
        "\n",
        "        tflite_interpreter.set_tensor(input_details['index'], input_tensor)\n",
        "        tflite_interpreter.invoke()\n",
        "        prediction_vec = tflite_interpreter.get_tensor(output_details['index'])\n",
        "\n",
        "        if verbose_test:\n",
        "            print(\"Getting \"+str(prediction_vec.shape)+\" \"+str(prediction_vec.dtype)+\" as output\")\n",
        "\n",
        "        if output_details['dtype'] is np.int8:\n",
        "            output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "            prediction_vec = (prediction_vec + output_zero_point) * output_scale\n",
        "\n",
        "        if verbose_test:\n",
        "            print(prediction_vec)\n",
        "        y_pred.append(np.argmax(prediction_vec))\n",
        "    return y_pred\n",
        "\n",
        "def test_regulartf_model(model_path,X_test,y_test,first_layer_is_conv,verbose_test = False):\n",
        "    imported = tf.keras.models.load_model(model_path)\n",
        "    if first_layer_is_conv:\n",
        "        test_set = np.expand_dims(X_test,axis=2)\n",
        "    else:\n",
        "        test_set = X_test\n",
        "    _, accuracy = imported.evaluate(test_set,  y_test, verbose=2)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkPVrRtLoxvu"
      },
      "source": [
        "# k-Fold Cross Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISgdGWqRFkMt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using training epochs:  120\n",
            "Using batch size:  1024\n"
          ]
        }
      ],
      "source": [
        "# --> Epochs / Batches\n",
        "print('Using training epochs: ', args['epochs'])\n",
        "print('Using batch size: ', args['batchsize'])\n",
        "\n",
        "# --> Quantize (Dynamic) and test the TF Lite model obtained (quicker but lower accuracy)\n",
        "TEST_QUANTIZATION = False\n",
        "# --> Early Stopping\n",
        "use_early_stopping = False\n",
        "\n",
        "# --> OVERSAMPLING ################################################\n",
        "DO_OVERSAMPLING = args['oversampling']                            #\n",
        "OVERSAMPLING_AGGRESSIVENESS = args['oversampling_aggressiveness'] #\n",
        "VERBOSE_OVERSAMPLING = False                                      #\n",
        "SMOTE_STRATEGY = {} # Do not set this variable\n",
        "###################################################################\n",
        "\n",
        "# --> KFOLD RUN #################################################\n",
        "K_SPLITS = args['k_folds']\n",
        "USE_CROSS_VALIDATION = K_SPLITS > 1 # Activate K-Fold Cross Validation only if K_SPLITS > 1\n",
        "VAL_SPLIT_SIZE = 0.1                                            # percentage of total entries going into the validation set\n",
        "# TODO: this is something to fix.\n",
        "# For the custom splitter that keeps guitarists separate, there\n",
        "# is the need to take the validation set from the test and not \n",
        "# the train set. To do this we now have two percentages.\n",
        "# TODO: change all code to always take the validation percentage\n",
        "# from the test set, so that there can be a single percentage \n",
        "# constant.\n",
        "VAL_SPLIT_SIZE_TESTPERC = 0.3                                   # percentage of test entries going into the validation set\n",
        "random_state = global_random_state                              # seed for pseudo random generator\n",
        "#################################################################\n",
        "\n",
        "# --> SINGLE RUN ################################################\n",
        "SAVE_MODEL_INFO = True                                          #\n",
        "test_split_size = 0.2                                           #\n",
        "#################################################################\n",
        "\n",
        "DO_TEST = False\n",
        "\n",
        "# optimizer = { \"method\" : \"sgd\", \"learning_rate\" : args['learning_rate'], \"momentum\" : 0.7 }\n",
        "optimizer = { \"method\" : \"adam\", \"learning_rate\" : args['learning_rate'] }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGkWC3hVoiz-"
      },
      "outputs": [],
      "source": [
        "def player_stats(metadata,exclude_extra_500 = False):\n",
        "    # metadata = metadata[metadata['meta_audiofilePath'].str.contains('500')]\n",
        "    if exclude_extra_500:\n",
        "        metadata = metadata[~metadata['meta_audiofilePath'].str.contains('500')]\n",
        "    players_meta_list = [re.findall('[A-Z][a-z][a-z][A-Z][a-z][a-z][0-2]?',el) for el in metadata['meta_audiofilePath']]\n",
        "    players_meta_list = [el[0] for el in players_meta_list]\n",
        "    players = np.unique(players_meta_list).tolist()\n",
        "\n",
        "    print(len(players),'players in the dataset')\n",
        "\n",
        "    for pix, p in enumerate(players):\n",
        "        print(str(pix+1)+' - Player \"'+p+'\" \\thas '+str(players_meta_list.count(p))+' note entries',end='')\n",
        "\n",
        "        # p_records = [el for el in metadata if '_'+p+'_' in metadata['meta_audiofilePath']]\n",
        "\n",
        "        p_records = metadata[metadata['meta_audiofilePath'].str.contains('_'+p+'_')]\n",
        "        assert len(p_records) == players_meta_list.count(p)\n",
        "        count_for_each_tech = p_records.groupby(\"meta_expressive_technique_id\")[\"meta_audiofilePath\"].count().to_dict()\n",
        "        print('  ',''.join([str(a)+':'+(' '*(4-len(str(b))))+str(b)+'  \\t' for a,b in count_for_each_tech.items()]))\n",
        "\n",
        "    tot_count_for_each_tech = metadata.groupby(\"meta_expressive_technique_id\")[\"meta_audiofilePath\"].count().to_dict()\n",
        "    print('_'*170)\n",
        "    print('                                          Tot: ',''.join([str(a)+':'+(' '*(4-len(str(b))))+str(b)+'  \\t' for a,b in tot_count_for_each_tech.items()]))\n",
        "\n",
        "# player_stats(dataset_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxfTUtYgg_nO"
      },
      "outputs": [],
      "source": [
        "class CustomPlayerFold():\n",
        "    def __init__(self, metadata: pd.DataFrame, features: pd.DataFrame, labels: pd.DataFrame, _val_split_size: float):\n",
        "        self.val_split_size = _val_split_size\n",
        "        self.metadata = metadata.copy()\n",
        "        self.features = features.copy()\n",
        "        self.labels = labels.copy()\n",
        "\n",
        "        assert self.metadata.shape[0] == self.features.shape[0] , str(self.metadata.shape[0]) + '!=' + str(self.features.shape[0]) \n",
        "        assert self.metadata.shape[0] == self.labels.shape[0] , str(self.metadata.shape[0]) + '!=' + str(self.labels.shape[0]) \n",
        "        assert np.max(self.metadata.index) == len(self.metadata.index)-1, 'np.max(self.metadata.index) == len(self.metadata.index)-1 ('+str(np.max(self.metadata.index))+'!='+str(len(self.metadata.index)-1)+')'\n",
        "        assert np.max(self.features.index) == len(self.features.index)-1, 'np.max(self.features.index) == len(self.features.index)-1 ('+str(np.max(self.features.index))+'!='+str(len(self.features.index)-1)+')'\n",
        "        assert np.max(self.labels.index) == len(self.labels.index)-1, 'np.max(self.labels.index) == len(self.labels.index)-1 ('+str(np.max(self.labels.index))+'!='+str(len(self.labels.index)-1)+')'\n",
        "\n",
        "        players_meta_list = [re.findall('[A-Z][a-z][a-z][A-Z][a-z][a-z][0-2]?',el)[0] for el in metadata['meta_audiofilePath']]\n",
        "        self.players = np.unique(players_meta_list).tolist()\n",
        "        self.k_splits = len(self.players)\n",
        "\n",
        "        # player_stats(metadata)\n",
        "\n",
        "    def get_k_splits(self,):\n",
        "        return self.k_splits\n",
        "\n",
        "    def split(self,_X,_y):\n",
        "        res = []\n",
        "\n",
        "        assert (_X == self.features.to_numpy()).all()\n",
        "        assert (_y == self.labels.to_numpy()).all()\n",
        "\n",
        "        for player in self.players:\n",
        "            p_records = self.metadata[self.metadata['meta_audiofilePath'].str.contains('_'+player+'_')]\n",
        "            not_p_records = self.metadata[~self.metadata['meta_audiofilePath'].str.contains('_'+player+'_')]\n",
        "\n",
        "            train_idx = not_p_records.index.values\n",
        "            test_idx = p_records.index.values\n",
        "\n",
        "            # print('test_idx',test_idx)\n",
        "            # print('len(test_idx)',len(test_idx))\n",
        "\n",
        "            stratify_labels = p_records['meta_expressive_technique_id'].tolist()\n",
        "            \n",
        "            # In this case, we want to take the validation split from the TEST split,\n",
        "            # unlike all the other cases where we take it from the test set.\n",
        "            # This is because we want the validation results to highlight GENERALIZATION.\n",
        "            # So we split the test and validation indexes here\n",
        "\n",
        "            # To keep things somewhat consistent, we take 'val_split_size', which is supposed to be a percentage of the train set, and convert it so that it is the same number of samples, when extracted from the test set\n",
        "            # new_valsplit_perc = self.val_split_size * len(train_idx) / len(test_idx)\n",
        "            # print('val_split_size:',self.val_split_size)\n",
        "            # print('len(train_idx):',len(train_idx))\n",
        "            # print('len(test_idx):', len(test_idx))\n",
        "            # assert new_valsplit_perc <= 1.0, 'new_valsplit_perc > 1.0 ('+str(new_valsplit_perc)+')'\n",
        "            # assert new_valsplit_perc >= 0.0, 'new_valsplit_perc < 0.0 ('+str(new_valsplit_perc)+')'\n",
        "\n",
        "            test_idx,val_idx = train_test_split(test_idx,test_size=self.val_split_size,random_state=random_state, shuffle=True, stratify = stratify_labels)\n",
        "\n",
        "            # print('len(val_idx)/(len(val_idx)+len(test_idx))',len(val_idx)/(len(val_idx)+len(test_idx)))\n",
        "            # print()\n",
        "\n",
        "            # print('len(val_idx)',len(val_idx))\n",
        "            # print('len(test_idx)',len(test_idx))\n",
        "            \n",
        "            # print()\n",
        "            # print()\n",
        "\n",
        "\n",
        "            assert type(train_idx) == type(val_idx) == type(test_idx)\n",
        "            assert np.all(train_idx < len(self.labels))\n",
        "            assert np.all(val_idx < len(self.labels))\n",
        "            assert np.all(test_idx < len(self.labels))\n",
        "            assert np.array_equal(np.unique(train_idx),sorted(train_idx))\n",
        "            assert np.array_equal(np.unique(test_idx),sorted(test_idx))\n",
        "            assert np.array_equal(np.unique(val_idx),sorted(val_idx))\n",
        "\n",
        "            res.append((train_idx,test_idx,val_idx))\n",
        "\n",
        "            players_intest = np.unique([re.findall(r'_([A-Z][a-z][a-z][A-Z][a-z][a-z][0-9]?)_',dat) for dat in self.metadata.iloc[test_idx]['meta_audiofilePath'].tolist()])\n",
        "            assert len(players_intest) == 1, 'There should be only one player in the test set. Instead, there are '+str(len(players_intest))+' players in the test set: '+str(players_intest)\n",
        "\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1hUwlybmgEE"
      },
      "outputs": [],
      "source": [
        "def oversample(features: list, labels: list, aggressiveness = 1, verbose: bool = False):\n",
        "    if verbose:\n",
        "        print(\"Oversampling...\")\n",
        "    import warnings\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "\n",
        "        unique, counts = np.unique(labels, return_counts=True)\n",
        "        target_count = int(round(max(counts) * aggressiveness,0))\n",
        "        sampling_strategy = dict(zip(unique, counts))\n",
        "        sampling_strategy = {k:(v if v > target_count else target_count) for k,v in sampling_strategy.items()}\n",
        "        smote_strategy = sampling_strategy\n",
        "\n",
        "        print('sampling_strategy:',sampling_strategy)\n",
        "\n",
        "        ovs_features, ovs_labels = imblearn.over_sampling.SMOTE(sampling_strategy=sampling_strategy).fit_resample(features, labels)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Increased training samples from \" + str(features.shape[0]) + \" to \" + str(ovs_features.shape[0]))\n",
        "            printSupport(ovs_labels)\n",
        "    return ovs_features, ovs_labels, smote_strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy9WiiwEpHXf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"guitar_timbre_classifier_20221222-182105\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_425 (Conv1D)          (None, 164, 4)            24        \n",
            "_________________________________________________________________\n",
            "batch_normalization_446 (Bat (None, 164, 4)            16        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_299 (MaxPoolin (None, 82, 4)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_426 (Conv1D)          (None, 39, 4)             84        \n",
            "_________________________________________________________________\n",
            "batch_normalization_447 (Bat (None, 39, 4)             16        \n",
            "_________________________________________________________________\n",
            "average_pooling1d_50 (Averag (None, 19, 4)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_427 (Conv1D)          (None, 15, 8)             168       \n",
            "_________________________________________________________________\n",
            "batch_normalization_448 (Bat (None, 15, 8)             32        \n",
            "_________________________________________________________________\n",
            "conv1d_428 (Conv1D)          (None, 11, 16)            656       \n",
            "_________________________________________________________________\n",
            "batch_normalization_449 (Bat (None, 11, 16)            64        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_300 (MaxPoolin (None, 5, 16)             0         \n",
            "_________________________________________________________________\n",
            "flatten_92 (Flatten)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dropout_113 (Dropout)        (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 64)                5184      \n",
            "_________________________________________________________________\n",
            "batch_normalization_450 (Bat (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_114 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_114 (Dense)            (None, 8)                 520       \n",
            "=================================================================\n",
            "Total params: 7,020\n",
            "Trainable params: 6,828\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "Warning! Using custom K-Fold, which splits the dataset in the data from different players.\n",
            "as a result, the number of folds has been OVERWRITTEN and is now  6\n"
          ]
        }
      ],
      "source": [
        "prefix = \"CrossValidated\" if USE_CROSS_VALIDATION else \"Single\"\n",
        "RUN_NAME = prefix + \"Run_\"+strftime(\"%Y%m%d-%H%M%S\")\n",
        "OUTPUT_DIR = os.path.join(MODELFOLDER,RUN_NAME)\n",
        "os.makedirs(OUTPUT_DIR,exist_ok = True) \n",
        "\n",
        "\n",
        "if PREVIEW_MODEL:\n",
        "    model_prev = define_model_architecture(len(CLASSES))\n",
        "    model_prev.summary()\n",
        "    with open(os.path.join(OUTPUT_DIR, 'model_summary.txt'), 'w') as f:\n",
        "        model_prev.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "\n",
        "\n",
        "if CUSTOM_PLAYER_K_FOLD:\n",
        "    print('Warning! Using custom K-Fold, which splits the dataset in the data from different players.')\n",
        "    cv = CustomPlayerFold(dataset_metadata,dataset_features,dataset_labels,_val_split_size=VAL_SPLIT_SIZE_TESTPERC)\n",
        "    K_SPLITS = cv.get_k_splits()\n",
        "    print('as a result, the number of folds has been OVERWRITTEN and is now ',K_SPLITS)\n",
        "\n",
        "else:\n",
        "    cv = StratifiedKFold(n_splits=K_SPLITS,shuffle=True,random_state=random_state)\n",
        "\n",
        "def main_routine(X,y,train_idx=None,test_idx=None,val_idx=None,_val_split_size=None,aug_data=None,foldcount=None,is_k_fold=False, eval_metrics=None, quantized_eval_metrics=None):\n",
        "    assert np.equal(np.sort(CLASSES),np.unique(y)).all(), 'np.sort(CLASSES) != np.unique(y)  ('+np.sort(CLASSES)+'!='+np.unique(y)+')'\n",
        "\n",
        "    np.random.shuffle(train_idx)   #TODO: remove if this turns out to be useless\n",
        "    np.random.shuffle(test_idx)    #TODO: remove if this turns out to be useless\n",
        "    np.random.shuffle(val_idx) #TODO: remove if this turns out to be useless\n",
        "    \n",
        "    if eval_metrics is None:\n",
        "        raise ValueError(\"provide a eval_metrics dict\")\n",
        "\n",
        "    current_dir = MODELFOLDER + \"/\" + RUN_NAME\n",
        "    # %mkdir -p \"$current_dir\"\n",
        "    os.makedirs(current_dir,exist_ok = True) \n",
        "    if is_k_fold:\n",
        "        fold_dir = current_dir + '/Fold_' + str(foldcount)\n",
        "        # %mkdir -p \"$fold_dir\"\n",
        "        os.makedirs(fold_dir,exist_ok = True)\n",
        "\n",
        "    ### PRINT INFO\n",
        "    if is_k_fold:\n",
        "        print(\"\\nFold [\"+str(foldcount)+\"/\"+str(K_SPLITS)+\"]\")\n",
        "        #### SPLIT DATA\n",
        "        print(\"Selecting Split Data...\")\n",
        "        X_train, y_train = X[train_idx], y[train_idx]\n",
        "        X_test, y_test = X[test_idx], y[test_idx]\n",
        "        # printSupport(y_train)                                                       # Verify that the split is STRATIFIED\n",
        "    else:\n",
        "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_split_size,random_state=random_state, shuffle=True, stratify = y)\n",
        "        # printSupport(y_train)                                                       # Verify that the split is STRATIFIED\n",
        "\n",
        "    if val_idx is None:\n",
        "        print('Performing generic validation/train split from training split')    \n",
        "        X_train,X_valid,y_train,y_valid = train_test_split(X_train,y_train,test_size=_val_split_size,random_state=random_state, shuffle=True, stratify = y_train)\n",
        "        # printSupport(y_train)                                                       # Verify that the split is STRATIFIED\n",
        "    else:\n",
        "        print('Taking validation split from provided indexes')    \n",
        "        X_valid, y_valid = X[val_idx], y[val_idx]\n",
        "        # printSupport(y_valid)                                                       # Verify that the split is STRATIFIED\n",
        "\n",
        "    ### NORMALIZE DATA\n",
        "    if DO_NORMALIZE_DATA:\n",
        "        print(\"Normalizing Data...\")\n",
        "        scaler = SCALER_TO_USE\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test =  scaler.transform(X_test)\n",
        "        X_valid = scaler.transform(X_valid)\n",
        "        scaler.fit([[0]]) # \"reset\" scaler\n",
        "        print(\"Done.\")\n",
        "\n",
        "\n",
        "\n",
        "    ### OVERSAMPLE\n",
        "    if VERBOSE_OVERSAMPLING:\n",
        "        if DO_OVERSAMPLING:\n",
        "            print(\"Oversampling...\")\n",
        "        else:\n",
        "            print('NOT performing oversampling')\n",
        "    if DO_OVERSAMPLING:\n",
        "        # VERBOSE_OVERSAMPLING = True\n",
        "        # with warnings.catch_warnings():\n",
        "        #     warnings.simplefilter(\"ignore\")\n",
        "        #     if VERBOSE_OVERSAMPLING:\n",
        "        #         prev_len = y_train.shape[0]\n",
        "        #     X_train, y_train = SMOTE(smote_mask).fit_sample(X_train, y_train)\n",
        "        #     if VERBOSE_OVERSAMPLING:\n",
        "        #         print(\"Increased training samples from \" + str(prev_len) + \" to \" + str(y_train.shape[0]))\n",
        "        #         printSupport(y_train)\n",
        "\n",
        "        X_train, y_train, smote_strategy = oversample(X_train, y_train, aggressiveness = OVERSAMPLING_AGGRESSIVENESS, verbose = VERBOSE_OVERSAMPLING)\n",
        "\n",
        "    ### ADD AUGMENTED DATA\n",
        "    assert not USE_AUGMENTED_DATA or (aug_data != None), 'USE_AUGMENTED_DATA should imply that aug_data is not None, however this is not the case'\n",
        "\n",
        "    if USE_AUGMENTED_DATA:\n",
        "        (metadata_aug, features_aug, labels_aug, train_aug_idx) = aug_data\n",
        "        X_train_aug, y_train_aug = features_aug.to_numpy()[train_aug_idx], labels_aug.to_numpy()[train_aug_idx]\n",
        "        print('Adding augmented data to training set...')\n",
        "        print('Length of training set before augmentation: ',len(X_train))\n",
        "        X_train = np.concatenate((X_train,X_train_aug),axis=0)\n",
        "        y_train = np.concatenate((y_train,y_train_aug),axis=0)\n",
        "        print('Length of training set after augmentation: ',len(X_train))\n",
        "        \n",
        "\n",
        "    ### DEFINE MODEL\n",
        "    model = define_model_architecture(len(CLASSES),_verbose = True)\n",
        "    \n",
        "    ### DEFINE LOSS\n",
        "    loss_fn = get_loss()\n",
        "\n",
        "    ### PREPARE DATA IN CASE OF A FIRST CONV LAYER IN THE NET\n",
        "    if type(model.layers[0]) == tf.keras.layers.Conv1D:\n",
        "        X_train = np.expand_dims(X_train,axis = 2) # Adapt data for Conv1d ([batch_shape, steps, input_dim] -> in our case indim = 1, steps = features, batchshape = train datset size)\n",
        "        X_valid= np.expand_dims(X_valid,axis = 2)  # Adapt data for Conv1d\n",
        "        X_test= np.expand_dims(X_test,axis = 2)    # Adapt data for Conv1d\n",
        "\n",
        "    ### PERFORM TEST (**OPTIONAL)\n",
        "    if DO_TEST:\n",
        "        predictions = model(X_test[:1].astype('float32')).numpy()\n",
        "        print(\"Predictions: \" + str(predictions) + \"\\nWith Softmax: \" + str(tf.nn.softmax(predictions).numpy()) + \"\\nLoss: \" + str(loss_fn(y_test[:1], predictions).numpy()))\n",
        "\n",
        "    ### COMPILE MODEL\n",
        "    compile_model(model,optimizer,loss_fn,_verbose = True)\n",
        "\n",
        "    ### SETUP TENSORBOARD\n",
        "    tensorboard_callback = start_tensorboard(tb_dir,\"Fold_\"+str(foldcount) if is_k_fold else None)\n",
        "    callbacks=[tensorboard_callback,]\n",
        "    \n",
        "    ### SETUP EARLY STOPPING (only if not in K-fold mode)\n",
        "    if is_k_fold is False and use_early_stopping:\n",
        "        callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200))\n",
        "\n",
        "    # * FIT MODEL *\n",
        "    history = model.fit(X_train, y_train, epochs=args['epochs'], validation_data = (X_valid,y_valid),\n",
        "                        callbacks=callbacks,\n",
        "                        batch_size=args['batchsize'])\n",
        "    # Plot history\n",
        "    plot_folder = fold_dir if is_k_fold else current_dir\n",
        "    getval = lambda metric: history.history[metric]\n",
        "    plot_history(getval('accuracy'),getval('val_accuracy'), \"Training and validation accuracy\",\"Epochs\",\"Accuracy\", filename = plot_folder + \"/AccuracyPlot\")\n",
        "    plot_history(getval('loss'),    getval('val_loss'),     \"Training and validation loss\",\"Epochs\",\"Accuracy\",     filename = plot_folder + \"/LossPlot\")\n",
        "    plt.close()\n",
        "    plt.ioff()\n",
        "\n",
        "    # * TEST MODEL *\n",
        "    # keras_test_loss, keras_test_accuracy = model.evaluate(X_test,  y_test, verbose=2) # Keras solution, might not be needed\n",
        "    y_true = np.squeeze(y_test)\n",
        "    y_pred = np.argmax(model(X_test),axis=1)\n",
        "    cm_acc, f1mw, cm_conf_matrix, cm_classf_report, cm_printable_classf_report = compute_metrics(y_true, \\\n",
        "                                                                                                 y_pred, \\\n",
        "                                                                                                 _verbose=True)\n",
        "    eval_metrics[\"accuracy\"].append(cm_acc)\n",
        "    eval_metrics[\"f1_weightedmacroavg\"].append(f1mw)\n",
        "    eval_metrics[\"confusion_matrix\"].append(cm_conf_matrix)\n",
        "    eval_metrics[\"classification_report\"].append(cm_classf_report)\n",
        "    eval_metrics[\"printable_classification_report\"].append(cm_printable_classf_report)\n",
        "\n",
        "    SAVED_MODEL_PATH = None\n",
        "    if is_k_fold:\n",
        "        # Save fold history\n",
        "        with open(fold_dir+\"/history_fold_\"+str(foldcount)+\".pickle\",'wb') as picklefile:\n",
        "            pickle.dump(history.history,picklefile)\n",
        "\n",
        "        # Save the fold models only if we want them, or need them to test (in the second case they will be deleted after test)        \n",
        "        if TEST_QUANTIZATION or DO_SAVE_FOLD_MODELS:\n",
        "            model.save(fold_dir)\n",
        "            SAVED_MODEL_PATH = fold_dir\n",
        "    else:\n",
        "        assert len(eval_metrics['accuracy']) == 1\n",
        "        \n",
        "        # Save the entire model as a SavedModel.\n",
        "        if TEST_QUANTIZATION or DO_SAVE_FOLD_MODELS:\n",
        "            model.save(current_dir)\n",
        "            SAVED_MODEL_PATH = current_dir\n",
        "        with open(current_dir+\"/history.pickle\",'wb') as picklefile:\n",
        "            pickle.dump(history.history,picklefile)\n",
        "\n",
        "    if TEST_QUANTIZATION:\n",
        "        assert quantized_eval_metrics is not None\n",
        "        model_filename = 'partially_quantized_test_model'\n",
        "        # Convert and save lite model\n",
        "        convert2tflite(SAVED_MODEL_PATH,model_name=model_filename,quantization=\"dynamic\")\n",
        "        # Load and Test lite model\n",
        "        y_quant_pred = test_tflite_model(SAVED_MODEL_PATH+'/'+model_filename+'.tflite',X_test,y_test,type(model.layers[0]) == tf.keras.layers.Conv1D,verbose_test = False)\n",
        "        # Compute Test Metrics\n",
        "        cm_acc, f1mw, cm_conf_matrix, cm_classf_report, cm_printable_classf_report = compute_metrics(y_true, \\\n",
        "                                                                                                     y_quant_pred, \\\n",
        "                                                                                                     _verbose=True)\n",
        "        quantized_eval_metrics[\"accuracy\"].append(cm_acc)\n",
        "        quantized_eval_metrics[\"f1_weightedmacroavg\"].append(f1mw)\n",
        "        quantized_eval_metrics[\"confusion_matrix\"].append(cm_conf_matrix)\n",
        "        quantized_eval_metrics[\"classification_report\"].append(cm_classf_report)\n",
        "        quantized_eval_metrics[\"printable_classification_report\"].append(cm_printable_classf_report)\n",
        "\n",
        "    if not DO_SAVE_FOLD_MODELS:\n",
        "        if os.path.exists(os.path.join(fold_dir,'assets')):\n",
        "            shutil.rmtree(os.path.join(fold_dir,'assets'))\n",
        "        if os.path.exists(os.path.join(fold_dir,'variables')):\n",
        "            shutil.rmtree(os.path.join(fold_dir,'variables'))\n",
        "        if os.path.exists(os.path.join(fold_dir,'savedmodel.pb')):\n",
        "            os.remove(os.path.join(fold_dir,'savedmodel.pb'))\n",
        "        if os.path.exists(os.path.join(fold_dir,'keras_metadata.pb')):\n",
        "            os.remove(os.path.join(fold_dir,'keras_metadata.pb'))\n",
        "        if TEST_QUANTIZATION and os.path.exists(os.path.join(fold_dir,'partially_quantized_test_model.tflite')):\n",
        "            os.remove(os.path.join(fold_dir,'partially_quantized_test_model.tflite'))\n",
        "\n",
        "    # Now that all the tests are performed, all the info can be saved\n",
        "\n",
        "    if is_k_fold:\n",
        "        metrics_to_save = {}\n",
        "        metrics_to_save.update({'def_model_'+key:value for (key,value) in eval_metrics.items()})\n",
        "        if TEST_QUANTIZATION:\n",
        "            metrics_to_save.update({'quant_model_'+key:value for (key,value) in quantized_eval_metrics.items()})\n",
        "\n",
        "        # save_fold_info(model,optimizer,foldcount,K_SPLITS,X_test.shape[0],eval_metrics,list(dataset_features.columns),fold_dir)\n",
        "        save_model_info(model,\n",
        "                        optimizer,\n",
        "                        False,K_SPLITS,\n",
        "                        metrics_to_save,\n",
        "                        fold_dir,\n",
        "                        fold_zerobased=foldcount-1,\n",
        "                        smote_strategy = smote_strategy)\n",
        "\n",
        "    SMOTE_STRATEGY = smote_strategy\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwKI-vRUdDs0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ],
      "source": [
        "%tensorboard --logdir $tb_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for split_idx, (train_idx, test_idx, val_idx) in enumerate(cv.split(dataset_features.to_numpy(), dataset_labels.to_numpy())):\n",
        "#     if USE_AUGMENTED_DATA:\n",
        "#         # Here we want to select the augmented data that corresponds to the current training split\n",
        "#         training_metadata = metadata.iloc[train_idx]\n",
        "#         training_aug_indices = []\n",
        "        \n",
        "#         sources_and_times_aug = metadata_aug[['meta_augmentation_source','meta_onsetGroundTruthLabelTime']].values\n",
        "#         training_sources_and_times = {tuple(k):True for k in training_metadata[['meta_audiofilePath','meta_onsetGroundTruthLabelTime']].values}\n",
        "\n",
        "#         for idx, (source_aug, time_aug) in enumerate(sources_and_times_aug):\n",
        "#             if((source_aug,time_aug) in training_sources_and_times.keys()):\n",
        "#                 training_aug_indices.append(idx)\n",
        "                \n",
        "# Faster code\n",
        "# for split_idx, (train_idx, test_idx, val_idx) in enumerate(cv.split(dataset_features.to_numpy(), dataset_labels.to_numpy())):\n",
        "#     training_aug_indices = []\n",
        "#     if USE_AUGMENTED_DATA:\n",
        "#         # Here we want to select the augmented data that corresponds to the current training split\n",
        "#         training_metadata = metadata.iloc[train_idx]\n",
        "#         training_sources_and_times = {tuple(k):True for k in training_metadata[['meta_audiofilePath','meta_onsetGroundTruthLabelTime']].values}\n",
        "\n",
        "#         for idx,source_aug,time_aug in  metadata_aug[['meta_augmentation_source','meta_onsetGroundTruthLabelTime']].itertuples():\n",
        "#             if((source_aug,time_aug) in training_sources_and_times.keys()):\n",
        "#                 training_aug_indices.append(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orQZbq4df5jK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting augmented data for fold 0 ...\n",
            "Found 67437 augmented samples for fold 0\n",
            "\n",
            "Fold [1/6]\n",
            "Selecting Split Data...\n",
            "Taking validation split from provided indexes\n",
            "Normalizing Data...\n",
            "Done.\n",
            "sampling_strategy: {0: 373, 1: 329, 2: 378, 3: 420, 4: 883, 5: 5208, 6: 4679, 7: 5104}\n",
            "Adding augmented data to training set...\n",
            "Length of training set before augmentation:  17374\n",
            "Length of training set after augmentation:  84811\n",
            "Model compiled\n",
            "Epoch 1/120\n",
            "83/83 [==============================] - 3s 21ms/step - loss: 2.3203 - accuracy: 0.1954 - val_loss: 2.0342 - val_accuracy: 0.3195\n",
            "Epoch 2/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.8249 - accuracy: 0.3758 - val_loss: 2.1803 - val_accuracy: 0.3195\n",
            "Epoch 3/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.5853 - accuracy: 0.4595 - val_loss: 2.1548 - val_accuracy: 0.3195\n",
            "Epoch 4/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.4261 - accuracy: 0.4995 - val_loss: 1.6592 - val_accuracy: 0.3195\n",
            "Epoch 5/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.3251 - accuracy: 0.5192 - val_loss: 1.3988 - val_accuracy: 0.3989\n",
            "Epoch 6/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.2568 - accuracy: 0.5326 - val_loss: 1.3736 - val_accuracy: 0.4061\n",
            "Epoch 7/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.2129 - accuracy: 0.5434 - val_loss: 1.3565 - val_accuracy: 0.4061\n",
            "Epoch 8/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.1742 - accuracy: 0.5544 - val_loss: 1.3688 - val_accuracy: 0.4052\n",
            "Epoch 9/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.1470 - accuracy: 0.5617 - val_loss: 1.3531 - val_accuracy: 0.4125\n",
            "Epoch 10/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.1244 - accuracy: 0.5695 - val_loss: 1.3415 - val_accuracy: 0.4305\n",
            "Epoch 11/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.1018 - accuracy: 0.5785 - val_loss: 1.3511 - val_accuracy: 0.4251\n",
            "Epoch 12/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.0802 - accuracy: 0.5864 - val_loss: 1.3316 - val_accuracy: 0.4305\n",
            "Epoch 13/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.0603 - accuracy: 0.5929 - val_loss: 1.3489 - val_accuracy: 0.4404\n",
            "Epoch 14/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.0445 - accuracy: 0.5982 - val_loss: 1.3333 - val_accuracy: 0.4305\n",
            "Epoch 15/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.0304 - accuracy: 0.6041 - val_loss: 1.3570 - val_accuracy: 0.4242\n",
            "Epoch 16/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.0172 - accuracy: 0.6093 - val_loss: 1.3463 - val_accuracy: 0.4323\n",
            "Epoch 17/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 1.0004 - accuracy: 0.6147 - val_loss: 1.3708 - val_accuracy: 0.4314\n",
            "Epoch 18/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.9860 - accuracy: 0.6199 - val_loss: 1.3456 - val_accuracy: 0.4404\n",
            "Epoch 19/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.9740 - accuracy: 0.6239 - val_loss: 1.3419 - val_accuracy: 0.4513\n",
            "Epoch 20/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.9641 - accuracy: 0.6291 - val_loss: 1.3734 - val_accuracy: 0.4269\n",
            "Epoch 21/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.9573 - accuracy: 0.6319 - val_loss: 1.3661 - val_accuracy: 0.4486\n",
            "Epoch 22/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.9451 - accuracy: 0.6378 - val_loss: 1.3426 - val_accuracy: 0.4666\n",
            "Epoch 23/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.9329 - accuracy: 0.6403 - val_loss: 1.3416 - val_accuracy: 0.4657\n",
            "Epoch 24/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.9238 - accuracy: 0.6432 - val_loss: 1.3294 - val_accuracy: 0.4621\n",
            "Epoch 25/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.9154 - accuracy: 0.6467 - val_loss: 1.3226 - val_accuracy: 0.4711\n",
            "Epoch 26/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.9102 - accuracy: 0.6495 - val_loss: 1.3226 - val_accuracy: 0.4765\n",
            "Epoch 27/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.9019 - accuracy: 0.6531 - val_loss: 1.3122 - val_accuracy: 0.4801\n",
            "Epoch 28/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8958 - accuracy: 0.6555 - val_loss: 1.3345 - val_accuracy: 0.4783\n",
            "Epoch 29/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8860 - accuracy: 0.6579 - val_loss: 1.2996 - val_accuracy: 0.4847\n",
            "Epoch 30/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8776 - accuracy: 0.6621 - val_loss: 1.3298 - val_accuracy: 0.4801\n",
            "Epoch 31/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8761 - accuracy: 0.6626 - val_loss: 1.3263 - val_accuracy: 0.4720\n",
            "Epoch 32/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8648 - accuracy: 0.6677 - val_loss: 1.2987 - val_accuracy: 0.4928\n",
            "Epoch 33/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8625 - accuracy: 0.6683 - val_loss: 1.3420 - val_accuracy: 0.4783\n",
            "Epoch 34/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8552 - accuracy: 0.6706 - val_loss: 1.2834 - val_accuracy: 0.4928\n",
            "Epoch 35/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8478 - accuracy: 0.6718 - val_loss: 1.2830 - val_accuracy: 0.5045\n",
            "Epoch 36/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8457 - accuracy: 0.6744 - val_loss: 1.3079 - val_accuracy: 0.4937\n",
            "Epoch 37/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8427 - accuracy: 0.6758 - val_loss: 1.3303 - val_accuracy: 0.4801\n",
            "Epoch 38/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8374 - accuracy: 0.6769 - val_loss: 1.3193 - val_accuracy: 0.5000\n",
            "Epoch 39/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8346 - accuracy: 0.6773 - val_loss: 1.3180 - val_accuracy: 0.4964\n",
            "Epoch 40/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8282 - accuracy: 0.6809 - val_loss: 1.2995 - val_accuracy: 0.4937\n",
            "Epoch 41/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8255 - accuracy: 0.6825 - val_loss: 1.2971 - val_accuracy: 0.4973\n",
            "Epoch 42/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8192 - accuracy: 0.6843 - val_loss: 1.2995 - val_accuracy: 0.4883\n",
            "Epoch 43/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8147 - accuracy: 0.6855 - val_loss: 1.3057 - val_accuracy: 0.4856\n",
            "Epoch 44/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8103 - accuracy: 0.6879 - val_loss: 1.3114 - val_accuracy: 0.4865\n",
            "Epoch 45/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8093 - accuracy: 0.6872 - val_loss: 1.3283 - val_accuracy: 0.4774\n",
            "Epoch 46/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8056 - accuracy: 0.6897 - val_loss: 1.3004 - val_accuracy: 0.4774\n",
            "Epoch 47/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.8008 - accuracy: 0.6916 - val_loss: 1.3212 - val_accuracy: 0.4684\n",
            "Epoch 48/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7988 - accuracy: 0.6914 - val_loss: 1.2796 - val_accuracy: 0.4783\n",
            "Epoch 49/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7963 - accuracy: 0.6920 - val_loss: 1.3313 - val_accuracy: 0.4711\n",
            "Epoch 50/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7899 - accuracy: 0.6949 - val_loss: 1.3139 - val_accuracy: 0.4810\n",
            "Epoch 51/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7898 - accuracy: 0.6948 - val_loss: 1.2954 - val_accuracy: 0.4801\n",
            "Epoch 52/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7849 - accuracy: 0.6972 - val_loss: 1.3210 - val_accuracy: 0.4756\n",
            "Epoch 53/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7847 - accuracy: 0.6981 - val_loss: 1.3096 - val_accuracy: 0.4747\n",
            "Epoch 54/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7815 - accuracy: 0.6992 - val_loss: 1.2850 - val_accuracy: 0.4693\n",
            "Epoch 55/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7779 - accuracy: 0.6988 - val_loss: 1.3152 - val_accuracy: 0.4621\n",
            "Epoch 56/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7768 - accuracy: 0.7005 - val_loss: 1.3213 - val_accuracy: 0.4720\n",
            "Epoch 57/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7700 - accuracy: 0.7019 - val_loss: 1.3082 - val_accuracy: 0.4711\n",
            "Epoch 58/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7691 - accuracy: 0.7024 - val_loss: 1.2784 - val_accuracy: 0.4829\n",
            "Epoch 59/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7680 - accuracy: 0.7037 - val_loss: 1.3536 - val_accuracy: 0.4639\n",
            "Epoch 60/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7643 - accuracy: 0.7055 - val_loss: 1.3258 - val_accuracy: 0.4747\n",
            "Epoch 61/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7605 - accuracy: 0.7069 - val_loss: 1.2644 - val_accuracy: 0.4910\n",
            "Epoch 62/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7595 - accuracy: 0.7062 - val_loss: 1.3048 - val_accuracy: 0.4783\n",
            "Epoch 63/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7564 - accuracy: 0.7085 - val_loss: 1.3182 - val_accuracy: 0.4738\n",
            "Epoch 64/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7528 - accuracy: 0.7095 - val_loss: 1.3329 - val_accuracy: 0.4819\n",
            "Epoch 65/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7528 - accuracy: 0.7100 - val_loss: 1.3149 - val_accuracy: 0.4856\n",
            "Epoch 66/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7492 - accuracy: 0.7117 - val_loss: 1.3101 - val_accuracy: 0.4847\n",
            "Epoch 67/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7517 - accuracy: 0.7098 - val_loss: 1.2810 - val_accuracy: 0.4910\n",
            "Epoch 68/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7467 - accuracy: 0.7130 - val_loss: 1.3013 - val_accuracy: 0.4901\n",
            "Epoch 69/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7458 - accuracy: 0.7120 - val_loss: 1.2848 - val_accuracy: 0.4865\n",
            "Epoch 70/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7433 - accuracy: 0.7126 - val_loss: 1.2896 - val_accuracy: 0.4946\n",
            "Epoch 71/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7431 - accuracy: 0.7149 - val_loss: 1.2844 - val_accuracy: 0.5018\n",
            "Epoch 72/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7377 - accuracy: 0.7159 - val_loss: 1.3172 - val_accuracy: 0.4801\n",
            "Epoch 73/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7385 - accuracy: 0.7158 - val_loss: 1.2838 - val_accuracy: 0.4883\n",
            "Epoch 74/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7355 - accuracy: 0.7181 - val_loss: 1.2790 - val_accuracy: 0.4973\n",
            "Epoch 75/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7355 - accuracy: 0.7159 - val_loss: 1.3110 - val_accuracy: 0.4928\n",
            "Epoch 76/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7342 - accuracy: 0.7172 - val_loss: 1.2488 - val_accuracy: 0.5018\n",
            "Epoch 77/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7332 - accuracy: 0.7190 - val_loss: 1.2599 - val_accuracy: 0.5099\n",
            "Epoch 78/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7298 - accuracy: 0.7187 - val_loss: 1.3100 - val_accuracy: 0.4865\n",
            "Epoch 79/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7299 - accuracy: 0.7176 - val_loss: 1.2639 - val_accuracy: 0.5018\n",
            "Epoch 80/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7262 - accuracy: 0.7192 - val_loss: 1.3051 - val_accuracy: 0.4991\n",
            "Epoch 81/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7273 - accuracy: 0.7198 - val_loss: 1.2827 - val_accuracy: 0.4964\n",
            "Epoch 82/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7272 - accuracy: 0.7213 - val_loss: 1.2454 - val_accuracy: 0.5063\n",
            "Epoch 83/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7240 - accuracy: 0.7217 - val_loss: 1.2751 - val_accuracy: 0.5009\n",
            "Epoch 84/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7215 - accuracy: 0.7243 - val_loss: 1.2564 - val_accuracy: 0.5009\n",
            "Epoch 85/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7217 - accuracy: 0.7221 - val_loss: 1.2611 - val_accuracy: 0.5018\n",
            "Epoch 86/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7173 - accuracy: 0.7226 - val_loss: 1.2750 - val_accuracy: 0.5045\n",
            "Epoch 87/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7202 - accuracy: 0.7217 - val_loss: 1.2439 - val_accuracy: 0.5090\n",
            "Epoch 88/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7167 - accuracy: 0.7255 - val_loss: 1.3017 - val_accuracy: 0.4847\n",
            "Epoch 89/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7190 - accuracy: 0.7238 - val_loss: 1.2537 - val_accuracy: 0.5027\n",
            "Epoch 90/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7166 - accuracy: 0.7253 - val_loss: 1.2602 - val_accuracy: 0.5045\n",
            "Epoch 91/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7154 - accuracy: 0.7264 - val_loss: 1.2564 - val_accuracy: 0.4991\n",
            "Epoch 92/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7134 - accuracy: 0.7269 - val_loss: 1.2920 - val_accuracy: 0.4955\n",
            "Epoch 93/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7145 - accuracy: 0.7250 - val_loss: 1.2673 - val_accuracy: 0.5009\n",
            "Epoch 94/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7123 - accuracy: 0.7260 - val_loss: 1.3458 - val_accuracy: 0.4783\n",
            "Epoch 95/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7108 - accuracy: 0.7254 - val_loss: 1.2472 - val_accuracy: 0.5054\n",
            "Epoch 96/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7107 - accuracy: 0.7269 - val_loss: 1.2606 - val_accuracy: 0.5000\n",
            "Epoch 97/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7071 - accuracy: 0.7285 - val_loss: 1.2415 - val_accuracy: 0.5018\n",
            "Epoch 98/120\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.7093 - accuracy: 0.7270 - val_loss: 1.2323 - val_accuracy: 0.5099\n",
            "Epoch 99/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7059 - accuracy: 0.7290 - val_loss: 1.2601 - val_accuracy: 0.5000\n",
            "Epoch 100/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7034 - accuracy: 0.7294 - val_loss: 1.2789 - val_accuracy: 0.4937\n",
            "Epoch 101/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7016 - accuracy: 0.7310 - val_loss: 1.2766 - val_accuracy: 0.5090\n",
            "Epoch 102/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7038 - accuracy: 0.7295 - val_loss: 1.2790 - val_accuracy: 0.4838\n",
            "Epoch 103/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7041 - accuracy: 0.7285 - val_loss: 1.2400 - val_accuracy: 0.4919\n",
            "Epoch 104/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7031 - accuracy: 0.7295 - val_loss: 1.2702 - val_accuracy: 0.4937\n",
            "Epoch 105/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7018 - accuracy: 0.7316 - val_loss: 1.2656 - val_accuracy: 0.4982\n",
            "Epoch 106/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7044 - accuracy: 0.7290 - val_loss: 1.2369 - val_accuracy: 0.5027\n",
            "Epoch 107/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7021 - accuracy: 0.7319 - val_loss: 1.2149 - val_accuracy: 0.5027\n",
            "Epoch 108/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7010 - accuracy: 0.7305 - val_loss: 1.2541 - val_accuracy: 0.4928\n",
            "Epoch 109/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.7022 - accuracy: 0.7307 - val_loss: 1.2479 - val_accuracy: 0.4946\n",
            "Epoch 110/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6979 - accuracy: 0.7317 - val_loss: 1.2428 - val_accuracy: 0.4973\n",
            "Epoch 111/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6970 - accuracy: 0.7324 - val_loss: 1.2339 - val_accuracy: 0.4991\n",
            "Epoch 112/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6955 - accuracy: 0.7312 - val_loss: 1.2759 - val_accuracy: 0.4874\n",
            "Epoch 113/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6974 - accuracy: 0.7314 - val_loss: 1.2367 - val_accuracy: 0.4883\n",
            "Epoch 114/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6927 - accuracy: 0.7333 - val_loss: 1.2264 - val_accuracy: 0.5009\n",
            "Epoch 115/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6970 - accuracy: 0.7325 - val_loss: 1.2442 - val_accuracy: 0.4946\n",
            "Epoch 116/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6929 - accuracy: 0.7329 - val_loss: 1.2346 - val_accuracy: 0.5000\n",
            "Epoch 117/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6923 - accuracy: 0.7343 - val_loss: 1.2427 - val_accuracy: 0.4901\n",
            "Epoch 118/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6929 - accuracy: 0.7331 - val_loss: 1.2651 - val_accuracy: 0.4973\n",
            "Epoch 119/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6918 - accuracy: 0.7346 - val_loss: 1.2451 - val_accuracy: 0.4874\n",
            "Epoch 120/120\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.6906 - accuracy: 0.7354 - val_loss: 1.2506 - val_accuracy: 0.4973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_513425/2383121875.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  precision = 1.0 * true_positives / np.sum(classPrediction)\n",
            "/tmp/ipykernel_513425/2383121875.py:12: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  f1score = 2 /((1/precision)+(1/recall))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.5402476780185759\n",
            "Test macro_weighted_avg f1-score: nan\n",
            "[[  1   0   0   0   0  19   1   0]\n",
            " [  0   0   0   0   0  14   1   6]\n",
            " [  0   0   0   0   0  20   0   1]\n",
            " [  1   0   0   1   0  19   0   0]\n",
            " [ 10   0   0   0   1  47  27  28]\n",
            " [ 25   0   0   1   1 599  62  60]\n",
            " [ 49   0   0   1   3 287 387  85]\n",
            " [ 11   0   1   0   4 216 188 407]]\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                   Kick     0.0103    0.0476    0.0169        21\n",
            "                Snare 1     0.0000    0.0000    0.0000        21\n",
            "                    Tom     0.0000    0.0000    0.0000        21\n",
            "                Snare 2     0.3333    0.0476    0.0833        21\n",
            "      Natural Harmonics     0.1111    0.0088    0.0164       113\n",
            "              Palm Mute     0.4906    0.8008    0.6084       748\n",
            "       Pick Near Bridge     0.5811    0.4766    0.5237       812\n",
            "Pick Over the Soundhole     0.6934    0.4921    0.5757       827\n",
            "\n",
            "               accuracy                         0.5402      2584\n",
            "              macro avg     0.2775    0.2342    0.2281      2584\n",
            "           weighted avg     0.5542    0.5402    0.5265      2584\n",
            "\n",
            "Selecting augmented data for fold 1 ...\n",
            "Found 68739 augmented samples for fold 1\n",
            "\n",
            "Fold [2/6]\n",
            "Selecting Split Data...\n",
            "Taking validation split from provided indexes\n",
            "Normalizing Data...\n",
            "Done.\n",
            "sampling_strategy: {0: 374, 1: 330, 2: 381, 3: 420, 4: 883, 5: 5107, 6: 5012, 7: 5106}\n",
            "Adding augmented data to training set...\n",
            "Length of training set before augmentation:  17613\n",
            "Length of training set after augmentation:  86352\n",
            "Model compiled\n",
            "Epoch 1/120\n",
            "85/85 [==============================] - 3s 20ms/step - loss: 2.2447 - accuracy: 0.2415 - val_loss: 1.8472 - val_accuracy: 0.2394\n",
            "Epoch 2/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.7300 - accuracy: 0.4084 - val_loss: 1.6823 - val_accuracy: 0.2394\n",
            "Epoch 3/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.5166 - accuracy: 0.4749 - val_loss: 1.5676 - val_accuracy: 0.2394\n",
            "Epoch 4/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.3747 - accuracy: 0.5073 - val_loss: 1.4787 - val_accuracy: 0.2616\n",
            "Epoch 5/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.2824 - accuracy: 0.5242 - val_loss: 1.4178 - val_accuracy: 0.3243\n",
            "Epoch 6/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.2152 - accuracy: 0.5400 - val_loss: 1.3899 - val_accuracy: 0.4421\n",
            "Epoch 7/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.1609 - accuracy: 0.5544 - val_loss: 1.3630 - val_accuracy: 0.4788\n",
            "Epoch 8/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.1241 - accuracy: 0.5663 - val_loss: 1.3498 - val_accuracy: 0.4604\n",
            "Epoch 9/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0858 - accuracy: 0.5797 - val_loss: 1.3231 - val_accuracy: 0.4334\n",
            "Epoch 10/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0548 - accuracy: 0.5919 - val_loss: 1.3284 - val_accuracy: 0.4459\n",
            "Epoch 11/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0263 - accuracy: 0.5998 - val_loss: 1.3051 - val_accuracy: 0.4595\n",
            "Epoch 12/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0020 - accuracy: 0.6093 - val_loss: 1.3033 - val_accuracy: 0.4208\n",
            "Epoch 13/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9788 - accuracy: 0.6180 - val_loss: 1.2927 - val_accuracy: 0.4305\n",
            "Epoch 14/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9602 - accuracy: 0.6255 - val_loss: 1.2946 - val_accuracy: 0.4479\n",
            "Epoch 15/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9457 - accuracy: 0.6299 - val_loss: 1.2834 - val_accuracy: 0.4537\n",
            "Epoch 16/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.9337 - accuracy: 0.6354 - val_loss: 1.2803 - val_accuracy: 0.5039\n",
            "Epoch 17/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9206 - accuracy: 0.6400 - val_loss: 1.2633 - val_accuracy: 0.4903\n",
            "Epoch 18/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9087 - accuracy: 0.6453 - val_loss: 1.2720 - val_accuracy: 0.4681\n",
            "Epoch 19/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8958 - accuracy: 0.6491 - val_loss: 1.2606 - val_accuracy: 0.4817\n",
            "Epoch 20/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8929 - accuracy: 0.6524 - val_loss: 1.2756 - val_accuracy: 0.4672\n",
            "Epoch 21/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8786 - accuracy: 0.6556 - val_loss: 1.2437 - val_accuracy: 0.4981\n",
            "Epoch 22/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8709 - accuracy: 0.6606 - val_loss: 1.2571 - val_accuracy: 0.4759\n",
            "Epoch 23/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8610 - accuracy: 0.6638 - val_loss: 1.2681 - val_accuracy: 0.4875\n",
            "Epoch 24/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8530 - accuracy: 0.6658 - val_loss: 1.2479 - val_accuracy: 0.4952\n",
            "Epoch 25/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8463 - accuracy: 0.6685 - val_loss: 1.2427 - val_accuracy: 0.4903\n",
            "Epoch 26/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8382 - accuracy: 0.6718 - val_loss: 1.2391 - val_accuracy: 0.5029\n",
            "Epoch 27/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8335 - accuracy: 0.6755 - val_loss: 1.2563 - val_accuracy: 0.4817\n",
            "Epoch 28/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8253 - accuracy: 0.6754 - val_loss: 1.2424 - val_accuracy: 0.4788\n",
            "Epoch 29/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8200 - accuracy: 0.6788 - val_loss: 1.2480 - val_accuracy: 0.4778\n",
            "Epoch 30/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8135 - accuracy: 0.6825 - val_loss: 1.2448 - val_accuracy: 0.4595\n",
            "Epoch 31/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.8091 - accuracy: 0.6853 - val_loss: 1.2258 - val_accuracy: 0.4884\n",
            "Epoch 32/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8058 - accuracy: 0.6854 - val_loss: 1.2406 - val_accuracy: 0.4807\n",
            "Epoch 33/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7977 - accuracy: 0.6894 - val_loss: 1.2283 - val_accuracy: 0.5000\n",
            "Epoch 34/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7911 - accuracy: 0.6925 - val_loss: 1.2124 - val_accuracy: 0.5116\n",
            "Epoch 35/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7874 - accuracy: 0.6933 - val_loss: 1.2196 - val_accuracy: 0.5039\n",
            "Epoch 36/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7831 - accuracy: 0.6944 - val_loss: 1.2353 - val_accuracy: 0.4768\n",
            "Epoch 37/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7786 - accuracy: 0.6969 - val_loss: 1.2127 - val_accuracy: 0.5087\n",
            "Epoch 38/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7730 - accuracy: 0.7008 - val_loss: 1.2205 - val_accuracy: 0.5000\n",
            "Epoch 39/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7712 - accuracy: 0.7002 - val_loss: 1.1972 - val_accuracy: 0.5193\n",
            "Epoch 40/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7640 - accuracy: 0.7035 - val_loss: 1.2137 - val_accuracy: 0.5203\n",
            "Epoch 41/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7638 - accuracy: 0.7046 - val_loss: 1.1959 - val_accuracy: 0.5212\n",
            "Epoch 42/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7568 - accuracy: 0.7044 - val_loss: 1.1925 - val_accuracy: 0.5261\n",
            "Epoch 43/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7535 - accuracy: 0.7090 - val_loss: 1.2298 - val_accuracy: 0.4990\n",
            "Epoch 44/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7508 - accuracy: 0.7095 - val_loss: 1.2220 - val_accuracy: 0.5145\n",
            "Epoch 45/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7481 - accuracy: 0.7108 - val_loss: 1.2048 - val_accuracy: 0.5116\n",
            "Epoch 46/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7448 - accuracy: 0.7106 - val_loss: 1.1942 - val_accuracy: 0.5261\n",
            "Epoch 47/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7413 - accuracy: 0.7115 - val_loss: 1.1909 - val_accuracy: 0.5241\n",
            "Epoch 48/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7412 - accuracy: 0.7125 - val_loss: 1.1938 - val_accuracy: 0.5232\n",
            "Epoch 49/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7367 - accuracy: 0.7137 - val_loss: 1.1859 - val_accuracy: 0.5261\n",
            "Epoch 50/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7331 - accuracy: 0.7169 - val_loss: 1.2157 - val_accuracy: 0.5029\n",
            "Epoch 51/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7299 - accuracy: 0.7161 - val_loss: 1.2150 - val_accuracy: 0.5077\n",
            "Epoch 52/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7289 - accuracy: 0.7167 - val_loss: 1.2006 - val_accuracy: 0.5261\n",
            "Epoch 53/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7276 - accuracy: 0.7185 - val_loss: 1.1997 - val_accuracy: 0.5125\n",
            "Epoch 54/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7237 - accuracy: 0.7190 - val_loss: 1.2117 - val_accuracy: 0.5048\n",
            "Epoch 55/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7202 - accuracy: 0.7218 - val_loss: 1.2038 - val_accuracy: 0.5145\n",
            "Epoch 56/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7196 - accuracy: 0.7210 - val_loss: 1.2150 - val_accuracy: 0.5135\n",
            "Epoch 57/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7157 - accuracy: 0.7242 - val_loss: 1.1892 - val_accuracy: 0.5357\n",
            "Epoch 58/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7146 - accuracy: 0.7224 - val_loss: 1.1926 - val_accuracy: 0.5261\n",
            "Epoch 59/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7120 - accuracy: 0.7257 - val_loss: 1.1967 - val_accuracy: 0.5174\n",
            "Epoch 60/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7120 - accuracy: 0.7229 - val_loss: 1.2004 - val_accuracy: 0.5222\n",
            "Epoch 61/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7096 - accuracy: 0.7257 - val_loss: 1.2119 - val_accuracy: 0.5193\n",
            "Epoch 62/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7071 - accuracy: 0.7266 - val_loss: 1.2029 - val_accuracy: 0.5116\n",
            "Epoch 63/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7092 - accuracy: 0.7243 - val_loss: 1.2017 - val_accuracy: 0.5212\n",
            "Epoch 64/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7032 - accuracy: 0.7283 - val_loss: 1.2135 - val_accuracy: 0.4932\n",
            "Epoch 65/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7030 - accuracy: 0.7270 - val_loss: 1.2004 - val_accuracy: 0.5290\n",
            "Epoch 66/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6996 - accuracy: 0.7302 - val_loss: 1.1955 - val_accuracy: 0.5164\n",
            "Epoch 67/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7004 - accuracy: 0.7275 - val_loss: 1.2199 - val_accuracy: 0.5087\n",
            "Epoch 68/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6968 - accuracy: 0.7305 - val_loss: 1.2136 - val_accuracy: 0.5048\n",
            "Epoch 69/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6945 - accuracy: 0.7328 - val_loss: 1.2452 - val_accuracy: 0.4875\n",
            "Epoch 70/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6943 - accuracy: 0.7320 - val_loss: 1.2108 - val_accuracy: 0.5048\n",
            "Epoch 71/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6925 - accuracy: 0.7314 - val_loss: 1.2072 - val_accuracy: 0.5164\n",
            "Epoch 72/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6932 - accuracy: 0.7324 - val_loss: 1.2180 - val_accuracy: 0.5174\n",
            "Epoch 73/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6905 - accuracy: 0.7344 - val_loss: 1.2104 - val_accuracy: 0.5116\n",
            "Epoch 74/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6896 - accuracy: 0.7335 - val_loss: 1.1995 - val_accuracy: 0.5232\n",
            "Epoch 75/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6866 - accuracy: 0.7347 - val_loss: 1.2104 - val_accuracy: 0.5135\n",
            "Epoch 76/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6862 - accuracy: 0.7347 - val_loss: 1.2131 - val_accuracy: 0.5212\n",
            "Epoch 77/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6858 - accuracy: 0.7350 - val_loss: 1.2054 - val_accuracy: 0.5077\n",
            "Epoch 78/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6808 - accuracy: 0.7374 - val_loss: 1.2298 - val_accuracy: 0.5106\n",
            "Epoch 79/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6838 - accuracy: 0.7347 - val_loss: 1.2074 - val_accuracy: 0.5097\n",
            "Epoch 80/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6802 - accuracy: 0.7386 - val_loss: 1.2065 - val_accuracy: 0.5106\n",
            "Epoch 81/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6768 - accuracy: 0.7375 - val_loss: 1.2071 - val_accuracy: 0.5193\n",
            "Epoch 82/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6774 - accuracy: 0.7384 - val_loss: 1.2105 - val_accuracy: 0.5203\n",
            "Epoch 83/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6762 - accuracy: 0.7392 - val_loss: 1.1997 - val_accuracy: 0.5261\n",
            "Epoch 84/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6792 - accuracy: 0.7398 - val_loss: 1.2106 - val_accuracy: 0.5183\n",
            "Epoch 85/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6713 - accuracy: 0.7410 - val_loss: 1.2181 - val_accuracy: 0.5077\n",
            "Epoch 86/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6734 - accuracy: 0.7403 - val_loss: 1.2139 - val_accuracy: 0.5010\n",
            "Epoch 87/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6712 - accuracy: 0.7411 - val_loss: 1.2062 - val_accuracy: 0.5058\n",
            "Epoch 88/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6714 - accuracy: 0.7401 - val_loss: 1.2068 - val_accuracy: 0.5125\n",
            "Epoch 89/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6716 - accuracy: 0.7409 - val_loss: 1.2034 - val_accuracy: 0.5106\n",
            "Epoch 90/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6703 - accuracy: 0.7399 - val_loss: 1.2088 - val_accuracy: 0.5058\n",
            "Epoch 91/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6670 - accuracy: 0.7421 - val_loss: 1.2184 - val_accuracy: 0.4894\n",
            "Epoch 92/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6673 - accuracy: 0.7416 - val_loss: 1.2071 - val_accuracy: 0.5154\n",
            "Epoch 93/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6668 - accuracy: 0.7418 - val_loss: 1.1932 - val_accuracy: 0.5367\n",
            "Epoch 94/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6649 - accuracy: 0.7427 - val_loss: 1.2035 - val_accuracy: 0.5048\n",
            "Epoch 95/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6651 - accuracy: 0.7437 - val_loss: 1.2034 - val_accuracy: 0.5116\n",
            "Epoch 96/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6629 - accuracy: 0.7435 - val_loss: 1.2163 - val_accuracy: 0.4981\n",
            "Epoch 97/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6670 - accuracy: 0.7438 - val_loss: 1.2217 - val_accuracy: 0.4990\n",
            "Epoch 98/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6605 - accuracy: 0.7447 - val_loss: 1.1836 - val_accuracy: 0.5116\n",
            "Epoch 99/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6601 - accuracy: 0.7444 - val_loss: 1.2042 - val_accuracy: 0.5164\n",
            "Epoch 100/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6586 - accuracy: 0.7453 - val_loss: 1.1924 - val_accuracy: 0.5212\n",
            "Epoch 101/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6590 - accuracy: 0.7442 - val_loss: 1.2093 - val_accuracy: 0.5087\n",
            "Epoch 102/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6580 - accuracy: 0.7444 - val_loss: 1.2159 - val_accuracy: 0.4971\n",
            "Epoch 103/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6557 - accuracy: 0.7478 - val_loss: 1.1934 - val_accuracy: 0.5290\n",
            "Epoch 104/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6519 - accuracy: 0.7487 - val_loss: 1.1782 - val_accuracy: 0.5174\n",
            "Epoch 105/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6538 - accuracy: 0.7476 - val_loss: 1.1784 - val_accuracy: 0.5309\n",
            "Epoch 106/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6564 - accuracy: 0.7462 - val_loss: 1.1746 - val_accuracy: 0.5309\n",
            "Epoch 107/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6539 - accuracy: 0.7478 - val_loss: 1.1937 - val_accuracy: 0.5261\n",
            "Epoch 108/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6523 - accuracy: 0.7477 - val_loss: 1.1934 - val_accuracy: 0.5145\n",
            "Epoch 109/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6504 - accuracy: 0.7494 - val_loss: 1.2081 - val_accuracy: 0.4990\n",
            "Epoch 110/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6557 - accuracy: 0.7454 - val_loss: 1.2087 - val_accuracy: 0.5019\n",
            "Epoch 111/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6512 - accuracy: 0.7483 - val_loss: 1.1828 - val_accuracy: 0.5270\n",
            "Epoch 112/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6503 - accuracy: 0.7494 - val_loss: 1.2019 - val_accuracy: 0.5048\n",
            "Epoch 113/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6477 - accuracy: 0.7497 - val_loss: 1.1931 - val_accuracy: 0.5097\n",
            "Epoch 114/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6468 - accuracy: 0.7516 - val_loss: 1.2370 - val_accuracy: 0.5039\n",
            "Epoch 115/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6494 - accuracy: 0.7501 - val_loss: 1.1861 - val_accuracy: 0.5183\n",
            "Epoch 116/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6441 - accuracy: 0.7513 - val_loss: 1.1840 - val_accuracy: 0.5145\n",
            "Epoch 117/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6429 - accuracy: 0.7519 - val_loss: 1.1744 - val_accuracy: 0.5154\n",
            "Epoch 118/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6462 - accuracy: 0.7502 - val_loss: 1.1919 - val_accuracy: 0.5029\n",
            "Epoch 119/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6431 - accuracy: 0.7510 - val_loss: 1.1785 - val_accuracy: 0.5222\n",
            "Epoch 120/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6440 - accuracy: 0.7509 - val_loss: 1.1997 - val_accuracy: 0.5097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_513425/2383121875.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  precision = 1.0 * true_positives / np.sum(classPrediction)\n",
            "/tmp/ipykernel_513425/2383121875.py:12: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  f1score = 2 /((1/precision)+(1/recall))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.49813818783616054\n",
            "Test macro_weighted_avg f1-score: nan\n",
            "[[  0   0   0   0   0  16   3   1]\n",
            " [  0   3   0   0   0  15   2   0]\n",
            " [  0   0   0   0   0  17   2   0]\n",
            " [  0   0   1   0   0  18   1   1]\n",
            " [  0   1   0   0   0  29  66  18]\n",
            " [  0   7   2   0   0 487 228  95]\n",
            " [  0   2   0   0   4  96 307 170]\n",
            " [  0   4   0   0   1 133 280 407]]\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                   Kick     0.0000    0.0000    0.0000        20\n",
            "                Snare 1     0.1765    0.1500    0.1622        20\n",
            "                    Tom     0.0000    0.0000    0.0000        19\n",
            "                Snare 2     0.0000    0.0000    0.0000        21\n",
            "      Natural Harmonics     0.0000    0.0000    0.0000       114\n",
            "              Palm Mute     0.6005    0.5946    0.5975       819\n",
            "       Pick Near Bridge     0.3453    0.5302    0.4183       579\n",
            "Pick Over the Soundhole     0.5882    0.4933    0.5366       825\n",
            "\n",
            "               accuracy                         0.4981      2417\n",
            "              macro avg     0.2138    0.2210    0.2143      2417\n",
            "           weighted avg     0.4884    0.4981    0.4872      2417\n",
            "\n",
            "Selecting augmented data for fold 2 ...\n",
            "Found 67788 augmented samples for fold 2\n",
            "\n",
            "Fold [3/6]\n",
            "Selecting Split Data...\n",
            "Taking validation split from provided indexes\n",
            "Normalizing Data...\n",
            "Done.\n",
            "sampling_strategy: {0: 383, 1: 330, 2: 378, 3: 420, 4: 886, 5: 5164, 6: 4738, 7: 5163}\n",
            "Adding augmented data to training set...\n",
            "Length of training set before augmentation:  17462\n",
            "Length of training set after augmentation:  85250\n",
            "Model compiled\n",
            "Epoch 1/120\n",
            "84/84 [==============================] - 2s 21ms/step - loss: 2.3154 - accuracy: 0.1946 - val_loss: 1.7232 - val_accuracy: 0.3087\n",
            "Epoch 2/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.8388 - accuracy: 0.3611 - val_loss: 1.6053 - val_accuracy: 0.3105\n",
            "Epoch 3/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.5639 - accuracy: 0.4624 - val_loss: 1.5085 - val_accuracy: 0.3152\n",
            "Epoch 4/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3995 - accuracy: 0.5044 - val_loss: 1.4368 - val_accuracy: 0.3244\n",
            "Epoch 5/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2969 - accuracy: 0.5267 - val_loss: 1.4108 - val_accuracy: 0.3410\n",
            "Epoch 6/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2280 - accuracy: 0.5414 - val_loss: 1.3837 - val_accuracy: 0.3632\n",
            "Epoch 7/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1727 - accuracy: 0.5550 - val_loss: 1.3763 - val_accuracy: 0.3771\n",
            "Epoch 8/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1320 - accuracy: 0.5671 - val_loss: 1.3867 - val_accuracy: 0.3651\n",
            "Epoch 9/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1009 - accuracy: 0.5765 - val_loss: 1.3608 - val_accuracy: 0.3854\n",
            "Epoch 10/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0701 - accuracy: 0.5872 - val_loss: 1.3463 - val_accuracy: 0.4011\n",
            "Epoch 11/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0462 - accuracy: 0.5947 - val_loss: 1.3427 - val_accuracy: 0.4002\n",
            "Epoch 12/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0264 - accuracy: 0.6006 - val_loss: 1.3426 - val_accuracy: 0.4039\n",
            "Epoch 13/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0068 - accuracy: 0.6079 - val_loss: 1.3502 - val_accuracy: 0.3882\n",
            "Epoch 14/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9922 - accuracy: 0.6130 - val_loss: 1.3857 - val_accuracy: 0.3789\n",
            "Epoch 15/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9783 - accuracy: 0.6207 - val_loss: 1.3513 - val_accuracy: 0.4067\n",
            "Epoch 16/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9664 - accuracy: 0.6243 - val_loss: 1.3593 - val_accuracy: 0.4020\n",
            "Epoch 17/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9556 - accuracy: 0.6277 - val_loss: 1.3511 - val_accuracy: 0.4020\n",
            "Epoch 18/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9489 - accuracy: 0.6296 - val_loss: 1.3688 - val_accuracy: 0.3872\n",
            "Epoch 19/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9375 - accuracy: 0.6347 - val_loss: 1.3756 - val_accuracy: 0.3799\n",
            "Epoch 20/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9268 - accuracy: 0.6391 - val_loss: 1.3932 - val_accuracy: 0.3919\n",
            "Epoch 21/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9188 - accuracy: 0.6431 - val_loss: 1.3456 - val_accuracy: 0.4122\n",
            "Epoch 22/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9112 - accuracy: 0.6460 - val_loss: 1.3464 - val_accuracy: 0.4067\n",
            "Epoch 23/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9032 - accuracy: 0.6495 - val_loss: 1.3530 - val_accuracy: 0.4067\n",
            "Epoch 24/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8967 - accuracy: 0.6516 - val_loss: 1.3945 - val_accuracy: 0.3900\n",
            "Epoch 25/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8928 - accuracy: 0.6541 - val_loss: 1.3394 - val_accuracy: 0.4214\n",
            "Epoch 26/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8868 - accuracy: 0.6554 - val_loss: 1.3488 - val_accuracy: 0.4177\n",
            "Epoch 27/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8763 - accuracy: 0.6622 - val_loss: 1.3640 - val_accuracy: 0.4131\n",
            "Epoch 28/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8758 - accuracy: 0.6588 - val_loss: 1.3398 - val_accuracy: 0.4177\n",
            "Epoch 29/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8695 - accuracy: 0.6632 - val_loss: 1.3359 - val_accuracy: 0.4270\n",
            "Epoch 30/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8637 - accuracy: 0.6642 - val_loss: 1.3455 - val_accuracy: 0.4288\n",
            "Epoch 31/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8592 - accuracy: 0.6670 - val_loss: 1.3336 - val_accuracy: 0.4288\n",
            "Epoch 32/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8531 - accuracy: 0.6696 - val_loss: 1.3340 - val_accuracy: 0.4288\n",
            "Epoch 33/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8495 - accuracy: 0.6694 - val_loss: 1.3401 - val_accuracy: 0.4187\n",
            "Epoch 34/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8441 - accuracy: 0.6735 - val_loss: 1.3335 - val_accuracy: 0.4279\n",
            "Epoch 35/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8410 - accuracy: 0.6740 - val_loss: 1.3293 - val_accuracy: 0.4261\n",
            "Epoch 36/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8357 - accuracy: 0.6778 - val_loss: 1.3569 - val_accuracy: 0.4261\n",
            "Epoch 37/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8322 - accuracy: 0.6765 - val_loss: 1.3336 - val_accuracy: 0.4372\n",
            "Epoch 38/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8265 - accuracy: 0.6800 - val_loss: 1.3427 - val_accuracy: 0.4288\n",
            "Epoch 39/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8244 - accuracy: 0.6811 - val_loss: 1.3163 - val_accuracy: 0.4455\n",
            "Epoch 40/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8198 - accuracy: 0.6836 - val_loss: 1.3227 - val_accuracy: 0.4279\n",
            "Epoch 41/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8132 - accuracy: 0.6849 - val_loss: 1.3199 - val_accuracy: 0.4279\n",
            "Epoch 42/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8136 - accuracy: 0.6854 - val_loss: 1.3191 - val_accuracy: 0.4455\n",
            "Epoch 43/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8077 - accuracy: 0.6893 - val_loss: 1.3157 - val_accuracy: 0.4436\n",
            "Epoch 44/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8048 - accuracy: 0.6900 - val_loss: 1.3030 - val_accuracy: 0.4427\n",
            "Epoch 45/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8017 - accuracy: 0.6920 - val_loss: 1.3260 - val_accuracy: 0.4409\n",
            "Epoch 46/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7978 - accuracy: 0.6919 - val_loss: 1.3105 - val_accuracy: 0.4510\n",
            "Epoch 47/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7938 - accuracy: 0.6941 - val_loss: 1.3065 - val_accuracy: 0.4501\n",
            "Epoch 48/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7917 - accuracy: 0.6947 - val_loss: 1.3337 - val_accuracy: 0.4409\n",
            "Epoch 49/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7896 - accuracy: 0.6950 - val_loss: 1.3195 - val_accuracy: 0.4455\n",
            "Epoch 50/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7873 - accuracy: 0.6967 - val_loss: 1.3032 - val_accuracy: 0.4464\n",
            "Epoch 51/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7816 - accuracy: 0.6980 - val_loss: 1.3183 - val_accuracy: 0.4436\n",
            "Epoch 52/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7778 - accuracy: 0.7000 - val_loss: 1.3247 - val_accuracy: 0.4381\n",
            "Epoch 53/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7740 - accuracy: 0.7000 - val_loss: 1.3146 - val_accuracy: 0.4399\n",
            "Epoch 54/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7756 - accuracy: 0.7009 - val_loss: 1.3017 - val_accuracy: 0.4556\n",
            "Epoch 55/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7691 - accuracy: 0.7032 - val_loss: 1.3092 - val_accuracy: 0.4445\n",
            "Epoch 56/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7697 - accuracy: 0.7028 - val_loss: 1.2956 - val_accuracy: 0.4584\n",
            "Epoch 57/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7635 - accuracy: 0.7055 - val_loss: 1.2924 - val_accuracy: 0.4593\n",
            "Epoch 58/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7615 - accuracy: 0.7067 - val_loss: 1.3057 - val_accuracy: 0.4519\n",
            "Epoch 59/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7588 - accuracy: 0.7066 - val_loss: 1.2958 - val_accuracy: 0.4538\n",
            "Epoch 60/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7623 - accuracy: 0.7054 - val_loss: 1.2937 - val_accuracy: 0.4584\n",
            "Epoch 61/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7537 - accuracy: 0.7106 - val_loss: 1.2974 - val_accuracy: 0.4529\n",
            "Epoch 62/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7528 - accuracy: 0.7109 - val_loss: 1.3081 - val_accuracy: 0.4510\n",
            "Epoch 63/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7526 - accuracy: 0.7106 - val_loss: 1.3018 - val_accuracy: 0.4372\n",
            "Epoch 64/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7492 - accuracy: 0.7123 - val_loss: 1.2986 - val_accuracy: 0.4464\n",
            "Epoch 65/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7465 - accuracy: 0.7122 - val_loss: 1.2999 - val_accuracy: 0.4621\n",
            "Epoch 66/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7471 - accuracy: 0.7128 - val_loss: 1.3094 - val_accuracy: 0.4445\n",
            "Epoch 67/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7434 - accuracy: 0.7149 - val_loss: 1.2816 - val_accuracy: 0.4667\n",
            "Epoch 68/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7423 - accuracy: 0.7132 - val_loss: 1.2698 - val_accuracy: 0.4630\n",
            "Epoch 69/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7395 - accuracy: 0.7161 - val_loss: 1.2887 - val_accuracy: 0.4482\n",
            "Epoch 70/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7353 - accuracy: 0.7176 - val_loss: 1.2727 - val_accuracy: 0.4640\n",
            "Epoch 71/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7386 - accuracy: 0.7145 - val_loss: 1.2845 - val_accuracy: 0.4547\n",
            "Epoch 72/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7362 - accuracy: 0.7167 - val_loss: 1.2587 - val_accuracy: 0.4593\n",
            "Epoch 73/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7314 - accuracy: 0.7168 - val_loss: 1.2712 - val_accuracy: 0.4575\n",
            "Epoch 74/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7324 - accuracy: 0.7163 - val_loss: 1.2715 - val_accuracy: 0.4612\n",
            "Epoch 75/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7269 - accuracy: 0.7197 - val_loss: 1.2775 - val_accuracy: 0.4575\n",
            "Epoch 76/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7275 - accuracy: 0.7214 - val_loss: 1.2683 - val_accuracy: 0.4704\n",
            "Epoch 77/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7247 - accuracy: 0.7214 - val_loss: 1.2828 - val_accuracy: 0.4630\n",
            "Epoch 78/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7231 - accuracy: 0.7214 - val_loss: 1.2610 - val_accuracy: 0.4621\n",
            "Epoch 79/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7220 - accuracy: 0.7226 - val_loss: 1.2643 - val_accuracy: 0.4787\n",
            "Epoch 80/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7211 - accuracy: 0.7219 - val_loss: 1.2491 - val_accuracy: 0.4695\n",
            "Epoch 81/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7182 - accuracy: 0.7239 - val_loss: 1.2928 - val_accuracy: 0.4510\n",
            "Epoch 82/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7190 - accuracy: 0.7239 - val_loss: 1.2588 - val_accuracy: 0.4741\n",
            "Epoch 83/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7144 - accuracy: 0.7246 - val_loss: 1.2676 - val_accuracy: 0.4621\n",
            "Epoch 84/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7175 - accuracy: 0.7234 - val_loss: 1.2726 - val_accuracy: 0.4612\n",
            "Epoch 85/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7120 - accuracy: 0.7250 - val_loss: 1.2629 - val_accuracy: 0.4649\n",
            "Epoch 86/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7079 - accuracy: 0.7273 - val_loss: 1.2579 - val_accuracy: 0.4677\n",
            "Epoch 87/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7111 - accuracy: 0.7261 - val_loss: 1.2555 - val_accuracy: 0.4686\n",
            "Epoch 88/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7091 - accuracy: 0.7264 - val_loss: 1.2599 - val_accuracy: 0.4566\n",
            "Epoch 89/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7103 - accuracy: 0.7267 - val_loss: 1.2481 - val_accuracy: 0.4713\n",
            "Epoch 90/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7058 - accuracy: 0.7272 - val_loss: 1.2469 - val_accuracy: 0.4760\n",
            "Epoch 91/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7060 - accuracy: 0.7266 - val_loss: 1.2574 - val_accuracy: 0.4593\n",
            "Epoch 92/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7043 - accuracy: 0.7291 - val_loss: 1.2353 - val_accuracy: 0.4750\n",
            "Epoch 93/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7041 - accuracy: 0.7287 - val_loss: 1.2333 - val_accuracy: 0.4732\n",
            "Epoch 94/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6988 - accuracy: 0.7302 - val_loss: 1.2447 - val_accuracy: 0.4713\n",
            "Epoch 95/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6994 - accuracy: 0.7313 - val_loss: 1.2441 - val_accuracy: 0.4704\n",
            "Epoch 96/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7011 - accuracy: 0.7305 - val_loss: 1.2292 - val_accuracy: 0.4732\n",
            "Epoch 97/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7004 - accuracy: 0.7308 - val_loss: 1.2348 - val_accuracy: 0.4750\n",
            "Epoch 98/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6969 - accuracy: 0.7327 - val_loss: 1.2234 - val_accuracy: 0.4824\n",
            "Epoch 99/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6947 - accuracy: 0.7333 - val_loss: 1.2362 - val_accuracy: 0.4732\n",
            "Epoch 100/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6959 - accuracy: 0.7316 - val_loss: 1.2348 - val_accuracy: 0.4556\n",
            "Epoch 101/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6938 - accuracy: 0.7328 - val_loss: 1.2310 - val_accuracy: 0.4723\n",
            "Epoch 102/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6918 - accuracy: 0.7341 - val_loss: 1.2437 - val_accuracy: 0.4649\n",
            "Epoch 103/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6936 - accuracy: 0.7354 - val_loss: 1.2488 - val_accuracy: 0.4640\n",
            "Epoch 104/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6907 - accuracy: 0.7333 - val_loss: 1.2249 - val_accuracy: 0.4769\n",
            "Epoch 105/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6887 - accuracy: 0.7348 - val_loss: 1.2302 - val_accuracy: 0.4778\n",
            "Epoch 106/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6874 - accuracy: 0.7357 - val_loss: 1.2498 - val_accuracy: 0.4593\n",
            "Epoch 107/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6858 - accuracy: 0.7364 - val_loss: 1.2506 - val_accuracy: 0.4575\n",
            "Epoch 108/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6900 - accuracy: 0.7336 - val_loss: 1.2439 - val_accuracy: 0.4640\n",
            "Epoch 109/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6854 - accuracy: 0.7371 - val_loss: 1.2401 - val_accuracy: 0.4640\n",
            "Epoch 110/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6822 - accuracy: 0.7377 - val_loss: 1.2315 - val_accuracy: 0.4630\n",
            "Epoch 111/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6856 - accuracy: 0.7370 - val_loss: 1.2291 - val_accuracy: 0.4732\n",
            "Epoch 112/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6855 - accuracy: 0.7379 - val_loss: 1.2448 - val_accuracy: 0.4658\n",
            "Epoch 113/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6805 - accuracy: 0.7391 - val_loss: 1.2581 - val_accuracy: 0.4538\n",
            "Epoch 114/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6811 - accuracy: 0.7395 - val_loss: 1.2361 - val_accuracy: 0.4621\n",
            "Epoch 115/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6804 - accuracy: 0.7391 - val_loss: 1.2376 - val_accuracy: 0.4649\n",
            "Epoch 116/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6792 - accuracy: 0.7394 - val_loss: 1.2411 - val_accuracy: 0.4649\n",
            "Epoch 117/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6794 - accuracy: 0.7398 - val_loss: 1.2428 - val_accuracy: 0.4778\n",
            "Epoch 118/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6771 - accuracy: 0.7394 - val_loss: 1.2513 - val_accuracy: 0.4547\n",
            "Epoch 119/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6761 - accuracy: 0.7413 - val_loss: 1.2345 - val_accuracy: 0.4658\n",
            "Epoch 120/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6787 - accuracy: 0.7385 - val_loss: 1.2690 - val_accuracy: 0.4409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_513425/2383121875.py:12: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  f1score = 2 /((1/precision)+(1/recall))\n",
            "/tmp/ipykernel_513425/2383121875.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  precision = 1.0 * true_positives / np.sum(classPrediction)\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.44409199048374304\n",
            "Test macro_weighted_avg f1-score: nan\n",
            "[[  0   0   0   0   0   9   5   0]\n",
            " [  0   3   0   0   0   2  14   1]\n",
            " [  0   0   2   0   0  19   0   0]\n",
            " [  0   0   0   0   0   0  12   9]\n",
            " [  1   0   0   0   0  47  55   8]\n",
            " [  3   3  11   3   0 538 175  46]\n",
            " [  1   2  16   0   0 291 321 140]\n",
            " [  0   0  13   0   0 242 274 256]]\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                   Kick     0.0000    0.0000    0.0000        14\n",
            "                Snare 1     0.3750    0.1500    0.2143        20\n",
            "                    Tom     0.0476    0.0952    0.0635        21\n",
            "                Snare 2     0.0000    0.0000    0.0000        21\n",
            "      Natural Harmonics     0.0000    0.0000    0.0000       111\n",
            "              Palm Mute     0.4686    0.6906    0.5584       779\n",
            "       Pick Near Bridge     0.3750    0.4163    0.3946       771\n",
            "Pick Over the Soundhole     0.5565    0.3261    0.4112       785\n",
            "\n",
            "               accuracy                         0.4441      2522\n",
            "              macro avg     0.2278    0.2098    0.2052      2522\n",
            "           weighted avg     0.4360    0.4441    0.4233      2522\n",
            "\n",
            "Selecting augmented data for fold 3 ...\n",
            "Found 69211 augmented samples for fold 3\n",
            "\n",
            "Fold [4/6]\n",
            "Selecting Split Data...\n",
            "Taking validation split from provided indexes\n",
            "Normalizing Data...\n",
            "Done.\n",
            "sampling_strategy: {0: 373, 1: 329, 2: 379, 3: 420, 4: 902, 5: 5284, 6: 4822, 7: 5305}\n",
            "Adding augmented data to training set...\n",
            "Length of training set before augmentation:  17814\n",
            "Length of training set after augmentation:  87025\n",
            "Model compiled\n",
            "Epoch 1/120\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 2.3056 - accuracy: 0.2065 - val_loss: 1.9124 - val_accuracy: 0.3012\n",
            "Epoch 2/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.7902 - accuracy: 0.3933 - val_loss: 1.7897 - val_accuracy: 0.3453\n",
            "Epoch 3/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.5587 - accuracy: 0.4669 - val_loss: 1.6361 - val_accuracy: 0.3115\n",
            "Epoch 4/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.4203 - accuracy: 0.4975 - val_loss: 1.5224 - val_accuracy: 0.3207\n",
            "Epoch 5/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.3264 - accuracy: 0.5161 - val_loss: 1.4371 - val_accuracy: 0.3678\n",
            "Epoch 6/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.2637 - accuracy: 0.5278 - val_loss: 1.3835 - val_accuracy: 0.4088\n",
            "Epoch 7/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.2196 - accuracy: 0.5393 - val_loss: 1.3598 - val_accuracy: 0.3996\n",
            "Epoch 8/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.1816 - accuracy: 0.5503 - val_loss: 1.3377 - val_accuracy: 0.4078\n",
            "Epoch 9/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.1538 - accuracy: 0.5589 - val_loss: 1.3295 - val_accuracy: 0.4344\n",
            "Epoch 10/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.1267 - accuracy: 0.5671 - val_loss: 1.3140 - val_accuracy: 0.4160\n",
            "Epoch 11/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.1043 - accuracy: 0.5738 - val_loss: 1.2988 - val_accuracy: 0.4498\n",
            "Epoch 12/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0824 - accuracy: 0.5829 - val_loss: 1.2986 - val_accuracy: 0.4365\n",
            "Epoch 13/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0658 - accuracy: 0.5866 - val_loss: 1.2864 - val_accuracy: 0.4498\n",
            "Epoch 14/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0488 - accuracy: 0.5905 - val_loss: 1.2920 - val_accuracy: 0.4406\n",
            "Epoch 15/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0371 - accuracy: 0.5948 - val_loss: 1.3114 - val_accuracy: 0.4303\n",
            "Epoch 16/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0247 - accuracy: 0.6002 - val_loss: 1.2731 - val_accuracy: 0.4529\n",
            "Epoch 17/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0150 - accuracy: 0.6028 - val_loss: 1.2640 - val_accuracy: 0.4477\n",
            "Epoch 18/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0022 - accuracy: 0.6074 - val_loss: 1.2643 - val_accuracy: 0.4580\n",
            "Epoch 19/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9932 - accuracy: 0.6124 - val_loss: 1.2612 - val_accuracy: 0.4600\n",
            "Epoch 20/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9808 - accuracy: 0.6179 - val_loss: 1.2544 - val_accuracy: 0.4221\n",
            "Epoch 21/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9725 - accuracy: 0.6188 - val_loss: 1.2702 - val_accuracy: 0.4641\n",
            "Epoch 22/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9629 - accuracy: 0.6243 - val_loss: 1.2331 - val_accuracy: 0.4652\n",
            "Epoch 23/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9580 - accuracy: 0.6240 - val_loss: 1.2389 - val_accuracy: 0.4549\n",
            "Epoch 24/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9518 - accuracy: 0.6278 - val_loss: 1.2350 - val_accuracy: 0.4406\n",
            "Epoch 25/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9436 - accuracy: 0.6299 - val_loss: 1.2368 - val_accuracy: 0.4559\n",
            "Epoch 26/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9380 - accuracy: 0.6319 - val_loss: 1.2282 - val_accuracy: 0.4652\n",
            "Epoch 27/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9274 - accuracy: 0.6371 - val_loss: 1.2466 - val_accuracy: 0.4068\n",
            "Epoch 28/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9223 - accuracy: 0.6369 - val_loss: 1.2160 - val_accuracy: 0.4703\n",
            "Epoch 29/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.9168 - accuracy: 0.6383 - val_loss: 1.2315 - val_accuracy: 0.4764\n",
            "Epoch 30/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9156 - accuracy: 0.6416 - val_loss: 1.1967 - val_accuracy: 0.4795\n",
            "Epoch 31/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9072 - accuracy: 0.6417 - val_loss: 1.1963 - val_accuracy: 0.4703\n",
            "Epoch 32/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8986 - accuracy: 0.6464 - val_loss: 1.1930 - val_accuracy: 0.4775\n",
            "Epoch 33/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8955 - accuracy: 0.6482 - val_loss: 1.2068 - val_accuracy: 0.5051\n",
            "Epoch 34/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8887 - accuracy: 0.6505 - val_loss: 1.1841 - val_accuracy: 0.4764\n",
            "Epoch 35/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8875 - accuracy: 0.6522 - val_loss: 1.1926 - val_accuracy: 0.4969\n",
            "Epoch 36/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8809 - accuracy: 0.6542 - val_loss: 1.1950 - val_accuracy: 0.4734\n",
            "Epoch 37/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8740 - accuracy: 0.6582 - val_loss: 1.2080 - val_accuracy: 0.4816\n",
            "Epoch 38/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8716 - accuracy: 0.6590 - val_loss: 1.1910 - val_accuracy: 0.4918\n",
            "Epoch 39/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8668 - accuracy: 0.6614 - val_loss: 1.1747 - val_accuracy: 0.4877\n",
            "Epoch 40/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8606 - accuracy: 0.6619 - val_loss: 1.1774 - val_accuracy: 0.4754\n",
            "Epoch 41/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8603 - accuracy: 0.6645 - val_loss: 1.1767 - val_accuracy: 0.4857\n",
            "Epoch 42/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8560 - accuracy: 0.6639 - val_loss: 1.1716 - val_accuracy: 0.4836\n",
            "Epoch 43/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8514 - accuracy: 0.6650 - val_loss: 1.1821 - val_accuracy: 0.4939\n",
            "Epoch 44/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8451 - accuracy: 0.6697 - val_loss: 1.1904 - val_accuracy: 0.4959\n",
            "Epoch 45/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8447 - accuracy: 0.6688 - val_loss: 1.1832 - val_accuracy: 0.4908\n",
            "Epoch 46/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8388 - accuracy: 0.6704 - val_loss: 1.1778 - val_accuracy: 0.4918\n",
            "Epoch 47/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8374 - accuracy: 0.6726 - val_loss: 1.1763 - val_accuracy: 0.4980\n",
            "Epoch 48/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8299 - accuracy: 0.6756 - val_loss: 1.1784 - val_accuracy: 0.4959\n",
            "Epoch 49/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8286 - accuracy: 0.6765 - val_loss: 1.1720 - val_accuracy: 0.4836\n",
            "Epoch 50/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8250 - accuracy: 0.6773 - val_loss: 1.2032 - val_accuracy: 0.4703\n",
            "Epoch 51/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8253 - accuracy: 0.6769 - val_loss: 1.1885 - val_accuracy: 0.4877\n",
            "Epoch 52/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8202 - accuracy: 0.6782 - val_loss: 1.1904 - val_accuracy: 0.4682\n",
            "Epoch 53/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8176 - accuracy: 0.6823 - val_loss: 1.1903 - val_accuracy: 0.4734\n",
            "Epoch 54/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8135 - accuracy: 0.6806 - val_loss: 1.1710 - val_accuracy: 0.4939\n",
            "Epoch 55/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8149 - accuracy: 0.6812 - val_loss: 1.1804 - val_accuracy: 0.4836\n",
            "Epoch 56/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8124 - accuracy: 0.6813 - val_loss: 1.2014 - val_accuracy: 0.4477\n",
            "Epoch 57/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8066 - accuracy: 0.6857 - val_loss: 1.2295 - val_accuracy: 0.4529\n",
            "Epoch 58/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8065 - accuracy: 0.6844 - val_loss: 1.2031 - val_accuracy: 0.4703\n",
            "Epoch 59/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8014 - accuracy: 0.6853 - val_loss: 1.1900 - val_accuracy: 0.4672\n",
            "Epoch 60/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8018 - accuracy: 0.6868 - val_loss: 1.1906 - val_accuracy: 0.4764\n",
            "Epoch 61/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7984 - accuracy: 0.6878 - val_loss: 1.2037 - val_accuracy: 0.4580\n",
            "Epoch 62/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7955 - accuracy: 0.6900 - val_loss: 1.1794 - val_accuracy: 0.4836\n",
            "Epoch 63/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7951 - accuracy: 0.6883 - val_loss: 1.2083 - val_accuracy: 0.4631\n",
            "Epoch 64/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7935 - accuracy: 0.6907 - val_loss: 1.1770 - val_accuracy: 0.4877\n",
            "Epoch 65/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7915 - accuracy: 0.6910 - val_loss: 1.2039 - val_accuracy: 0.4682\n",
            "Epoch 66/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7871 - accuracy: 0.6929 - val_loss: 1.1953 - val_accuracy: 0.4580\n",
            "Epoch 67/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7880 - accuracy: 0.6907 - val_loss: 1.1879 - val_accuracy: 0.4775\n",
            "Epoch 68/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7839 - accuracy: 0.6939 - val_loss: 1.1870 - val_accuracy: 0.4713\n",
            "Epoch 69/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7838 - accuracy: 0.6928 - val_loss: 1.1969 - val_accuracy: 0.4621\n",
            "Epoch 70/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7829 - accuracy: 0.6935 - val_loss: 1.2114 - val_accuracy: 0.4590\n",
            "Epoch 71/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7803 - accuracy: 0.6959 - val_loss: 1.1743 - val_accuracy: 0.4713\n",
            "Epoch 72/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7753 - accuracy: 0.6962 - val_loss: 1.1989 - val_accuracy: 0.4631\n",
            "Epoch 73/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7748 - accuracy: 0.6970 - val_loss: 1.2234 - val_accuracy: 0.4365\n",
            "Epoch 74/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7749 - accuracy: 0.6978 - val_loss: 1.2083 - val_accuracy: 0.4580\n",
            "Epoch 75/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7721 - accuracy: 0.6974 - val_loss: 1.2088 - val_accuracy: 0.4529\n",
            "Epoch 76/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7704 - accuracy: 0.6979 - val_loss: 1.1939 - val_accuracy: 0.4672\n",
            "Epoch 77/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7675 - accuracy: 0.7008 - val_loss: 1.2111 - val_accuracy: 0.4549\n",
            "Epoch 78/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7652 - accuracy: 0.7011 - val_loss: 1.2222 - val_accuracy: 0.4477\n",
            "Epoch 79/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7616 - accuracy: 0.7032 - val_loss: 1.2006 - val_accuracy: 0.4662\n",
            "Epoch 80/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7641 - accuracy: 0.7017 - val_loss: 1.1959 - val_accuracy: 0.4662\n",
            "Epoch 81/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7618 - accuracy: 0.7021 - val_loss: 1.1826 - val_accuracy: 0.4775\n",
            "Epoch 82/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7616 - accuracy: 0.7028 - val_loss: 1.1949 - val_accuracy: 0.4682\n",
            "Epoch 83/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7591 - accuracy: 0.7038 - val_loss: 1.1900 - val_accuracy: 0.4682\n",
            "Epoch 84/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7551 - accuracy: 0.7061 - val_loss: 1.2040 - val_accuracy: 0.4641\n",
            "Epoch 85/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7577 - accuracy: 0.7039 - val_loss: 1.1907 - val_accuracy: 0.4662\n",
            "Epoch 86/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7512 - accuracy: 0.7062 - val_loss: 1.1960 - val_accuracy: 0.4570\n",
            "Epoch 87/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7486 - accuracy: 0.7079 - val_loss: 1.1988 - val_accuracy: 0.4580\n",
            "Epoch 88/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7493 - accuracy: 0.7080 - val_loss: 1.1845 - val_accuracy: 0.4816\n",
            "Epoch 89/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7492 - accuracy: 0.7085 - val_loss: 1.1774 - val_accuracy: 0.4641\n",
            "Epoch 90/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7431 - accuracy: 0.7098 - val_loss: 1.1774 - val_accuracy: 0.4775\n",
            "Epoch 91/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7431 - accuracy: 0.7097 - val_loss: 1.2120 - val_accuracy: 0.4539\n",
            "Epoch 92/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7433 - accuracy: 0.7107 - val_loss: 1.1958 - val_accuracy: 0.4703\n",
            "Epoch 93/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7401 - accuracy: 0.7108 - val_loss: 1.2061 - val_accuracy: 0.4641\n",
            "Epoch 94/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7368 - accuracy: 0.7126 - val_loss: 1.1876 - val_accuracy: 0.4662\n",
            "Epoch 95/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7391 - accuracy: 0.7119 - val_loss: 1.1923 - val_accuracy: 0.4621\n",
            "Epoch 96/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7396 - accuracy: 0.7119 - val_loss: 1.2056 - val_accuracy: 0.4611\n",
            "Epoch 97/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7344 - accuracy: 0.7135 - val_loss: 1.1758 - val_accuracy: 0.4754\n",
            "Epoch 98/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7371 - accuracy: 0.7115 - val_loss: 1.1974 - val_accuracy: 0.4395\n",
            "Epoch 99/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7357 - accuracy: 0.7129 - val_loss: 1.1736 - val_accuracy: 0.4805\n",
            "Epoch 100/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7352 - accuracy: 0.7131 - val_loss: 1.1758 - val_accuracy: 0.4641\n",
            "Epoch 101/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7353 - accuracy: 0.7120 - val_loss: 1.1800 - val_accuracy: 0.4631\n",
            "Epoch 102/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7316 - accuracy: 0.7157 - val_loss: 1.1956 - val_accuracy: 0.4682\n",
            "Epoch 103/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7304 - accuracy: 0.7134 - val_loss: 1.1936 - val_accuracy: 0.4703\n",
            "Epoch 104/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7288 - accuracy: 0.7155 - val_loss: 1.1659 - val_accuracy: 0.4857\n",
            "Epoch 105/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7276 - accuracy: 0.7156 - val_loss: 1.2055 - val_accuracy: 0.4672\n",
            "Epoch 106/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7249 - accuracy: 0.7181 - val_loss: 1.1621 - val_accuracy: 0.4836\n",
            "Epoch 107/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7213 - accuracy: 0.7194 - val_loss: 1.1786 - val_accuracy: 0.4611\n",
            "Epoch 108/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7282 - accuracy: 0.7164 - val_loss: 1.1672 - val_accuracy: 0.4744\n",
            "Epoch 109/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7238 - accuracy: 0.7168 - val_loss: 1.1803 - val_accuracy: 0.4693\n",
            "Epoch 110/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7227 - accuracy: 0.7185 - val_loss: 1.1848 - val_accuracy: 0.4754\n",
            "Epoch 111/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7190 - accuracy: 0.7207 - val_loss: 1.1674 - val_accuracy: 0.4836\n",
            "Epoch 112/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7208 - accuracy: 0.7195 - val_loss: 1.1632 - val_accuracy: 0.4990\n",
            "Epoch 113/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7170 - accuracy: 0.7210 - val_loss: 1.1863 - val_accuracy: 0.4559\n",
            "Epoch 114/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7189 - accuracy: 0.7210 - val_loss: 1.1676 - val_accuracy: 0.4775\n",
            "Epoch 115/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7202 - accuracy: 0.7201 - val_loss: 1.1779 - val_accuracy: 0.4795\n",
            "Epoch 116/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7168 - accuracy: 0.7211 - val_loss: 1.1710 - val_accuracy: 0.4734\n",
            "Epoch 117/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7136 - accuracy: 0.7208 - val_loss: 1.1772 - val_accuracy: 0.4785\n",
            "Epoch 118/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7141 - accuracy: 0.7220 - val_loss: 1.1847 - val_accuracy: 0.4600\n",
            "Epoch 119/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7130 - accuracy: 0.7222 - val_loss: 1.1924 - val_accuracy: 0.4662\n",
            "Epoch 120/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7137 - accuracy: 0.7226 - val_loss: 1.1798 - val_accuracy: 0.4703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_513425/2383121875.py:12: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  f1score = 2 /((1/precision)+(1/recall))\n",
            "/tmp/ipykernel_513425/2383121875.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  precision = 1.0 * true_positives / np.sum(classPrediction)\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.46528998242530756\n",
            "Test macro_weighted_avg f1-score: nan\n",
            "[[  1   0   0   9   0  11   0   0]\n",
            " [  0  10   0   0   0   1   4   6]\n",
            " [  0   1   4   1   0  10   1   3]\n",
            " [  0   0   0   0   0  16   4   1]\n",
            " [  0   0   0   0   0  46  28  26]\n",
            " [  0   0   1   0   0 475  16 203]\n",
            " [  0   0   0   0   0 263 175 274]\n",
            " [  0   1   0   0   0 226  65 394]]\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                   Kick     1.0000    0.0476    0.0909        21\n",
            "                Snare 1     0.8333    0.4762    0.6061        21\n",
            "                    Tom     0.8000    0.2000    0.3200        20\n",
            "                Snare 2     0.0000    0.0000    0.0000        21\n",
            "      Natural Harmonics     0.0000    0.0000    0.0000       100\n",
            "              Palm Mute     0.4532    0.6835    0.5450       695\n",
            "       Pick Near Bridge     0.5973    0.2458    0.3483       712\n",
            "Pick Over the Soundhole     0.4344    0.5743    0.4947       686\n",
            "\n",
            "               accuracy                         0.4653      2276\n",
            "              macro avg     0.5148    0.2784    0.3006      2276\n",
            "           weighted avg     0.4801    0.4653    0.4337      2276\n",
            "\n",
            "Selecting augmented data for fold 4 ...\n",
            "Found 68429 augmented samples for fold 4\n",
            "\n",
            "Fold [5/6]\n",
            "Selecting Split Data...\n",
            "Taking validation split from provided indexes\n",
            "Normalizing Data...\n",
            "Done.\n",
            "sampling_strategy: {0: 376, 1: 329, 2: 378, 3: 420, 4: 891, 5: 5154, 6: 4816, 7: 5214}\n",
            "Adding augmented data to training set...\n",
            "Length of training set before augmentation:  17578\n",
            "Length of training set after augmentation:  86007\n",
            "Model compiled\n",
            "Epoch 1/120\n",
            "84/84 [==============================] - 2s 20ms/step - loss: 2.3604 - accuracy: 0.1983 - val_loss: 1.9727 - val_accuracy: 0.0086\n",
            "Epoch 2/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.8555 - accuracy: 0.3499 - val_loss: 1.8033 - val_accuracy: 0.3133\n",
            "Epoch 3/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.5729 - accuracy: 0.4489 - val_loss: 1.6396 - val_accuracy: 0.3075\n",
            "Epoch 4/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.4209 - accuracy: 0.4895 - val_loss: 1.5718 - val_accuracy: 0.3534\n",
            "Epoch 5/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3183 - accuracy: 0.5147 - val_loss: 1.5659 - val_accuracy: 0.3582\n",
            "Epoch 6/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2479 - accuracy: 0.5370 - val_loss: 1.5968 - val_accuracy: 0.3467\n",
            "Epoch 7/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1948 - accuracy: 0.5502 - val_loss: 1.4991 - val_accuracy: 0.3591\n",
            "Epoch 8/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1549 - accuracy: 0.5607 - val_loss: 1.4420 - val_accuracy: 0.3725\n",
            "Epoch 9/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1197 - accuracy: 0.5718 - val_loss: 1.4198 - val_accuracy: 0.3763\n",
            "Epoch 10/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0964 - accuracy: 0.5780 - val_loss: 1.3862 - val_accuracy: 0.3649\n",
            "Epoch 11/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0702 - accuracy: 0.5878 - val_loss: 1.3879 - val_accuracy: 0.3286\n",
            "Epoch 12/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0484 - accuracy: 0.5979 - val_loss: 1.3483 - val_accuracy: 0.4031\n",
            "Epoch 13/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0293 - accuracy: 0.6052 - val_loss: 1.3267 - val_accuracy: 0.4451\n",
            "Epoch 14/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0114 - accuracy: 0.6135 - val_loss: 1.3310 - val_accuracy: 0.4260\n",
            "Epoch 15/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9980 - accuracy: 0.6186 - val_loss: 1.3517 - val_accuracy: 0.4031\n",
            "Epoch 16/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9876 - accuracy: 0.6202 - val_loss: 1.3468 - val_accuracy: 0.4241\n",
            "Epoch 17/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9749 - accuracy: 0.6277 - val_loss: 1.3361 - val_accuracy: 0.4394\n",
            "Epoch 18/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9666 - accuracy: 0.6304 - val_loss: 1.3376 - val_accuracy: 0.4403\n",
            "Epoch 19/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9552 - accuracy: 0.6346 - val_loss: 1.3197 - val_accuracy: 0.4327\n",
            "Epoch 20/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9446 - accuracy: 0.6375 - val_loss: 1.3205 - val_accuracy: 0.4365\n",
            "Epoch 21/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9367 - accuracy: 0.6409 - val_loss: 1.3159 - val_accuracy: 0.4384\n",
            "Epoch 22/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9331 - accuracy: 0.6423 - val_loss: 1.3268 - val_accuracy: 0.4279\n",
            "Epoch 23/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9232 - accuracy: 0.6448 - val_loss: 1.3180 - val_accuracy: 0.4374\n",
            "Epoch 24/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9192 - accuracy: 0.6481 - val_loss: 1.3205 - val_accuracy: 0.4489\n",
            "Epoch 25/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9095 - accuracy: 0.6531 - val_loss: 1.3133 - val_accuracy: 0.4451\n",
            "Epoch 26/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9040 - accuracy: 0.6543 - val_loss: 1.3075 - val_accuracy: 0.4470\n",
            "Epoch 27/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8997 - accuracy: 0.6553 - val_loss: 1.3083 - val_accuracy: 0.4403\n",
            "Epoch 28/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8920 - accuracy: 0.6588 - val_loss: 1.3097 - val_accuracy: 0.4432\n",
            "Epoch 29/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8879 - accuracy: 0.6585 - val_loss: 1.3100 - val_accuracy: 0.4537\n",
            "Epoch 30/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8832 - accuracy: 0.6637 - val_loss: 1.3154 - val_accuracy: 0.4441\n",
            "Epoch 31/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8779 - accuracy: 0.6626 - val_loss: 1.3091 - val_accuracy: 0.4470\n",
            "Epoch 32/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8700 - accuracy: 0.6671 - val_loss: 1.3058 - val_accuracy: 0.4508\n",
            "Epoch 33/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8675 - accuracy: 0.6677 - val_loss: 1.3065 - val_accuracy: 0.4604\n",
            "Epoch 34/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8608 - accuracy: 0.6714 - val_loss: 1.3011 - val_accuracy: 0.4460\n",
            "Epoch 35/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8565 - accuracy: 0.6714 - val_loss: 1.3070 - val_accuracy: 0.4594\n",
            "Epoch 36/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8500 - accuracy: 0.6741 - val_loss: 1.3145 - val_accuracy: 0.4546\n",
            "Epoch 37/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8472 - accuracy: 0.6754 - val_loss: 1.3053 - val_accuracy: 0.4460\n",
            "Epoch 38/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8411 - accuracy: 0.6758 - val_loss: 1.3003 - val_accuracy: 0.4690\n",
            "Epoch 39/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8364 - accuracy: 0.6796 - val_loss: 1.2876 - val_accuracy: 0.4479\n",
            "Epoch 40/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8341 - accuracy: 0.6807 - val_loss: 1.2873 - val_accuracy: 0.4585\n",
            "Epoch 41/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8280 - accuracy: 0.6817 - val_loss: 1.2822 - val_accuracy: 0.4661\n",
            "Epoch 42/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8239 - accuracy: 0.6825 - val_loss: 1.2925 - val_accuracy: 0.4575\n",
            "Epoch 43/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8178 - accuracy: 0.6859 - val_loss: 1.3065 - val_accuracy: 0.4518\n",
            "Epoch 44/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8180 - accuracy: 0.6858 - val_loss: 1.2882 - val_accuracy: 0.4546\n",
            "Epoch 45/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8134 - accuracy: 0.6884 - val_loss: 1.2926 - val_accuracy: 0.4518\n",
            "Epoch 46/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8087 - accuracy: 0.6883 - val_loss: 1.3080 - val_accuracy: 0.4613\n",
            "Epoch 47/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8043 - accuracy: 0.6899 - val_loss: 1.2921 - val_accuracy: 0.4594\n",
            "Epoch 48/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8036 - accuracy: 0.6903 - val_loss: 1.3133 - val_accuracy: 0.4451\n",
            "Epoch 49/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8001 - accuracy: 0.6910 - val_loss: 1.3131 - val_accuracy: 0.4527\n",
            "Epoch 50/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7969 - accuracy: 0.6921 - val_loss: 1.2786 - val_accuracy: 0.4613\n",
            "Epoch 51/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7955 - accuracy: 0.6939 - val_loss: 1.2896 - val_accuracy: 0.4613\n",
            "Epoch 52/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7894 - accuracy: 0.6955 - val_loss: 1.2788 - val_accuracy: 0.4766\n",
            "Epoch 53/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7891 - accuracy: 0.6940 - val_loss: 1.2953 - val_accuracy: 0.4690\n",
            "Epoch 54/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7846 - accuracy: 0.6980 - val_loss: 1.2761 - val_accuracy: 0.4527\n",
            "Epoch 55/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7806 - accuracy: 0.6982 - val_loss: 1.2722 - val_accuracy: 0.4575\n",
            "Epoch 56/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7769 - accuracy: 0.6996 - val_loss: 1.2938 - val_accuracy: 0.4718\n",
            "Epoch 57/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7765 - accuracy: 0.7008 - val_loss: 1.2738 - val_accuracy: 0.4661\n",
            "Epoch 58/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7711 - accuracy: 0.7027 - val_loss: 1.2713 - val_accuracy: 0.4613\n",
            "Epoch 59/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7691 - accuracy: 0.7024 - val_loss: 1.2800 - val_accuracy: 0.4690\n",
            "Epoch 60/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7670 - accuracy: 0.7032 - val_loss: 1.2716 - val_accuracy: 0.4575\n",
            "Epoch 61/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7693 - accuracy: 0.7033 - val_loss: 1.3083 - val_accuracy: 0.4575\n",
            "Epoch 62/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7627 - accuracy: 0.7048 - val_loss: 1.3352 - val_accuracy: 0.4451\n",
            "Epoch 63/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7596 - accuracy: 0.7078 - val_loss: 1.2664 - val_accuracy: 0.4651\n",
            "Epoch 64/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7606 - accuracy: 0.7054 - val_loss: 1.2616 - val_accuracy: 0.4680\n",
            "Epoch 65/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7578 - accuracy: 0.7085 - val_loss: 1.2680 - val_accuracy: 0.4699\n",
            "Epoch 66/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7533 - accuracy: 0.7081 - val_loss: 1.2636 - val_accuracy: 0.4756\n",
            "Epoch 67/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7474 - accuracy: 0.7102 - val_loss: 1.2636 - val_accuracy: 0.4661\n",
            "Epoch 68/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7470 - accuracy: 0.7106 - val_loss: 1.2616 - val_accuracy: 0.4565\n",
            "Epoch 69/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7513 - accuracy: 0.7103 - val_loss: 1.2581 - val_accuracy: 0.4642\n",
            "Epoch 70/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7476 - accuracy: 0.7105 - val_loss: 1.2862 - val_accuracy: 0.4527\n",
            "Epoch 71/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7416 - accuracy: 0.7153 - val_loss: 1.2794 - val_accuracy: 0.4613\n",
            "Epoch 72/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7385 - accuracy: 0.7148 - val_loss: 1.2676 - val_accuracy: 0.4728\n",
            "Epoch 73/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7395 - accuracy: 0.7141 - val_loss: 1.2732 - val_accuracy: 0.4594\n",
            "Epoch 74/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7386 - accuracy: 0.7137 - val_loss: 1.3076 - val_accuracy: 0.4632\n",
            "Epoch 75/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7342 - accuracy: 0.7156 - val_loss: 1.2777 - val_accuracy: 0.4680\n",
            "Epoch 76/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7337 - accuracy: 0.7152 - val_loss: 1.2916 - val_accuracy: 0.4670\n",
            "Epoch 77/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7324 - accuracy: 0.7167 - val_loss: 1.2858 - val_accuracy: 0.4527\n",
            "Epoch 78/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7294 - accuracy: 0.7180 - val_loss: 1.2734 - val_accuracy: 0.4537\n",
            "Epoch 79/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7295 - accuracy: 0.7170 - val_loss: 1.2729 - val_accuracy: 0.4585\n",
            "Epoch 80/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7275 - accuracy: 0.7188 - val_loss: 1.2582 - val_accuracy: 0.4737\n",
            "Epoch 81/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7270 - accuracy: 0.7200 - val_loss: 1.2504 - val_accuracy: 0.4642\n",
            "Epoch 82/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7244 - accuracy: 0.7197 - val_loss: 1.3004 - val_accuracy: 0.4613\n",
            "Epoch 83/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7211 - accuracy: 0.7199 - val_loss: 1.2708 - val_accuracy: 0.4632\n",
            "Epoch 84/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7196 - accuracy: 0.7207 - val_loss: 1.2625 - val_accuracy: 0.4776\n",
            "Epoch 85/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7173 - accuracy: 0.7222 - val_loss: 1.2579 - val_accuracy: 0.4785\n",
            "Epoch 86/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7132 - accuracy: 0.7243 - val_loss: 1.2618 - val_accuracy: 0.4766\n",
            "Epoch 87/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7130 - accuracy: 0.7240 - val_loss: 1.2681 - val_accuracy: 0.4737\n",
            "Epoch 88/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7127 - accuracy: 0.7241 - val_loss: 1.2648 - val_accuracy: 0.4766\n",
            "Epoch 89/120\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.7080 - accuracy: 0.7251 - val_loss: 1.2586 - val_accuracy: 0.4747\n",
            "Epoch 90/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7116 - accuracy: 0.7243 - val_loss: 1.2670 - val_accuracy: 0.4690\n",
            "Epoch 91/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7041 - accuracy: 0.7270 - val_loss: 1.2568 - val_accuracy: 0.4728\n",
            "Epoch 92/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7082 - accuracy: 0.7250 - val_loss: 1.2740 - val_accuracy: 0.4585\n",
            "Epoch 93/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7061 - accuracy: 0.7272 - val_loss: 1.2697 - val_accuracy: 0.4690\n",
            "Epoch 94/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7067 - accuracy: 0.7274 - val_loss: 1.2494 - val_accuracy: 0.4651\n",
            "Epoch 95/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7059 - accuracy: 0.7263 - val_loss: 1.2657 - val_accuracy: 0.4862\n",
            "Epoch 96/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7039 - accuracy: 0.7283 - val_loss: 1.2688 - val_accuracy: 0.4699\n",
            "Epoch 97/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7015 - accuracy: 0.7292 - val_loss: 1.2463 - val_accuracy: 0.4699\n",
            "Epoch 98/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7002 - accuracy: 0.7298 - val_loss: 1.2670 - val_accuracy: 0.4699\n",
            "Epoch 99/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6991 - accuracy: 0.7298 - val_loss: 1.2678 - val_accuracy: 0.4766\n",
            "Epoch 100/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6981 - accuracy: 0.7304 - val_loss: 1.2687 - val_accuracy: 0.4737\n",
            "Epoch 101/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6974 - accuracy: 0.7312 - val_loss: 1.3001 - val_accuracy: 0.4670\n",
            "Epoch 102/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6937 - accuracy: 0.7334 - val_loss: 1.2742 - val_accuracy: 0.4785\n",
            "Epoch 103/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6927 - accuracy: 0.7311 - val_loss: 1.2479 - val_accuracy: 0.4814\n",
            "Epoch 104/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6924 - accuracy: 0.7323 - val_loss: 1.2810 - val_accuracy: 0.4690\n",
            "Epoch 105/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6901 - accuracy: 0.7330 - val_loss: 1.2480 - val_accuracy: 0.4747\n",
            "Epoch 106/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6919 - accuracy: 0.7304 - val_loss: 1.2763 - val_accuracy: 0.4613\n",
            "Epoch 107/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6902 - accuracy: 0.7313 - val_loss: 1.2556 - val_accuracy: 0.4881\n",
            "Epoch 108/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6911 - accuracy: 0.7330 - val_loss: 1.2531 - val_accuracy: 0.4957\n",
            "Epoch 109/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6846 - accuracy: 0.7332 - val_loss: 1.2616 - val_accuracy: 0.4862\n",
            "Epoch 110/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6861 - accuracy: 0.7335 - val_loss: 1.2618 - val_accuracy: 0.4986\n",
            "Epoch 111/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6838 - accuracy: 0.7344 - val_loss: 1.2764 - val_accuracy: 0.4690\n",
            "Epoch 112/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6812 - accuracy: 0.7364 - val_loss: 1.2749 - val_accuracy: 0.4862\n",
            "Epoch 113/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6831 - accuracy: 0.7351 - val_loss: 1.2527 - val_accuracy: 0.4947\n",
            "Epoch 114/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6804 - accuracy: 0.7360 - val_loss: 1.2506 - val_accuracy: 0.4756\n",
            "Epoch 115/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6826 - accuracy: 0.7363 - val_loss: 1.2526 - val_accuracy: 0.4890\n",
            "Epoch 116/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6807 - accuracy: 0.7370 - val_loss: 1.2883 - val_accuracy: 0.4651\n",
            "Epoch 117/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6782 - accuracy: 0.7374 - val_loss: 1.2590 - val_accuracy: 0.4957\n",
            "Epoch 118/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6760 - accuracy: 0.7390 - val_loss: 1.2433 - val_accuracy: 0.4871\n",
            "Epoch 119/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6775 - accuracy: 0.7373 - val_loss: 1.2491 - val_accuracy: 0.4919\n",
            "Epoch 120/120\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6775 - accuracy: 0.7378 - val_loss: 1.2729 - val_accuracy: 0.4776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_513425/2383121875.py:12: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  f1score = 2 /((1/precision)+(1/recall))\n",
            "/tmp/ipykernel_513425/2383121875.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  precision = 1.0 * true_positives / np.sum(classPrediction)\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.48176976648914377\n",
            "Test macro_weighted_avg f1-score: nan\n",
            "[[  0   0   0   0   0  16   2   1]\n",
            " [  0   0   0   0   0  18   2   1]\n",
            " [  0   0   0   0   0  13   3   5]\n",
            " [  0   0   0   0   0  16   5   0]\n",
            " [  0   0   0   0   1  57  30  20]\n",
            " [  0   1   1   0   0 596  98  90]\n",
            " [  1   0   0   0   3 236 303 173]\n",
            " [  0   0   0   0   1 299 173 276]]\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                   Kick     0.0000    0.0000    0.0000        19\n",
            "                Snare 1     0.0000    0.0000    0.0000        21\n",
            "                    Tom     0.0000    0.0000    0.0000        21\n",
            "                Snare 2     0.0000    0.0000    0.0000        21\n",
            "      Natural Harmonics     0.2000    0.0093    0.0177       108\n",
            "              Palm Mute     0.4764    0.7583    0.5852       786\n",
            "       Pick Near Bridge     0.4919    0.4232    0.4550       716\n",
            "Pick Over the Soundhole     0.4876    0.3685    0.4198       749\n",
            "\n",
            "               accuracy                         0.4818      2441\n",
            "              macro avg     0.2070    0.1949    0.1847      2441\n",
            "           weighted avg     0.4562    0.4818    0.4515      2441\n",
            "\n",
            "Selecting augmented data for fold 5 ...\n",
            "Found 68581 augmented samples for fold 5\n",
            "\n",
            "Fold [6/6]\n",
            "Selecting Split Data...\n",
            "Taking validation split from provided indexes\n",
            "Normalizing Data...\n",
            "Done.\n",
            "sampling_strategy: {0: 136, 1: 148, 2: 146, 3: 150, 4: 780, 5: 5468, 6: 5128, 7: 5533}\n",
            "Adding augmented data to training set...\n",
            "Length of training set before augmentation:  17489\n",
            "Length of training set after augmentation:  86070\n",
            "Model compiled\n",
            "Epoch 1/120\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 2.3344 - accuracy: 0.1928 - val_loss: 2.1682 - val_accuracy: 0.1983\n",
            "Epoch 2/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.8723 - accuracy: 0.3448 - val_loss: 2.2365 - val_accuracy: 0.1983\n",
            "Epoch 3/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 1.5823 - accuracy: 0.4481 - val_loss: 2.2138 - val_accuracy: 0.2039\n",
            "Epoch 4/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.3652 - accuracy: 0.5095 - val_loss: 2.1544 - val_accuracy: 0.1955\n",
            "Epoch 5/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.2317 - accuracy: 0.5415 - val_loss: 2.1626 - val_accuracy: 0.2104\n",
            "Epoch 6/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.1554 - accuracy: 0.5642 - val_loss: 2.2132 - val_accuracy: 0.2868\n",
            "Epoch 7/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.1064 - accuracy: 0.5792 - val_loss: 2.1978 - val_accuracy: 0.2737\n",
            "Epoch 8/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0669 - accuracy: 0.5931 - val_loss: 2.1827 - val_accuracy: 0.2858\n",
            "Epoch 9/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0417 - accuracy: 0.6037 - val_loss: 2.1865 - val_accuracy: 0.3017\n",
            "Epoch 10/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.0151 - accuracy: 0.6111 - val_loss: 2.1672 - val_accuracy: 0.3017\n",
            "Epoch 11/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9927 - accuracy: 0.6194 - val_loss: 2.1587 - val_accuracy: 0.3035\n",
            "Epoch 12/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9758 - accuracy: 0.6250 - val_loss: 2.1944 - val_accuracy: 0.3231\n",
            "Epoch 13/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9598 - accuracy: 0.6297 - val_loss: 2.2141 - val_accuracy: 0.3166\n",
            "Epoch 14/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9454 - accuracy: 0.6345 - val_loss: 2.2974 - val_accuracy: 0.3277\n",
            "Epoch 15/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9359 - accuracy: 0.6384 - val_loss: 2.2056 - val_accuracy: 0.3259\n",
            "Epoch 16/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9224 - accuracy: 0.6405 - val_loss: 2.1296 - val_accuracy: 0.3073\n",
            "Epoch 17/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9137 - accuracy: 0.6473 - val_loss: 2.1835 - val_accuracy: 0.3287\n",
            "Epoch 18/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.9032 - accuracy: 0.6485 - val_loss: 2.1752 - val_accuracy: 0.3128\n",
            "Epoch 19/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8943 - accuracy: 0.6520 - val_loss: 2.1306 - val_accuracy: 0.3333\n",
            "Epoch 20/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8868 - accuracy: 0.6572 - val_loss: 2.1650 - val_accuracy: 0.3231\n",
            "Epoch 21/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8801 - accuracy: 0.6588 - val_loss: 2.1346 - val_accuracy: 0.3250\n",
            "Epoch 22/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8722 - accuracy: 0.6614 - val_loss: 2.2095 - val_accuracy: 0.3305\n",
            "Epoch 23/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8675 - accuracy: 0.6640 - val_loss: 2.1606 - val_accuracy: 0.3222\n",
            "Epoch 24/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8603 - accuracy: 0.6666 - val_loss: 2.1807 - val_accuracy: 0.3333\n",
            "Epoch 25/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8526 - accuracy: 0.6680 - val_loss: 2.1719 - val_accuracy: 0.3380\n",
            "Epoch 26/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8479 - accuracy: 0.6720 - val_loss: 2.1476 - val_accuracy: 0.3287\n",
            "Epoch 27/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8421 - accuracy: 0.6725 - val_loss: 2.1128 - val_accuracy: 0.3194\n",
            "Epoch 28/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8356 - accuracy: 0.6768 - val_loss: 2.1152 - val_accuracy: 0.3361\n",
            "Epoch 29/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8318 - accuracy: 0.6766 - val_loss: 2.2148 - val_accuracy: 0.3315\n",
            "Epoch 30/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8252 - accuracy: 0.6781 - val_loss: 2.1415 - val_accuracy: 0.3212\n",
            "Epoch 31/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8206 - accuracy: 0.6808 - val_loss: 2.0940 - val_accuracy: 0.3343\n",
            "Epoch 32/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8140 - accuracy: 0.6831 - val_loss: 2.2439 - val_accuracy: 0.3296\n",
            "Epoch 33/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8136 - accuracy: 0.6822 - val_loss: 2.1374 - val_accuracy: 0.3333\n",
            "Epoch 34/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8072 - accuracy: 0.6869 - val_loss: 2.1062 - val_accuracy: 0.3361\n",
            "Epoch 35/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.8012 - accuracy: 0.6883 - val_loss: 2.1147 - val_accuracy: 0.3277\n",
            "Epoch 36/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7992 - accuracy: 0.6870 - val_loss: 2.1545 - val_accuracy: 0.3417\n",
            "Epoch 37/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7930 - accuracy: 0.6912 - val_loss: 2.1595 - val_accuracy: 0.3361\n",
            "Epoch 38/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7892 - accuracy: 0.6918 - val_loss: 2.0665 - val_accuracy: 0.3352\n",
            "Epoch 39/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7849 - accuracy: 0.6939 - val_loss: 2.0996 - val_accuracy: 0.3445\n",
            "Epoch 40/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7834 - accuracy: 0.6925 - val_loss: 2.0631 - val_accuracy: 0.3380\n",
            "Epoch 41/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7786 - accuracy: 0.6962 - val_loss: 2.1088 - val_accuracy: 0.3408\n",
            "Epoch 42/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7775 - accuracy: 0.6949 - val_loss: 2.1446 - val_accuracy: 0.3426\n",
            "Epoch 43/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7766 - accuracy: 0.6967 - val_loss: 2.1256 - val_accuracy: 0.3399\n",
            "Epoch 44/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7710 - accuracy: 0.6991 - val_loss: 2.0811 - val_accuracy: 0.3436\n",
            "Epoch 45/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7705 - accuracy: 0.6989 - val_loss: 2.0947 - val_accuracy: 0.3343\n",
            "Epoch 46/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7665 - accuracy: 0.7014 - val_loss: 2.0371 - val_accuracy: 0.3408\n",
            "Epoch 47/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7638 - accuracy: 0.7031 - val_loss: 2.0795 - val_accuracy: 0.3380\n",
            "Epoch 48/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7621 - accuracy: 0.7017 - val_loss: 2.0441 - val_accuracy: 0.3417\n",
            "Epoch 49/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7603 - accuracy: 0.7019 - val_loss: 2.0493 - val_accuracy: 0.3436\n",
            "Epoch 50/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7574 - accuracy: 0.7041 - val_loss: 2.0778 - val_accuracy: 0.3436\n",
            "Epoch 51/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7576 - accuracy: 0.7031 - val_loss: 2.0259 - val_accuracy: 0.3454\n",
            "Epoch 52/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7516 - accuracy: 0.7048 - val_loss: 2.0957 - val_accuracy: 0.3436\n",
            "Epoch 53/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7529 - accuracy: 0.7043 - val_loss: 2.0460 - val_accuracy: 0.3343\n",
            "Epoch 54/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7513 - accuracy: 0.7039 - val_loss: 2.0127 - val_accuracy: 0.3482\n",
            "Epoch 55/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7475 - accuracy: 0.7074 - val_loss: 2.0338 - val_accuracy: 0.3454\n",
            "Epoch 56/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7466 - accuracy: 0.7071 - val_loss: 2.0514 - val_accuracy: 0.3464\n",
            "Epoch 57/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7442 - accuracy: 0.7084 - val_loss: 2.0619 - val_accuracy: 0.3399\n",
            "Epoch 58/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7422 - accuracy: 0.7086 - val_loss: 2.0345 - val_accuracy: 0.3426\n",
            "Epoch 59/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7400 - accuracy: 0.7111 - val_loss: 1.9604 - val_accuracy: 0.3520\n",
            "Epoch 60/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7420 - accuracy: 0.7091 - val_loss: 2.0140 - val_accuracy: 0.3436\n",
            "Epoch 61/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7384 - accuracy: 0.7115 - val_loss: 1.9566 - val_accuracy: 0.3538\n",
            "Epoch 62/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7354 - accuracy: 0.7120 - val_loss: 2.0295 - val_accuracy: 0.3492\n",
            "Epoch 63/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7346 - accuracy: 0.7105 - val_loss: 2.0059 - val_accuracy: 0.3492\n",
            "Epoch 64/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7330 - accuracy: 0.7138 - val_loss: 1.9801 - val_accuracy: 0.3445\n",
            "Epoch 65/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7379 - accuracy: 0.7105 - val_loss: 2.0046 - val_accuracy: 0.3547\n",
            "Epoch 66/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7335 - accuracy: 0.7114 - val_loss: 2.0082 - val_accuracy: 0.3454\n",
            "Epoch 67/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7317 - accuracy: 0.7120 - val_loss: 1.9643 - val_accuracy: 0.3557\n",
            "Epoch 68/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7299 - accuracy: 0.7129 - val_loss: 2.0487 - val_accuracy: 0.3473\n",
            "Epoch 69/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7271 - accuracy: 0.7139 - val_loss: 2.0017 - val_accuracy: 0.3454\n",
            "Epoch 70/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7277 - accuracy: 0.7147 - val_loss: 2.0217 - val_accuracy: 0.3464\n",
            "Epoch 71/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7251 - accuracy: 0.7159 - val_loss: 1.9602 - val_accuracy: 0.3547\n",
            "Epoch 72/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7237 - accuracy: 0.7178 - val_loss: 1.9604 - val_accuracy: 0.3538\n",
            "Epoch 73/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7250 - accuracy: 0.7165 - val_loss: 2.0118 - val_accuracy: 0.3473\n",
            "Epoch 74/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.7203 - accuracy: 0.7180 - val_loss: 2.0168 - val_accuracy: 0.3464\n",
            "Epoch 75/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7222 - accuracy: 0.7166 - val_loss: 1.9809 - val_accuracy: 0.3557\n",
            "Epoch 76/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7179 - accuracy: 0.7185 - val_loss: 1.9488 - val_accuracy: 0.3482\n",
            "Epoch 77/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7209 - accuracy: 0.7168 - val_loss: 1.9586 - val_accuracy: 0.3566\n",
            "Epoch 78/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7165 - accuracy: 0.7185 - val_loss: 2.0143 - val_accuracy: 0.3492\n",
            "Epoch 79/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7166 - accuracy: 0.7195 - val_loss: 2.0112 - val_accuracy: 0.3520\n",
            "Epoch 80/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7180 - accuracy: 0.7172 - val_loss: 1.9534 - val_accuracy: 0.3622\n",
            "Epoch 81/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7140 - accuracy: 0.7185 - val_loss: 1.9848 - val_accuracy: 0.3538\n",
            "Epoch 82/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7127 - accuracy: 0.7204 - val_loss: 2.0192 - val_accuracy: 0.3492\n",
            "Epoch 83/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7137 - accuracy: 0.7197 - val_loss: 1.9679 - val_accuracy: 0.3575\n",
            "Epoch 84/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7120 - accuracy: 0.7202 - val_loss: 2.0085 - val_accuracy: 0.3547\n",
            "Epoch 85/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7128 - accuracy: 0.7207 - val_loss: 1.9944 - val_accuracy: 0.3482\n",
            "Epoch 86/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7085 - accuracy: 0.7229 - val_loss: 1.9337 - val_accuracy: 0.3594\n",
            "Epoch 87/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7097 - accuracy: 0.7231 - val_loss: 1.9873 - val_accuracy: 0.3622\n",
            "Epoch 88/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7065 - accuracy: 0.7239 - val_loss: 1.9554 - val_accuracy: 0.3631\n",
            "Epoch 89/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7075 - accuracy: 0.7216 - val_loss: 1.9476 - val_accuracy: 0.3631\n",
            "Epoch 90/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7057 - accuracy: 0.7233 - val_loss: 1.9734 - val_accuracy: 0.3529\n",
            "Epoch 91/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7028 - accuracy: 0.7258 - val_loss: 2.0348 - val_accuracy: 0.3520\n",
            "Epoch 92/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7038 - accuracy: 0.7249 - val_loss: 1.9413 - val_accuracy: 0.3585\n",
            "Epoch 93/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7058 - accuracy: 0.7236 - val_loss: 1.9853 - val_accuracy: 0.3501\n",
            "Epoch 94/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7028 - accuracy: 0.7251 - val_loss: 1.9660 - val_accuracy: 0.3585\n",
            "Epoch 95/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7033 - accuracy: 0.7251 - val_loss: 1.9454 - val_accuracy: 0.3641\n",
            "Epoch 96/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7002 - accuracy: 0.7253 - val_loss: 1.9669 - val_accuracy: 0.3547\n",
            "Epoch 97/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7001 - accuracy: 0.7241 - val_loss: 1.9637 - val_accuracy: 0.3585\n",
            "Epoch 98/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6982 - accuracy: 0.7271 - val_loss: 1.9598 - val_accuracy: 0.3594\n",
            "Epoch 99/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.7002 - accuracy: 0.7270 - val_loss: 1.9724 - val_accuracy: 0.3575\n",
            "Epoch 100/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6956 - accuracy: 0.7267 - val_loss: 1.9637 - val_accuracy: 0.3575\n",
            "Epoch 101/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6962 - accuracy: 0.7268 - val_loss: 1.9869 - val_accuracy: 0.3547\n",
            "Epoch 102/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6946 - accuracy: 0.7270 - val_loss: 1.9464 - val_accuracy: 0.3603\n",
            "Epoch 103/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6952 - accuracy: 0.7285 - val_loss: 1.9840 - val_accuracy: 0.3557\n",
            "Epoch 104/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6948 - accuracy: 0.7281 - val_loss: 1.9754 - val_accuracy: 0.3566\n",
            "Epoch 105/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6951 - accuracy: 0.7271 - val_loss: 1.9673 - val_accuracy: 0.3622\n",
            "Epoch 106/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6907 - accuracy: 0.7299 - val_loss: 1.9647 - val_accuracy: 0.3603\n",
            "Epoch 107/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6922 - accuracy: 0.7270 - val_loss: 1.9655 - val_accuracy: 0.3659\n",
            "Epoch 108/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6926 - accuracy: 0.7283 - val_loss: 1.9718 - val_accuracy: 0.3585\n",
            "Epoch 109/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6897 - accuracy: 0.7297 - val_loss: 1.9181 - val_accuracy: 0.3631\n",
            "Epoch 110/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6899 - accuracy: 0.7307 - val_loss: 1.9558 - val_accuracy: 0.3529\n",
            "Epoch 111/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6882 - accuracy: 0.7300 - val_loss: 1.9548 - val_accuracy: 0.3650\n",
            "Epoch 112/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6864 - accuracy: 0.7303 - val_loss: 1.9409 - val_accuracy: 0.3669\n",
            "Epoch 113/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6873 - accuracy: 0.7298 - val_loss: 1.9706 - val_accuracy: 0.3575\n",
            "Epoch 114/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6910 - accuracy: 0.7300 - val_loss: 1.9775 - val_accuracy: 0.3669\n",
            "Epoch 115/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6880 - accuracy: 0.7306 - val_loss: 1.9633 - val_accuracy: 0.3594\n",
            "Epoch 116/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6860 - accuracy: 0.7305 - val_loss: 1.9388 - val_accuracy: 0.3650\n",
            "Epoch 117/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.6815 - accuracy: 0.7328 - val_loss: 1.9835 - val_accuracy: 0.3594\n",
            "Epoch 118/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6830 - accuracy: 0.7324 - val_loss: 1.9392 - val_accuracy: 0.3650\n",
            "Epoch 119/120\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 0.6803 - accuracy: 0.7327 - val_loss: 1.9454 - val_accuracy: 0.3706\n",
            "Epoch 120/120\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.6814 - accuracy: 0.7320 - val_loss: 1.9472 - val_accuracy: 0.3659\n",
            "Test Accuracy: 0.3811426288453855\n",
            "Test macro_weighted_avg f1-score: nan\n",
            "[[  0   0   0   0   0 149  34   4]\n",
            " [  0   0   0   0   0  26 109  13]\n",
            " [  0   0   0   0   0 113  64   6]\n",
            " [  3   0   0  11   0 169  27   0]\n",
            " [  0   0   0   0   1 106  60  18]\n",
            " [  1   0   0   1   0 469  66  29]\n",
            " [  0   0   0   0   1 184 209 104]\n",
            " [  0   0   0   0   1 140 121 264]]\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "                   Kick     0.0000    0.0000    0.0000       187\n",
            "                Snare 1     0.0000    0.0000    0.0000       148\n",
            "                    Tom     0.0000    0.0000    0.0000       183\n",
            "                Snare 2     0.9167    0.0524    0.0991       210\n",
            "      Natural Harmonics     0.3333    0.0054    0.0106       185\n",
            "              Palm Mute     0.3459    0.8286    0.4880       566\n",
            "       Pick Near Bridge     0.3029    0.4197    0.3519       498\n",
            "Pick Over the Soundhole     0.6027    0.5019    0.5477       526\n",
            "\n",
            "               accuracy                         0.3811      2503\n",
            "              macro avg     0.3127    0.2260    0.1872      2503\n",
            "           weighted avg     0.3667    0.3811    0.3046      2503\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_513425/2383121875.py:12: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  f1score = 2 /((1/precision)+(1/recall))\n",
            "/tmp/ipykernel_513425/2383121875.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  precision = 1.0 * true_positives / np.sum(classPrediction)\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/domenico/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "'''Call the main routine for each fold'''\n",
        "result_model = []\n",
        "train_aug_indexes = {}\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    metric_names = ['accuracy','f1_weightedmacroavg','confusion_matrix','classification_report','printable_classification_report']\n",
        "    evaluation_metrics, quantized_model_evaluation_metrics = {k:[] for k in metric_names}, {k:[] for k in metric_names}\n",
        "    \n",
        "    X,y = dataset_features.to_numpy(), dataset_labels.to_numpy()\n",
        "\n",
        "    if USE_CROSS_VALIDATION:\n",
        "        for foldidx,split_folds in enumerate(cv.split(X, y)): \n",
        "            if CUSTOM_PLAYER_K_FOLD:\n",
        "                train_idx, test_idx, val_idx  = split_folds\n",
        "            else:\n",
        "                train_idx, test_idx = split_folds\n",
        "                val_idx = None\n",
        "\n",
        "            train_aug_idx = []  # Indexes of the augmented data that correspond to the current training split\n",
        "            if USE_AUGMENTED_DATA: # Here we want to select the augmented data that corresponds to the current training split\n",
        "                print('Selecting augmented data for fold',foldidx,'...')\n",
        "                training_metadata = metadata.iloc[train_idx]\n",
        "                training_sources_and_times = {tuple(k):True for k in training_metadata[['meta_audiofilePath','meta_onsetGroundTruthLabelTime']].values}\n",
        "                \n",
        "                for idx,source_aug,time_aug in  metadata_aug[['meta_augmentation_source','meta_onsetGroundTruthLabelTime']].itertuples():\n",
        "                    if((source_aug,time_aug) in training_sources_and_times.keys()):\n",
        "                        train_aug_idx.append(idx)\n",
        "                assert len(train_aug_idx) > 0, \"No augmented data found for the current training split\"\n",
        "                print('Found',len(train_aug_idx),'augmented samples for fold',foldidx)\n",
        "            train_aug_indexes[foldidx] = train_aug_idx\n",
        "            # TODO: wait there might be a bug here, we are not using the augmented data \n",
        "            result_model.append(main_routine(X, y,\n",
        "                                             train_idx = train_idx,\n",
        "                                             test_idx  = test_idx,\n",
        "                                             val_idx   = val_idx,\n",
        "                                             aug_data = None if not USE_AUGMENTED_DATA else (metadata_aug, features_aug, labels_aug, train_aug_idx),\n",
        "                                             foldcount = foldidx+1,\n",
        "                                             is_k_fold = USE_CROSS_VALIDATION,\n",
        "                                             eval_metrics           = evaluation_metrics,\n",
        "                                             quantized_eval_metrics = quantized_model_evaluation_metrics))        \n",
        "    else:\n",
        "        result_model = main_routine(X, y,\n",
        "                                    eval_metrics           = evaluation_metrics,\n",
        "                                    quantized_eval_metrics = quantized_model_evaluation_metrics,\n",
        "                                    _val_split_size        = VAL_SPLIT_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLTufCRmlpIW"
      },
      "source": [
        "# Cross Validation average results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOqw9k1wlWZC"
      },
      "source": [
        "## Utilities for reports and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvpD2bFcYcCi"
      },
      "outputs": [],
      "source": [
        "def report_average(reports):\n",
        "    mean_dict = dict()\n",
        "    for label in reports[0].keys():\n",
        "        dictionary = dict()\n",
        "\n",
        "        if label in 'accuracy':\n",
        "            mean_dict[label] = sum(d[label] for d in reports) / len(reports)\n",
        "            continue\n",
        "\n",
        "        for key in reports[0][label].keys():\n",
        "            dictionary[key] = sum(d[label][key] for d in reports) / len(reports)\n",
        "        mean_dict[label] = dictionary\n",
        "\n",
        "    return mean_dict\n",
        "\n",
        "def classification_report_dict2print(report):\n",
        "    ret = \"\"\n",
        "    classes = list(report.keys())[0:-3]\n",
        "    summary_metrics = list(report.keys())[-3:]\n",
        "    longest_1st_column_name = max([len(key) for key in report.keys()])\n",
        "    ret = ' ' * longest_1st_column_name\n",
        "    ret += '  precision    recall  f1-score   support\\n\\n'\n",
        "\n",
        "    METRIC_DECIMAL_DIGITS = 4\n",
        "    metric_digits = METRIC_DECIMAL_DIGITS + 2 # add 0 and dot\n",
        "\n",
        "    header_spacing = 1\n",
        "    metrics = list(report[classes[0]].keys())\n",
        "    longest_1st_row_name = max([len(key) for key in report[classes[0]].keys()]) + header_spacing\n",
        "\n",
        "    for classname in classes:\n",
        "        ret += (' '*(longest_1st_column_name-len(classname))) + classname + ' '\n",
        "        for metric in metrics:\n",
        "            if metric != \"support\":\n",
        "                ret += (' '*(longest_1st_row_name-metric_digits))\n",
        "                ret += \"%.4f\" % round(report[classname][metric],METRIC_DECIMAL_DIGITS)\n",
        "            else:\n",
        "                current_support_digits = len(str(int(report[classname][metric])))\n",
        "                ret += (' '*(longest_1st_row_name-current_support_digits))\n",
        "                ret += \"%d\" % round(report[classname][metric],0)\n",
        "        ret += '\\n'\n",
        "    ret += '\\n'\n",
        "\n",
        "    # Accuracy\n",
        "    ret += (' '*(longest_1st_column_name-len(summary_metrics[0]))) + summary_metrics[0] + ' '\n",
        "    ret += 2* (' '*longest_1st_row_name)\n",
        "    ret += (' '*(longest_1st_row_name-metric_digits))\n",
        "    ret += \"%.4f\" % round(report[\"accuracy\"],METRIC_DECIMAL_DIGITS)\n",
        "    current_support_digits = len(str(int(report[summary_metrics[-1]]['support'])))\n",
        "    ret += (' '*(longest_1st_row_name-current_support_digits))\n",
        "    ret += \"%d\" % round(report[summary_metrics[-1]]['support'],0)\n",
        "    ret += '\\n'\n",
        "  \n",
        "  \n",
        "    for classname in summary_metrics[1:]:\n",
        "        ret += (' '*(longest_1st_column_name-len(classname))) + classname + ' '\n",
        "        for metric in metrics:\n",
        "            if metric != \"support\":\n",
        "                ret += (' '*(longest_1st_row_name-metric_digits))\n",
        "                ret += \"%.4f\" % round(report[classname][metric],METRIC_DECIMAL_DIGITS)\n",
        "            else:\n",
        "                current_support_digits = len(str(int(report[classname][metric])))\n",
        "                ret += (' '*(longest_1st_row_name-current_support_digits))\n",
        "                ret += \"%d\" % round(report[classname][metric],0)\n",
        "        ret += '\\n'\n",
        "    ret += '\\n'\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vw1nmcpmApM"
      },
      "source": [
        "## Compute average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-xQAAnQu6BO"
      },
      "outputs": [],
      "source": [
        "if USE_CROSS_VALIDATION:\n",
        "    assert len(evaluation_metrics['accuracy']) == K_SPLITS, \"The number of accuracy values does not match the number of folds ({} != {})\".format(len(evaluation_metrics['accuracy']),K_SPLITS)\n",
        "    \n",
        "    averaged_classification_reports = report_average(evaluation_metrics[\"classification_report\"])\n",
        "    macro_avg_f1_score = averaged_classification_reports[\"macro avg\"][\"f1-score\"]\n",
        "    average_fold_accuracy = averaged_classification_reports[\"accuracy\"]\n",
        "    printable_avg_report = classification_report_dict2print(averaged_classification_reports)\n",
        "    qm_printable_avg_report = \"Not performed\"\n",
        "    if TEST_QUANTIZATION:\n",
        "        qm_printable_avg_report = classification_report_dict2print(report_average(quantized_model_evaluation_metrics[\"classification_report\"]))\n",
        "    metrics_to_save = {'macro avg f1-score' : macro_avg_f1_score,\\\n",
        "                       'average_fold_accuracy' : average_fold_accuracy,\\\n",
        "                       'avg_classification_report' : printable_avg_report,\\\n",
        "                       'avg_classification_report_for_quantized_model' : qm_printable_avg_report}\n",
        "else:\n",
        "    assert len(evaluation_metrics['accuracy']) == 1\n",
        "    metrics_to_save = {}\n",
        "    for metric in evaluation_metrics.keys():\n",
        "        metrics_to_save[metric] = evaluation_metrics[metric][0]\n",
        "    for metric in quantized_model_evaluation_metrics.keys():\n",
        "        metrics_to_save['quantizedmod_'+str(metric)] = quantized_model_evaluation_metrics[metric][0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sYtK9DZu64h"
      },
      "source": [
        "# Save Model Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNDoHM4gXw5x"
      },
      "outputs": [],
      "source": [
        "if SAVE_MODEL_INFO:\n",
        "    current_dir = MODELFOLDER + \"/\" + RUN_NAME\n",
        "    # %mkdir -p \"$current_dir\"\n",
        "    os.makedirs(current_dir,exist_ok = True)\n",
        "\n",
        "    save_model_info(result_model[0] if type(result_model) == list else result_model,\n",
        "                    optimizer,\n",
        "                    USE_CROSS_VALIDATION,K_SPLITS,\n",
        "                    metrics_to_save,\n",
        "                    current_dir)\n",
        "else:\n",
        "    print(\"RESULTS\\n\\n\" + metrics_to_save)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl7ZdTjKVcE3"
      },
      "source": [
        "# Train final model on the entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_dir = os.path.join(MODELFOLDER,RUN_NAME)\n",
        "assert os.path.exists(run_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT6_bSsfVbiH"
      },
      "outputs": [],
      "source": [
        "if TRAIN_FINAL_MODEL:\n",
        "    use_early_stopping = False\n",
        "\n",
        "    ### DEFINE MODEL\n",
        "    final_model = define_model_architecture(len(CLASSES),_verbose = True)\n",
        "    loss_fn = get_loss()\n",
        "\n",
        "    ### Normalize data if needed\n",
        "    if DO_NORMALIZE_DATA:\n",
        "        scaler = SCALER_TO_USE\n",
        "        X = scaler.fit_transform(X)\n",
        "\n",
        "        # Save final scaler and parameters\n",
        "        with open(os.path.join(run_dir,'scaler.pickle'),'wb') as sf:\n",
        "            pickle.dump(scaler,sf)\n",
        "        with open(os.path.join(run_dir,'info.txt'),'a') as infof:\n",
        "            if type(SCALER_TO_USE) == MinMaxScaler:\n",
        "                infof.write(\"The scaler used was sklearn.preprocessing MinMaxScaler\\nScaler parameters:\\n\")\n",
        "\n",
        "                infof.write('MinMaxScaler().data_min_: '        + str(SCALER_TO_USE.data_min_)+'\\n')\n",
        "                infof.write('MinMaxScaler().data_max_: '        + str(SCALER_TO_USE.data_max_)+'\\n')\n",
        "                infof.write('MinMaxScaler().data_range_: '      + str(SCALER_TO_USE.data_range_)+'\\n')\n",
        "                infof.write('MinMaxScaler().scale_: '           + str(SCALER_TO_USE.scale_)+'\\n')\n",
        "                infof.write('MinMaxScaler().n_samples_seen_: '  + str(SCALER_TO_USE.n_samples_seen_)+'\\n')\n",
        "            elif type(SCALER_TO_USE) == StandardScaler:\n",
        "                infof.write(\"The scaler used was sklearn.preprocessing StandardScaler\\nScaler parameters:\\n\")\n",
        "                infof.write('StandardScaler().mean_: '          + str(SCALER_TO_USE.mean_)+'\\n')\n",
        "                infof.write('StandardScaler().var_: '           + str(SCALER_TO_USE.var_)+'\\n')\n",
        "                infof.write('StandardScaler().scale_: '         + str(SCALER_TO_USE.scale_)+'\\n')\n",
        "                infof.write('StandardScaler().n_samples_seen_: '+ str(SCALER_TO_USE.n_samples_seen_)+'\\n')\n",
        "            else:\n",
        "                raise Exception(\"\\\"%s\\\" scaler not supported\"%(SCALER_TO_USE))\n",
        "\n",
        "    ### PREPARE DATA IN CASE OF A FIRST CONV LAYER IN THE NET\n",
        "    if type(final_model.layers[0]) == tf.keras.layers.Conv1D:\n",
        "        X_all = np.expand_dims(X,axis = 2) # Adapt data for Conv1d ([batch_shape, steps, input_dim] -> in our case indim = 1, steps = features, batchshape = train datset size)\n",
        "    else:\n",
        "        X_all = X\n",
        "\n",
        "    ### COMPILE MODEL\n",
        "    compile_model(final_model,optimizer,loss_fn,_verbose = True)\n",
        "\n",
        "    ### SETUP TENSORBOARD\n",
        "    tensorboard_callback = start_tensorboard(tb_dir,None)\n",
        "    callbacks=[tensorboard_callback,]\n",
        "\n",
        "    ### SETUP EARLY STOPPING (only if not in K-fold mode)\n",
        "    if use_early_stopping:\n",
        "        callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='min', verbose=1, patience=200))\n",
        "\n",
        "    # * FIT MODEL *\n",
        "    final_model.fit(X_all, y, epochs=args['epochs'],\n",
        "                    callbacks=callbacks,\n",
        "                    batch_size=args['batchsize'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXJ9wBMbb4sp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./output/CrossValidatedRun_20221222-182105/finalModel/assets\n"
          ]
        }
      ],
      "source": [
        "final_model_dir = MODELFOLDER + \"/\" + RUN_NAME + \"/finalModel\"\n",
        "# %mkdir -p \"$final_model_dir\"\n",
        "os.makedirs(final_model_dir,exist_ok = True)\n",
        "\n",
        "final_model.save(final_model_dir)\n",
        "\n",
        "# Convert and save lite model (Non quantized)\n",
        "convert2tflite(final_model_dir,model_name='final_model',quantization=None)\n",
        "# Convert and save lite model (Dynamically quantized)\n",
        "convert2tflite(final_model_dir,model_name='final_model_dynquant',quantization=\"dynamic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pBrSDphxyxL"
      },
      "source": [
        "# Save the model for TF Lite\n",
        "## *(Only if not a Cross Validated run)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3ScdRpC-m_J"
      },
      "outputs": [],
      "source": [
        "# if USE_CROSS_VALIDATION is False:\n",
        "#     model_path = MODELFOLDER + \"/\" + RUN_NAME\n",
        "#     convert2tflite(model_path)                                                # standard TFLITE model\n",
        "#     convert2tflite(model_path,model_name=\"model_partially_quantized\",quantization=\"dynamic\")   # Partial quantization  https://www.tensorflow.org/lite/performance/post_training_quantization#dynamic_range_quantization\n",
        "    \n",
        "#     quantization_dataset = X\n",
        "#     if type(result_model.layers[0]) == tf.keras.layers.Conv1D:\n",
        "#         quantization_dataset = np.expand_dims(X,axis = 2) # Adapt data for Conv1d\n",
        "    \n",
        "#     convert2tflite(model_path,model_name=\"model_float_fallback\",quantization=\"float-fallback\",dataset=quantization_dataset) # https://www.tensorflow.org/lite/performance/post_training_integer_quant#convert_using_float_fallback_quantization\n",
        "#     convert2tflite(model_path,model_name=\"model_fully_quantized\",quantization=\"full\",dataset=quantization_dataset)          # FULL uint8 quantization https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnPqZ8k4box0"
      },
      "outputs": [],
      "source": [
        "# first_layer_is_conv = (type(result_model.layers[0]) == tf.keras.layers.Conv1D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QdCLmkgzonI"
      },
      "outputs": [],
      "source": [
        "# TEST_SAVED_MODEL = None\n",
        "# # TEST_SAVED_MODEL = 'model.tflite'\n",
        "# # TEST_SAVED_MODEL = 'model_partially_quantized.tflite'\n",
        "# # TEST_SAVED_MODEL = 'model_float_fallback.tflite'\n",
        "# # TEST_SAVED_MODEL = 'model_fully_quantized.tflite'\n",
        "# # TEST_SAVED_MODEL = 'quant_aware_model.tflite'\n",
        "# # TEST_SAVED_MODEL = 'saved_model.pb'\n",
        "# verbose_test = False\n",
        "\n",
        "# def test_generic_model(model_filename,model_path,X_test,Y_test,first_layer_is_conv,verbose_test = False):\n",
        "#     if model_filename.split('.')[-1] == 'tflite':\n",
        "#         y_pred = test_tflite_model(model_path+'/'+model_filename,X_test,y_test,first_layer_is_conv,verbose_test = verbose_test)\n",
        "#         correct = np.count_nonzero((np.array(y_pred) == np.ravel(y_test)).astype(int))\n",
        "#         total = np.shape(y_test)[0]\n",
        "#         accuracy = round(correct/total,4)\n",
        "#     elif model_filename.split('.')[-1] == 'pb':\n",
        "#         accuracy = test_regulartf_model(model_path,X_test,y_test,first_layer_is_conv,verbose_test = verbose_test)\n",
        "#     else:\n",
        "#         raise ValueError(\"\")\n",
        "\n",
        "#     return accuracy\n",
        "\n",
        "# if USE_CROSS_VALIDATION is False and TEST_SAVED_MODEL is not None:\n",
        "#     assert np.max([len(ev_metric) for ev_metric in evaluation_metrics]) == K_SPLITS\n",
        "\n",
        "#     target_accuracy = evaluation_metrics['accuracy'][0]\n",
        "#     accuracy = test_generic_model(TEST_SAVED_MODEL,model_path,X_test,Y_test,first_layer_is_conv)\n",
        "\n",
        "#     epsilon = 1e-4\n",
        "#     EQUAL_ACCURACY = abs(target_accuracy - accuracy) < epsilon\n",
        "\n",
        "#     print(\"accuracy: \" + str(accuracy))\n",
        "\n",
        "#     if EQUAL_ACCURACY:\n",
        "#         print(\"Accuracy of the original model and the saved TF model correspond(on same test set)\")\n",
        "#     else:\n",
        "#         raise ValueError('Accuracy does not match target (Target: '+str(target_accuracy)+' but got '+str(accuracy)+' instead)')\n",
        "# else:\n",
        "#     print(\"TF model testing is disabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERYDqiDVXUqX"
      },
      "source": [
        "# Quantization aware fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2QJCdx9HOfW"
      },
      "outputs": [],
      "source": [
        "# #################################################\n",
        "# PERFORM_QUANZATION_AWARE_TRAINING = False       #\n",
        "# #################################################\n",
        "# if PERFORM_QUANZATION_AWARE_TRAINING:\n",
        "#     pip_install('tensorflow_model_optimization')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5W8KuwyXTsX"
      },
      "outputs": [],
      "source": [
        "# if PERFORM_QUANZATION_AWARE_TRAINING:\n",
        "#     imported_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "#     import tensorflow_model_optimization as tfmot\n",
        "\n",
        "#     quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "#     # q_aware stands for for quantization aware.\n",
        "#     q_aware_model = None\n",
        "#     q_aware_model = quantize_model(imported_model)\n",
        "\n",
        "#     # `quantize_model` requires a recompile.\n",
        "#     _,loss_fn = define_model_architecture(len(CLASSES),_verbose = True)  # Get only the loss function\n",
        "#     compile_model(q_aware_model,optimizer,loss_fn,_verbose = True)  # Recompile the quantization aware model\n",
        "\n",
        "#     q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pb9pAqTA0h5"
      },
      "outputs": [],
      "source": [
        "# if PERFORM_QUANZATION_AWARE_TRAINING:\n",
        "#     tb_dir = \"logs2/fit/\"\n",
        "#     %tensorboard --logdir $tb_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQPy1nbXtWto"
      },
      "outputs": [],
      "source": [
        "# if PERFORM_QUANZATION_AWARE_TRAINING:\n",
        "#     finetuning_epochs = 50\n",
        "#     tensorboard_callback = start_tensorboard(tb_dir,None)\n",
        "\n",
        "#     q_history = q_aware_model.fit(X_train, y_train, epochs=finetuning_epochs, validation_data = (X_valid,y_valid),\n",
        "#                                 callbacks=[tensorboard_callback],\n",
        "#                                 batch_size=args['batchsize'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIbbjlPRx1bx"
      },
      "outputs": [],
      "source": [
        "# if PERFORM_QUANZATION_AWARE_TRAINING:\n",
        "#     quant_model_path = MODELFOLDER + \"/\" + RUN_NAME + \"/quant_aware_model.tflite\"\n",
        "\n",
        "#     converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "#     converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "#     quantized_tflite_model = converter.convert()\n",
        "\n",
        "#     with tf.io.gfile.GFile(quant_model_path, 'wb') as f:\n",
        "#         f.write(quantized_tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVw_zjlf6uFi"
      },
      "source": [
        "## Rename current output folder by prefixing the accuracy value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if FEATURE_WINDOW_SIZE == FeatureWindowSize.s4800_SAMPLES_100ms:\n",
        "    window_folder = '100ms'\n",
        "elif FEATURE_WINDOW_SIZE == FeatureWindowSize.s704_Samples_14ms:\n",
        "    window_folder = '14.67ms'\n",
        "else:\n",
        "    raise ValueError('Invalid FeatureWindowSize \"%s\"'%FeatureWindowSize.name)\n",
        "# make window folder\n",
        "window_folder = os.path.join(os.path.dirname(run_dir),window_folder)\n",
        "if not os.path.exists(window_folder):\n",
        "    os.mkdir(window_folder)\n",
        "problem_folder = os.path.join(window_folder,classification_task.value[1])\n",
        "if not os.path.exists(problem_folder):\n",
        "    os.mkdir(problem_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzJLnKEZ6uFi"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(os.path.join(run_dir,'info.txt')):\n",
        "    metrics_prefix = 'c_' if 'CrossValidated' in os.path.basename(run_dir) else ''\n",
        "\n",
        "    metrics_prefix += 'maf1_%.4f_acc_%.4f_'%(round(metrics_to_save['macro avg f1-score'],4),round(metrics_to_save['average_fold_accuracy'],4))\n",
        "\n",
        "    window_prefix = ''\n",
        "    if FEATURE_WINDOW_SIZE == FeatureWindowSize.s4800_SAMPLES_100ms:\n",
        "        window_prefix = 'z100ms_'\n",
        "    elif FEATURE_WINDOW_SIZE == FeatureWindowSize.s704_Samples_14ms:\n",
        "        pass\n",
        "    else:\n",
        "        raise ValueError('Invalid FeatureWindowSize \"%s\"'%FeatureWindowSize.name)\n",
        "\n",
        "\n",
        "    problem_prefix = classification_task.value[1]+'_'\n",
        "        \n",
        "    newfoldername = os.path.join(problem_folder,window_prefix+problem_prefix+metrics_prefix+os.path.basename(run_dir))\n",
        "    # print('Renaming \"'+run_dir+'\" to \"'+newfoldername+'\"')\n",
        "    os.rename(run_dir,newfoldername)\n",
        "    run_dir = newfoldername\n",
        "else:\n",
        "    errfoldername = os.path.join(os.path.dirname(run_dir),'ERR_'+os.path.basename(run_dir))\n",
        "    os.rename(run_dir,errfoldername)\n",
        "    run_dir = errfoldername"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAgndl_b6uFi"
      },
      "source": [
        "## Testing with extra test data\n",
        "This data was extracted from extra recordings, made to test the system in a real life scenario.  \n",
        "Here we test only to veryfy that everything is working here, before making a shift to the real life test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if FEATURE_WINDOW_SIZE == FeatureWindowSize.s4800_SAMPLES_100ms:\n",
        "    TEST_WITH_EXTRA_DATA = False\n",
        "elif FEATURE_WINDOW_SIZE == FeatureWindowSize.s704_Samples_14ms:\n",
        "    TEST_WITH_EXTRA_DATA = True # Heep in mind that TRAIN_FINAL_MODEL should be True too\n",
        "else:\n",
        "    raise ValueError('Invalid FeatureWindowSize \"%s\"'%FeatureWindowSize.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdhiK3rD6uFj"
      },
      "outputs": [],
      "source": [
        "if TRAIN_FINAL_MODEL and TEST_WITH_EXTRA_DATA:\n",
        "    \"\"\" Load the test data \"\"\"\n",
        "\n",
        "    TEST_DATA_FILE_PATH = os.path.join(DATAFOLDER,'20221011_110715_test_onlycorrectdetections.pickle')\n",
        "    print(\"Loading test data from pickle...\")\n",
        "    with open(TEST_DATA_FILE_PATH,'rb') as pf:\n",
        "        testdataset = pickle.load(pf)\n",
        "    testdataset.sort_values(['meta_expressive_technique_id','meta_audiofilePath'],inplace = True)\n",
        "    print('Done.')\n",
        "    # If this fails, the dataset has changed from the last time the program was run successfully (CHECK THE DATA!!!)\n",
        "    assert testdataset.shape == (754,507)\n",
        "    # display(testdataset)\n",
        "\n",
        "\n",
        "    \"\"\" Drop unused features (like the train/test dataset) \"\"\"\n",
        "\n",
        "    drop_unused_features(testdataset,inplace=True)\n",
        "    assert testdataset.shape == (754,504)\n",
        "\n",
        "\n",
        "    \"\"\" Divide the test data into metadata, features and labels (like the train/test dataset) \"\"\"\n",
        "\n",
        "    test_metadata, test_features, test_labels = divide_dataset(testdataset)\n",
        "    assert test_metadata.shape[0] == test_features.shape[0] == test_labels.shape[0] == 754\n",
        "    assert test_metadata.shape[1] == 9\n",
        "    assert test_features.shape[1] == 495\n",
        "\n",
        "    \"\"\" Filter the dataset according to the task \"\"\"\n",
        "    # This might mean removing samples or renaming classes\n",
        "    test_features,test_labels,test_metadata = filter_dataset(test_features.copy(),test_labels.copy(),test_metadata.copy(),classification_task)\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\" Apply the feature selection computed for the train/test set (like the train/test dataset) \"\"\"\n",
        "\n",
        "    test_features = test_features.copy().loc[:,selected_features]\n",
        "\n",
        "    if len(selected_features) != AUTO_FEATURE_NUMBER:\n",
        "        raise Exception('The number of selected_features ('+str(len(selected_features))+') is not the same as AUTO_FEATURE_NUMBER ('+str(AUTO_FEATURE_NUMBER)+'). Check the code.')\n",
        "\n",
        "    if test_features.shape[1] != AUTO_FEATURE_NUMBER:\n",
        "        raise Exception('The number of features in the test dataset ('+str(test_features.shape[1])+') is different from the number of features in the train/test dataset ('+str(AUTO_FEATURE_NUMBER)+')')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XskezstrklRC"
      },
      "outputs": [],
      "source": [
        "if TRAIN_FINAL_MODEL and TEST_WITH_EXTRA_DATA:\n",
        "    extra_test_x = test_features.to_numpy()\n",
        "    extra_test_y = test_labels.to_numpy()\n",
        "\n",
        "    \n",
        "\n",
        "    if DO_NORMALIZE_DATA:\n",
        "        # This scaler was \"learned\" a few cells above on the whole train/test dataset (obviously exluding the etra-test data)\n",
        "        extra_test_x = scaler.transform(extra_test_x)\n",
        "\n",
        "    if type(final_model.layers[0]) == tf.keras.layers.Conv1D:\n",
        "        extra_test_x = np.expand_dims(extra_test_x,axis = 2) # Adapt data for Conv1d ([batch_shape, steps, input_dim] -> in our case indim = 1, steps = features, batchshape = train datset size)\n",
        "\n",
        "    y_true = np.squeeze(extra_test_y)\n",
        "    y_pred = np.argmax(final_model(extra_test_x),axis=1)\n",
        "    cm_acc, f1mw, cm_conf_matrix, cm_classf_report, cm_printable_classf_report = compute_metrics(y_true, y_pred, _verbose=False)\n",
        "\n",
        "    with open(os.path.join(run_dir,'info.txt'),'a') as infof:\n",
        "        infof.write('______________________________________________________________________________________________________________________________________________________\\n\\n\\n')\n",
        "        infof.write('+----------------------------------------------------------------+\\n')\n",
        "        infof.write('| Results obtained on extra test recordings with the FINAL MODEL |\\n')\n",
        "        infof.write('+----------------------------------------------------------------+\\n\\n')\n",
        "        infof.write('Extra-test-Accuracy: '+str(cm_acc)+'\\n\\n')\n",
        "        infof.write('Extra-test-F1 Score (weighted average): '+str(f1mw)+'\\n\\n')\n",
        "        infof.write('Extra-test-ConfusionMatrix: \\n'+str(cm_conf_matrix)+'\\n\\n')\n",
        "        infof.write('Extra-test-Report: \\n'+str(cm_printable_classf_report)+'\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp5iv_0pklRC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*--* Training successfully completed. *--*\n",
            "Data at ./output/14.67ms/full/full_c_maf1_0.2200_acc_0.4684_CrossValidatedRun_20221222-182105\n"
          ]
        }
      ],
      "source": [
        "print('*--* Training successfully completed. *--*')\n",
        "print(\"Data at\",run_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def send_to_telegram(message):\n",
        "    apiToken = 'apiKeyHere'\n",
        "    chatID = 'chatIDHere'\n",
        "    apiURL = f'https://api.telegram.org/bot{apiToken}/sendMessage'\n",
        "\n",
        "    try:\n",
        "        response = requests.post(apiURL, json={'chat_id': chatID, 'text': message})\n",
        "        # print(response.text)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "# send_to_telegram('Training completed in folder ' + run_dir)\n",
        "\n",
        "\n",
        "# check if 'best_notified_accyracy_yet.txt' exists\n",
        "# if it does, read the value, compare to the current and notify via telegram if the current is better\n",
        "# if it doesn't, create it and write the current value\n",
        "\n",
        "def save_and_notify_if_greater(newvalue, metricfilepath, metric_name):\n",
        "    BA_FILE = metricfilepath\n",
        "    if os.path.exists(BA_FILE):\n",
        "        with open(BA_FILE) as f:\n",
        "            best_notified_metric_yet = float(f.readline())\n",
        "    else:\n",
        "        best_notified_metric_yet = 0.0\n",
        "\n",
        "    if newvalue > best_notified_metric_yet:\n",
        "        message = str(round(newvalue,4)) + '\\nfrom run in folder ' + run_dir\n",
        "        with open(BA_FILE,'w') as f:\n",
        "            f.write(message)\n",
        "        send_to_telegram('New best '+str(metric_name)+': '+message)\n",
        "\n",
        "save_and_notify_if_greater(metrics_to_save['average_fold_accuracy'], os.path.join(MODELFOLDER,'best_accuracy_yet_notified.txt'), 'Accuracy')\n",
        "save_and_notify_if_greater(metrics_to_save['macro avg f1-score'], os.path.join(MODELFOLDER,'best_maf1_yet_notified.txt'), 'Macro Average F1-Score')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uLTufCRmlpIW",
        "4pBrSDphxyxL"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
