{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAJRnwSBQNbQ"
      },
      "source": [
        "# Expressive Guitar Technique classifier\n",
        "Ph.D. research project of [Domenico Stefani](work.domenicostefani.com)  \n",
        "This notebook loads a dataset of feature vectors extracted from **pitched** and **percussive** sounds recorded with many acoustic guitars.\n",
        "The techniques/classes recorded are:  \n",
        "\n",
        "0.    **Kick**      (Palm on lower body)\n",
        "1.    **Snare 1**   (All fingers on lower side)\n",
        "2.    **Tom**       (Thumb on higher body)\n",
        "3.    **Snare 2**   (Fingers on the muted strings, over the end\n",
        "of the fingerboard)\n",
        "___\n",
        "4.    **Natural Harmonics** (Stop strings from playing the dominant frequency, letting harmonics ring)\n",
        "5.    **Palm Mute** (Muting partially the strings with the palm\n",
        "of the pick hand)\n",
        "6.    **Pick Near Bridge** (Playing toward the bridge/saddle)\n",
        "7.    **Pick Over the Soundhole** (Playing over the sound hole)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a2ha_JDqV9I"
      },
      "source": [
        "## Import modules and mount drive folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # For NON-Windowed - 100ms window\n",
        "# DATASET_FILENAME = 'onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20221206-165551_SUPERLONGdataset-phase3PROCESSED_FEATURES.pickle'\n",
        "# # For NON-Windowed - 14.67ms window\n",
        "# DATASET_FILENAME = 'onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20221201-182312_REALTIMEdataset-phase3PROCESSED_FEATURES.pickle'\n",
        "\n",
        "# # For WINDOWED -  14.67ms window\n",
        "# DATASET_FILENAME = 'windowed-test-704.csv'\n",
        "# # For WINDOWED -  100ms window (pitched)\n",
        "# DATASET_FILENAME = 'windowed-test-4800.csv'\n",
        "# # For WINDOWED -  100ms window (percussive: kick mf)\n",
        "# DATASET_FILENAME = 'windowed-test-4800-kick-mf.csv'\n",
        "\n",
        "# PAPER_DATASET - WINDOWED -  14.66ms window (704 samples)\n",
        "DATASET_FILENAME = 'paper-onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20230119-141803_windowed704-mainset-phase3PROCESSED_FEATURES.pickle'\n",
        "\n",
        "# # PAPER_DATASET - WINDOWED -  44ms window (2112 samples)\n",
        "# DATASET_FILENAME = 'paper-onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20230119-141803_windowed2112-mainset-phase3PROCESSED_FEATURES.pickle'\n",
        "\n",
        "# # PAPER_DATASET - WINDOWED -  72ms window (3456 samples)\n",
        "# DATASET_FILENAME = 'paper-onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20230119-141803_windowed3456-mainset-phase3PROCESSED_FEATURES.pickle'\n",
        "\n",
        "# # PAPER_DATASET - WINDOWED -  100ms window\n",
        "# DATASET_FILENAME = 'paper-onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20230119-105343_windowed4800-mainset-phase3PROCESSED_FEATURES.pickle'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yPrPhmjHk-kc"
      },
      "outputs": [],
      "source": [
        "# Choose ClassificationTask task\n",
        "from enum import Enum\n",
        "class ClassificationTask(Enum):\n",
        "    FULL_8_CLASS_PROBLEM,BINARY_PERCUSSIVE_PITCHED,PERCUSSIVE_4_ONLY,PITCHED_4_ONLY,PERCUSSIVE_PLUS_PITCHED_CLASS = ((1,'full'), (2,'binary'), (3,'perc'), (4,'pitch'), (5,'perc+pitch'))\n",
        "class FeatureSelection(Enum):\n",
        "    NONE,MANUAL_VARIABLES,MANUAL_LIST,AUTO_ANOVA,AUTO_RELIEF = (0, 1, 2, 3, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_task = ClassificationTask.FULL_8_CLASS_PROBLEM\n",
        "# classification_task = ClassificationTask.BINARY_PERCUSSIVE_PITCHED\n",
        "# classification_task = ClassificationTask.PERCUSSIVE_4_ONLY\n",
        "# classification_task = ClassificationTask.PERCUSSIVE_PLUS_PITCHED_CLASS\n",
        "\n",
        "# FEATURE_SELECTION = FeatureSelection.MANUAL_VARIABLES\n",
        "# FEATURE_SELECTION = FeatureSelection.MANUAL_LIST\n",
        "FEATURE_SELECTION = FeatureSelection.AUTO_ANOVA #ANOVA: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html\n",
        "# FEATURE_SELECTION = FeatureSelection.AUTO_RELIEF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VuprRjSbkuh3"
      },
      "outputs": [],
      "source": [
        "# Install module for the ReliefF feature selection\n",
        "# !pip install skrebate\n",
        "# !pip install tensorboard\n",
        "# !pip3 install pickle5\n",
        "# !pip3 install tensorflow==2.4.1\n",
        "# !pip3 install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dw8otQ7AQMaV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not running on CoLab\n"
          ]
        }
      ],
      "source": [
        "DROP_EXTRA_PERCUSSIVE_SOUNDS = False # If true, drop the data from files that have 'extra' in the filename, which otherwise make the dataset unbalanced\n",
        "\n",
        "DO_NORMALIZE_DATA = True\n",
        "\n",
        "DO_NORMALIZE_FOR_FEATURE_SELECTION = True\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import strftime, time\n",
        "import pickle\n",
        "import re\n",
        "import shutil\n",
        "\n",
        "COLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if COLAB:\n",
        "    print('Running on CoLab')\n",
        "    #Connect and mount the drive folder that contains the train dataset and the output folder\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive', force_remount=False)\n",
        "\n",
        "    HOMEBASE = os.path.join('/content','gdrive','MyDrive','dottorato','Publications','02-IEEE-RTEmbeddedTimbreClassification(submitted)','Classifier')\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    HOMEBASE = \"./../\"\n",
        "DATAFOLDER = os.path.join(HOMEBASE,\"data/phase3\")\n",
        "MODELFOLDER = os.path.join(HOMEBASE,\"output\")\n",
        "\n",
        "RELIEF_CACHE_FILEPATH = os.path.join(DATAFOLDER,'relief_cache.pickle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sY_34JvX6uFT"
      },
      "outputs": [],
      "source": [
        "def is_notebook() -> bool:\n",
        "    try:\n",
        "        shell = get_ipython().__class__.__name__\n",
        "        if shell == 'ZMQInteractiveShell':\n",
        "            return True   # Jupyter notebook or qtconsole\n",
        "        elif shell == 'TerminalInteractiveShell':\n",
        "            return False  # Terminal running IPython\n",
        "        else:\n",
        "            return False  # Other type (?)\n",
        "    except NameError:\n",
        "        return False      # Probably standard Python interpreter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2hdmJnSsEOM"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CozyQAQgznvK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from file: paper-onlycorrectdetections_extraction-outputPROCESSED_FEATURES_20230119-105343_windowed4800-mainset-phase3PROCESSED_FEATURES.pickle\n",
            "Reading dataset from pickle...\n",
            "Successfully Loaded!\n",
            "It took 25.4s to load from regular pickle\n",
            "Dataset loaded!\n",
            "\n",
            "Data is WINDOWED! 38 windows\n"
          ]
        }
      ],
      "source": [
        "print('Loading dataset from file:',DATASET_FILENAME)\n",
        "\n",
        "DATA_IS_RAW = False\n",
        "DATA_IS_WINDOWED = False\n",
        "if os.path.splitext(DATASET_FILENAME)[1] == '.pickle':\n",
        "    print(\"Reading dataset from pickle...\")\n",
        "    DATASET_PATH = os.path.join(DATAFOLDER,DATASET_FILENAME)\n",
        "    startime = time()\n",
        "    with open(DATASET_PATH,'rb') as pf:\n",
        "        featuredataset = pickle.load(pf)\n",
        "    print('Successfully Loaded!\\nIt took %.1fs to load from regular pickle' % (time()-startime))\n",
        "elif os.path.splitext(DATASET_FILENAME)[1] == '.csv':\n",
        "    print(\"Reading dataset from csv...\")\n",
        "    DATASET_PATH = os.path.join(DATAFOLDER,DATASET_FILENAME)\n",
        "    startime = time()\n",
        "    featuredataset = pd.read_csv(DATASET_PATH)\n",
        "    print('Successfully Loaded!\\nIt took %.1fs to load from csv' % (time()-startime))\n",
        "    DATA_IS_RAW = featuredataset[featuredataset['1_attackTime_peaksamp'].isna()].shape[0] > 0\n",
        "    featuredataset = featuredataset[~featuredataset['1_attackTime_peaksamp'].isna()] # Dropping Start and Stop markers\n",
        "    featuredataset.reset_index(inplace=True,drop=True)\n",
        "else:\n",
        "    raise Exception(\"Extension %s not supported!\" % os.path.splitext(DATASET_FILENAME)[1])\n",
        "    \n",
        "\n",
        "print('Dataset loaded!')\n",
        "# display(featuredataset)\n",
        "\n",
        "print('Data is RAW!' if DATA_IS_RAW else '')\n",
        "\n",
        "DATA_IS_WINDOWED = featuredataset.columns.str.match('0_').any()\n",
        "window_indexes = sorted(list(set([e.split('_')[0] for e in featuredataset.columns[featuredataset.columns.str.match('\\d+_')].to_list()])))\n",
        "\n",
        "print('Data is WINDOWED!' if DATA_IS_WINDOWED else '', '%d windows' % (len(window_indexes)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from glob import glob\n",
        "# augmented_featuredataset_list = []\n",
        "# if USE_AUGMENTED_DATA:\n",
        "#     augmented_data_paths = glob(os.path.join(DATAFOLDER,'augmented_data','*.pickle'))\n",
        "#     for augmented_data_path in augmented_data_paths:\n",
        "#         print(\"Loading file %s\" % os.path.basename(augmented_data_path))\n",
        "#         with open(augmented_data_path,'rb') as pf:\n",
        "#             augmented_featuredataset_list.append(pickle.load(pf))\n",
        "#     augmented_featuredataset = pd.concat(augmented_featuredataset_list, ignore_index=True)\n",
        "#     print(\"Loaded %d augmented samples\" % len(augmented_featuredataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E1rKcNy5RqZ"
      },
      "source": [
        "### Drop features that we have found to be problematic with feature selection and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Uhip8r7F4sSv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied\n",
            "indexes gotten Max:37\n",
            "Doing stuff for index 0\n",
            "Dropping\n",
            "Doing stuff for index 1\n",
            "Dropping\n",
            "Doing stuff for index 2\n",
            "Dropping\n",
            "Doing stuff for index 3\n",
            "Dropping\n",
            "Doing stuff for index 4\n",
            "Dropping\n",
            "Doing stuff for index 5\n",
            "Dropping\n",
            "Doing stuff for index 6\n",
            "Dropping\n",
            "Doing stuff for index 7\n",
            "Dropping\n",
            "Doing stuff for index 8\n",
            "Dropping\n",
            "Doing stuff for index 9\n",
            "Dropping\n",
            "Doing stuff for index 10\n",
            "Dropping\n",
            "Doing stuff for index 11\n",
            "Dropping\n",
            "Doing stuff for index 12\n",
            "Dropping\n",
            "Doing stuff for index 13\n",
            "Dropping\n",
            "Doing stuff for index 14\n",
            "Dropping\n",
            "Doing stuff for index 15\n",
            "Dropping\n",
            "Doing stuff for index 16\n",
            "Dropping\n",
            "Doing stuff for index 17\n",
            "Dropping\n",
            "Doing stuff for index 18\n",
            "Dropping\n",
            "Doing stuff for index 19\n",
            "Dropping\n",
            "Doing stuff for index 20\n",
            "Dropping\n",
            "Doing stuff for index 21\n",
            "Dropping\n",
            "Doing stuff for index 22\n",
            "Dropping\n",
            "Doing stuff for index 23\n",
            "Dropping\n",
            "Doing stuff for index 24\n",
            "Dropping\n",
            "Doing stuff for index 25\n",
            "Dropping\n",
            "Doing stuff for index 26\n",
            "Dropping\n",
            "Doing stuff for index 27\n",
            "Dropping\n",
            "Doing stuff for index 28\n",
            "Dropping\n",
            "Doing stuff for index 29\n",
            "Dropping\n",
            "Doing stuff for index 30\n",
            "Dropping\n",
            "Doing stuff for index 31\n",
            "Dropping\n",
            "Doing stuff for index 32\n",
            "Dropping\n",
            "Doing stuff for index 33\n",
            "Dropping\n",
            "Doing stuff for index 34\n",
            "Dropping\n",
            "Doing stuff for index 35\n",
            "Dropping\n",
            "Doing stuff for index 36\n",
            "Dropping\n",
            "Doing stuff for index 37\n",
            "Dropping\n"
          ]
        }
      ],
      "source": [
        "def drop_unused_features(features_df: pd.DataFrame, is_windowed = False, inplace = False) -> pd.DataFrame:\n",
        "    if not inplace:\n",
        "        res_df = features_df.copy()\n",
        "        print('Copied',flush=True)\n",
        "    else:\n",
        "        res_df = features_df\n",
        "        print('Not Copied',flush=True)\n",
        "\n",
        "\n",
        "    if is_windowed:\n",
        "        window_indexes = sorted(list(set([int(e.split('_')[0]) for e in res_df.columns[res_df.columns.str.match('\\d+_')].to_list()])))\n",
        "        print('indexes gotten len:%d'%(len(window_indexes)),flush=True)\n",
        "\n",
        "        for window_index in window_indexes:\n",
        "            print('Dropping bad columns for index %d'%(window_index),flush=True)\n",
        "\n",
        "            if '%s_attackTime_peaksamp'%window_index       not in res_df.columns.to_list() or\\\n",
        "               '%s_attackTime_attackStartIdx'%window_index not in res_df.columns.to_list() or\\\n",
        "               '%s_peakSample_index'%window_index          not in res_df.columns.to_list():\n",
        "                # raise Exception(\"The features dataframe does not contain the required columns!\")\n",
        "                # Show warning instead of exception\n",
        "                print(\"Warning! The features dataframe does not contain the required columns! (%s, %s, %s)\"%('%s_attackTime_peaksamp'%window_index,'%s_attackTime_attackStartIdx'%window_index,'%s_peakSample_index'%window_index))\n",
        "            else:\n",
        "                res_df.drop(columns=['%s_attackTime_peaksamp' % window_index,\\\n",
        "                                        '%s_attackTime_attackStartIdx' % window_index,\\\n",
        "                                        '%s_peakSample_index' % window_index], inplace=True)\n",
        "    else:\n",
        "        if 'attackTime_peaksamp'       not in res_df.columns.to_list() or\\\n",
        "        'attackTime_attackStartIdx' not in res_df.columns.to_list() or\\\n",
        "        'peakSample_index'          not in res_df.columns.to_list():\n",
        "            # raise Exception(\"The features dataframe does not contain the required columns!\")\n",
        "            print(\"Warning! The features dataframe does not contain the required columns! (%s, %s, %s)\" % ('attackTime_peaksamp' in res_df.columns.to_list(), 'attackTime_attackStartIdx' in res_df.columns.to_list(), 'peakSample_index' in res_df.columns.to_list()))\n",
        "        else:\n",
        "            res_df.drop(columns=['attackTime_peaksamp',\\\n",
        "                                    'attackTime_attackStartIdx',\\\n",
        "                                    'peakSample_index'], inplace=True)\n",
        "    return res_df\n",
        "featuredataset = drop_unused_features(featuredataset, is_windowed = DATA_IS_WINDOWED)\n",
        "# if USE_AUGMENTED_DATA:\n",
        "#     augmented_featuredataset = drop_unused_features(augmented_featuredataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0xh-UknklQy"
      },
      "source": [
        "### If specified, drop extra percussive recorded data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvUB_btbklQy"
      },
      "outputs": [],
      "source": [
        "# assert featuredataset.shape == (EXPECTED_DATASED_SIZE, 504)\n",
        "if DROP_EXTRA_PERCUSSIVE_SOUNDS and not DATA_IS_RAW:\n",
        "    to_drop_count = np.count_nonzero(featuredataset.meta_audiofilePath.str.contains(\"additional-500\").values)\n",
        "    if to_drop_count >= 0:\n",
        "        print('Dropping %d additional percussive recordings because \"DROP_EXTRA_PERCUSSIVE_SOUNDS\" was specified.'%(to_drop_count))\n",
        "        featuredataset = featuredataset[~featuredataset.meta_audiofilePath.str.contains(\"additional-500\")].reset_index(drop=True)\n",
        "        print('Dataset shape after dropping extra percussive recordings: %s'%(str(featuredataset.shape)))\n",
        "    # assert featuredataset.shape == (EXPECTED_DATASED_SIZE-2237, 504)\n",
        "\n",
        "\n",
        "# if USE_AUGMENTED_DATA and DROP_EXTRA_PERCUSSIVE_SOUNDS_FROMAUG:\n",
        "#     augmented_featuredataset_dr = augmented_featuredataset.copy()\n",
        "#     to_drop_count_aug = np.count_nonzero(augmented_featuredataset.meta_augmentation_source.str.contains(\"additional-500\").values)\n",
        "#     if to_drop_count_aug >= 0:\n",
        "#         print('Dropping %d additional percussive recordings because \"DROP_EXTRA_PERCUSSIVE_SOUNDS\" was specified.'%(to_drop_count_aug))\n",
        "#         augmented_featuredataset_dr = augmented_featuredataset[~augmented_featuredataset.meta_augmentation_source.str.contains(\"additional-500\")].reset_index(drop=True)\n",
        "#         print('Dataset shape after dropping extra percussive recordings: %s'%(str(augmented_featuredataset_dr.shape)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HN56MAc5kjA"
      },
      "outputs": [],
      "source": [
        "# Extract separate DFs\n",
        "from typing import Tuple\n",
        "\n",
        "# Divide dataset into metadata, features and labels\n",
        "def divide_dataset(features_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    metadata = features_df.filter(regex='^meta_',axis=1)\n",
        "    labels = features_df.meta_expressive_technique_id\n",
        "    features = features_df.loc[:,[col for col in features_df.columns if col not in metadata.columns]]\n",
        "    # Convert to numeric formats where possible (somehow convert_dtypes doesn't work [https://stackoverflow.com/questions/65915048/pandas-convert-dtypes-not-working-on-numbers-marked-as-objects])\n",
        "    metadata = metadata.apply(pd.to_numeric, errors='ignore')\n",
        "    labels = labels.apply(pd.to_numeric, errors='ignore')\n",
        "    features = features.apply(pd.to_numeric, errors='ignore')\n",
        "    return metadata, features, labels\n",
        "\n",
        "if not DATA_IS_RAW:\n",
        "    metadata, features, labels = divide_dataset(featuredataset)\n",
        "    assert metadata.shape[1] == 9\n",
        "else:\n",
        "    metacolumns = ['onsetDetectionTime','featureComputationTime','featureExtractionWindowSize','sampleRate','blockSize']\n",
        "    datacolumns = featuredataset.columns.difference(metacolumns)\n",
        "\n",
        "    metadata_r = featuredataset[metacolumns]\n",
        "    features_r = featuredataset[datacolumns]\n",
        "    labels_r = pd.Series([0 for i in range(len(features_r))]) # Dummy labels for raw data #TODO: remove if not needed\n",
        "\n",
        "# if SUPERLONG_WINDOW:\n",
        "#     assert features.shape[1] == 2552-9\n",
        "# else:\n",
        "#     assert features.shape[1] == 495\n",
        "\n",
        "# if USE_AUGMENTED_DATA:\n",
        "#     metadata_aug, features_aug, labels_aug = divide_dataset(augmented_featuredataset_dr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1iiyTkcYKFi"
      },
      "outputs": [],
      "source": [
        "def get_classes_description(classftask: ClassificationTask):\n",
        "    if classification_task == ClassificationTask.FULL_8_CLASS_PROBLEM:\n",
        "        classes_desk = {0:\"Kick\",1:\"Snare 1\",2:\"Tom\",3:\"Snare 2\",4:\"Natural Harmonics\",5:\"Palm Mute\",6:\"Pick Near Bridge\",7:\"Pick Over the Soundhole\"}\n",
        "    elif classification_task == ClassificationTask.BINARY_PERCUSSIVE_PITCHED:\n",
        "        classes_desk = {0:\"Percussive\",1:\"Pitched\"}\n",
        "    elif classification_task == ClassificationTask.PERCUSSIVE_4_ONLY:\n",
        "        classes_desk = {0:\"Kick\", 1:\"Snare 1\", 2:\"Tom\", 3:\"Snare 2\"}\n",
        "    elif classification_task == ClassificationTask.PITCHED_4_ONLY:\n",
        "        classes_desk = {0:\"Natural Harmonics\", 1:\"Palm Mute\", 2:\"Pick Near Bridge\", 3:\"Pick Over the Soundhole\"}\n",
        "    elif classification_task == ClassificationTask.PERCUSSIVE_PLUS_PITCHED_CLASS:\n",
        "        classes_desk = {0:\"Kick\", 1:\"Snare 1\", 2:\"Tom\", 3:\"Snare 2\", 4:\"Pitched\"}\n",
        "    else:\n",
        "        raise Exception('The Classification Task selected is not supported')\n",
        "    classes = list(classes_desk.keys())\n",
        "    return classes,classes_desk\n",
        "\n",
        "def filter_dataset(tofilt_features,tofilt_labels,tofilt_metadata,classftask: ClassificationTask, hardcoded_sizes_test = False):\n",
        "    if classification_task == ClassificationTask.FULL_8_CLASS_PROBLEM:\n",
        "        pass\n",
        "    elif classification_task == ClassificationTask.BINARY_PERCUSSIVE_PITCHED:\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "\n",
        "        tofilt_labels = tofilt_labels.replace([0,1,2,3],[0,0,0,0])\n",
        "        tofilt_labels = tofilt_labels.replace([4,5,6,7],[1,1,1,1])\n",
        "    elif classification_task == ClassificationTask.PERCUSSIVE_4_ONLY:\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "\n",
        "        filtered_idxs = tofilt_labels < 4\n",
        "        tofilt_features = tofilt_features[filtered_idxs]\n",
        "        tofilt_labels = tofilt_labels[filtered_idxs]\n",
        "        tofilt_metadata = tofilt_metadata[filtered_idxs].copy()\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "        if hardcoded_sizes_test:\n",
        "            assert len(tofilt_features) == 1620\n",
        "    elif classification_task == ClassificationTask.PITCHED_4_ONLY:\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "        filtered_idxs = tofilt_labels >= 4\n",
        "        tofilt_features = tofilt_features[filtered_idxs]\n",
        "        tofilt_metadata = tofilt_metadata[filtered_idxs].copy()\n",
        "        tofilt_labels = tofilt_labels[filtered_idxs]\n",
        "        tofilt_labels = tofilt_labels.replace([4,5,6,7],[0,1,2,3])\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "    elif classification_task == ClassificationTask.PERCUSSIVE_PLUS_PITCHED_CLASS:\n",
        "        assert len(tofilt_features) == len(tofilt_labels)\n",
        "        tofilt_labels = tofilt_labels.replace([5,6,7],[4,4,4])\n",
        "    else:\n",
        "        raise Exception('The Classification Task selected is not supported')\n",
        "\n",
        "\n",
        "    tofilt_features.reset_index(drop=True,inplace=True)\n",
        "    tofilt_labels.reset_index(drop=True,inplace=True)\n",
        "    tofilt_metadata.reset_index(drop=True,inplace=True)\n",
        "\n",
        "    return tofilt_features, tofilt_labels, tofilt_metadata\n",
        "\n",
        "if not DATA_IS_RAW:\n",
        "    original_dataset_features = features.copy()\n",
        "    dataset_labels = labels.copy()\n",
        "    dataset_metadata = metadata.copy()\n",
        "\n",
        "    CLASSES,CLASSES_DESC = get_classes_description(classification_task)\n",
        "    original_dataset_features,dataset_labels,dataset_metadata = filter_dataset(original_dataset_features,dataset_labels,dataset_metadata,classification_task,hardcoded_sizes_test=False)\n",
        "    # if USE_AUGMENTED_DATA:\n",
        "    #     features_aug,labels_aug,metadata_aug = filter_dataset(features_aug,labels_aug,metadata_aug,classification_task,hardcoded_sizes_test=False)\n",
        "    #     assert len(np.sort(CLASSES)) == len(np.sort(pd.unique(labels_aug))) and np.equal(np.sort(CLASSES),np.sort(pd.unique(labels_aug))).all()\n",
        "\n",
        "    assert len(np.sort(CLASSES)) == len(np.sort(pd.unique(dataset_labels))) and np.equal(np.sort(CLASSES),np.sort(pd.unique(dataset_labels))).all()\n",
        "else:\n",
        "    original_dataset_features = features_r.copy()\n",
        "    dataset_labels = labels_r.copy()\n",
        "    dataset_metadata = metadata_r.copy()\n",
        "\n",
        "    CLASSES_DESC = {0:\"Dummy\"}\n",
        "    CLASSES = list(CLASSES_DESC.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_JEEbL-mcJ-"
      },
      "outputs": [],
      "source": [
        "toprint = [(original_dataset_features,'Main datase')]\n",
        "# if USE_AUGMENTED_DATA:\n",
        "#     toprint.append((features_aug,'Augmented data'))\n",
        "\n",
        "for dat,name in toprint:\n",
        "    print('Dataset \"'+name+'\" read')\n",
        "    print(\"| Entries: \"+str(dat.shape[0]))\n",
        "    print(\"╰─ Features: \"+str(dat.shape[1]))\n",
        "\n",
        "original_feature_number = original_dataset_features.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2gv9fFFavMz"
      },
      "outputs": [],
      "source": [
        "# Compute has of the dataset files.\n",
        "# This are used to cache precomputed feature selection with ReliefF (Which is rather slow)\n",
        "import hashlib\n",
        " \n",
        "dataset_sha256_hash = hashlib.sha256()\n",
        "with open(DATASET_PATH,\"rb\") as fy:\n",
        "    for byte_block in iter(lambda: fy.read(4096),b\"\"):    # Read and update hash string value in blocks of 4K\n",
        "        dataset_sha256_hash.update(byte_block)\n",
        "dataset_sha256_hash = dataset_sha256_hash.hexdigest()\n",
        "\n",
        "print(dataset_sha256_hash)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3ND_A4d6uFT"
      },
      "source": [
        "## Arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVHOAmQ-6uFU"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
        "\"\"\"                               +-----------------------------------------------------------------------------------------------+                                 #\n",
        "#                                 |    CHANGE THE VALUES HERE IF RUNNING THE TRAINING FROM A JUPYTER NOTEBOOK (e.g., on Colab)    |                                 #\n",
        "#                                 + ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ +                                 #\n",
        "\"\"\" #↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓#\n",
        "args = {'features':      'all', \n",
        "        'verbose':       False}\n",
        "#↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑#\n",
        "\"\"\"                               + ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ +                                 #\n",
        "#                                 |    CHANGE THE VALUES HERE IF RUNNING THE TRAINING FROM A JUPYTER NOTEBOOK (e.g., on Colab)    |                                 #\n",
        "#                                 +-----------------------------------------------------------------------------------------------+                                 #\n",
        "\"\"\"#----------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
        "print('Arguments: [' + ', '.join([str(k)+':'+str(v) for k,v in args.items()]) + ']')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjF3Cif5zr1p"
      },
      "source": [
        "## Subset features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--hCfGHKZK98"
      },
      "outputs": [],
      "source": [
        "def get_manual_selected_features(data,prefix = ''):\n",
        "    print (\"Subsetting features...\")\n",
        "    columns_to_keep = []\n",
        "    # if USE_ATTACKTIME_PEAKSAMP:\n",
        "    #     columns_to_keep.append(\"attackTime_peaksamp\")\n",
        "    # if USE_ATTACKTIME_ATTACKSTARTIDX:\n",
        "    #     columns_to_keep.append(\"attackTime_attackStartIdx\")\n",
        "    if USE_ATTACKTIME_VALUE:\n",
        "        columns_to_keep.append(prefix+\"attackTime_value\")\n",
        "    if USE_BARKSPECBRIGHTNESS:\n",
        "        columns_to_keep.append(prefix+\"barkSpecBrightness\")\n",
        "    if USE_PEAKSAMPLE_VALUE:\n",
        "        columns_to_keep.append(prefix+\"peakSample_value\")\n",
        "    # if USE_PEAKSAMPLE_INDEX:\n",
        "    #     columns_to_keep.append(\"peakSample_index\")\n",
        "    if USE_ZEROCROSSING:\n",
        "        columns_to_keep.append(prefix+\"zeroCrossing\")\n",
        "\n",
        "    assert USE_BARKSPEC <= 50 and USE_BARKSPEC >= 0 and USE_BFCC <= 49 and USE_BFCC >= 0 and USE_CEPSTRUM <= 353 and USE_CEPSTRUM >= 0 and USE_MFCC <= 37 and USE_MFCC >= 0\n",
        "\n",
        "    if USE_BARKSPEC > 0:\n",
        "        columns_to_keep += [prefix+'barkSpec_'+str(i+1) for i in range(USE_BARKSPEC)]\n",
        "    if USE_BFCC > 0:\n",
        "        columns_to_keep += [prefix+'bfcc_'+str(i+2) for i in range(USE_BFCC)]  # +2 is correct here since we want to skip the first normalized coefficient\n",
        "    if USE_CEPSTRUM > 0:\n",
        "        columns_to_keep += [prefix+'cepstrum_'+str(i+1) for i in range(USE_CEPSTRUM)]\n",
        "    if USE_MFCC > 0:\n",
        "        columns_to_keep += [prefix+'mfcc_'+str(i+2) for i in range(USE_MFCC)]  # +2 is correct here since we want to skip the first normalized coefficient\n",
        "\n",
        "    return columns_to_keep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agcUWSWVbokS"
      },
      "outputs": [],
      "source": [
        "# # To Compeltely reset RelieFF cache\n",
        "# with open(RELIEF_CACHE_FILEPATH, 'wb') as rcf:\n",
        "#     pickle.dump(set(), rcf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBDXJV0dnx2W"
      },
      "outputs": [],
      "source": [
        "# how_many_examples_per_class =10\n",
        "# subselection = list(range(0,how_many_examples_per_class))+\\\n",
        "#                list(range(600,600+how_many_examples_per_class))+\\\n",
        "#                list(range(1100,1100+how_many_examples_per_class))+\\\n",
        "#                list(range(1400,1400+how_many_examples_per_class))+\\\n",
        "#                list(range(1900,1900+how_many_examples_per_class))+\\\n",
        "#                list(range(3000,3000+how_many_examples_per_class))+\\\n",
        "#                list(range(9000,9000+how_many_examples_per_class))+\\\n",
        "#                list(range(14000,14000+how_many_examples_per_class))\n",
        "\n",
        "# testprova_dataset_features = original_dataset_features.iloc[subselection]\n",
        "# testprova_dataset_labels = dataset_labels.iloc[subselection]\n",
        "import os, platform, subprocess, re\n",
        "\n",
        "def get_processor_name():\n",
        "    if platform.system() == \"Windows\":\n",
        "        return platform.processor()\n",
        "    elif platform.system() == \"Darwin\":\n",
        "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin'\n",
        "        command =\"sysctl -n machdep.cpu.brand_string\"\n",
        "        return subprocess.check_output(command).strip()\n",
        "    elif platform.system() == \"Linux\":\n",
        "        command = \"cat /proc/cpuinfo\"\n",
        "        all_info = subprocess.check_output(command, shell=True).decode().strip()\n",
        "        for line in all_info.split(\"\\n\"):\n",
        "            if \"model name\" in line:\n",
        "                return re.sub( \".*model name.*:\", \"\", line,1)\n",
        "    return \"\"\n",
        "\n",
        "class ReliefCacheElem(dict):\n",
        "\n",
        "    PRINT_HASH = False\n",
        "\n",
        "    def __init__(self,dataset_sha256,n_neighbors,relieff_top_features,relieff_feature_importances,time_of_computation):\n",
        "        self.dataset_sha256 = dataset_sha256\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.relieff_top_features = relieff_top_features\n",
        "        self.relieff_feature_importances = relieff_feature_importances\n",
        "        self.date = strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
        "\n",
        "        self.cpu_info = get_processor_name()\n",
        "        self.time_of_computation = time_of_computation\n",
        "\n",
        "    def __key(self):\n",
        "        return tuple([self.dataset_sha256,\n",
        "                     self.n_neighbors,\n",
        "                     str(self.relieff_top_features),\n",
        "                     str(self.relieff_feature_importances)])\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.__key())\n",
        "\n",
        "    def __str__(self):\n",
        "        res = '{date: '+self.date+', n_neighbors:'+str(self.n_neighbors)\n",
        "        \n",
        "        if self.PRINT_HASH:\n",
        "            res += 'dataset_sha256:'+str(self.dataset_sha256)+','\n",
        "\n",
        "        res += 'cpu_info:'+str(self.cpu_info)+','\n",
        "        res += 'time_of_computation:'+str(self.time_of_computation)+','\n",
        "        res += '}'\n",
        "        return res\n",
        "\n",
        "\n",
        "def relieff_selection(X:list,y:list,n_features,n_neighbors,relief_cache_filepath,verbose_ = True):\n",
        "    relief_data_X = X\n",
        "    relief_data_y = y\n",
        "    relief_top_features_ = None\n",
        "    relief_feature_importances_ = None\n",
        "    # First check if result is already cached\n",
        "    ## Load Cache\n",
        "    relief_cache = None\n",
        "\n",
        "    ##----------------------------------------------##\n",
        "    if not os.path.exists(relief_cache_filepath):\n",
        "        raise Exception(\"RELIEF CACHE NOT FOUND at '\"+relief_cache_filepath+\"'! Comment exception to create empty cache\")\n",
        "        with open(relief_cache_filepath, 'wb') as rcf:\n",
        "            pickle.dump(set(), rcf)\n",
        "    ##----------------------------------------------##\n",
        "\n",
        "    with open(relief_cache_filepath,'rb') as rcf:\n",
        "        relief_cache = pickle.load(rcf)\n",
        "        if verbose_: \n",
        "            print('Loaded Relief cache ('+str(len(relief_cache))+' solutions)')\n",
        "    # Check if present\n",
        "    for cache_elem in relief_cache:\n",
        "        if cache_elem.dataset_sha256 == dataset_sha256_hash and\\\n",
        "           cache_elem.n_neighbors == n_neighbors:\n",
        "            if verbose_:\n",
        "                print(\"Result found in cache!\")\n",
        "            return cache_elem.relieff_top_features[:n_features]\n",
        "    \n",
        "    # If not present, compute\n",
        "    if verbose_:\n",
        "        print(\"Result NOT found in cache, computing now... (might take a long while)\")\n",
        "    \n",
        "    from skrebate import ReliefF\n",
        "    r = ReliefF(n_neighbors=n_neighbors,verbose=verbose_)\n",
        "    \n",
        "    start_fit = time()\n",
        "    r.fit(X=relief_data_X,y=relief_data_y)\n",
        "    top_features = r.top_features_\n",
        "    feature_importances = r.feature_importances_\n",
        "    stop_fit = time()\n",
        "\n",
        "    if verbose_:\n",
        "        print(\"Done. Now storing in cache...\")\n",
        "\n",
        "    savedata = ReliefCacheElem(\n",
        "        dataset_sha256 = dataset_sha256_hash,\n",
        "        n_neighbors = n_neighbors,\n",
        "        relieff_top_features = top_features,\n",
        "        relieff_feature_importances = feature_importances,\n",
        "        time_of_computation = stop_fit - start_fit)\n",
        "    relief_cache.add(savedata)\n",
        "    with open(relief_cache_filepath, 'wb') as rcf:\n",
        "        pickle.dump(relief_cache, rcf)\n",
        "\n",
        "    if verbose_:\n",
        "        print(\"Done.\")\n",
        "\n",
        "\n",
        "    return top_features[:n_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oas8vnnMQ0uP"
      },
      "outputs": [],
      "source": [
        "if FEATURE_SELECTION == FeatureSelection.AUTO_RELIEF:\n",
        "    with open(RELIEF_CACHE_FILEPATH,'rb') as rcf:\n",
        "        relief_cache = pickle.load(rcf)\n",
        "        \n",
        "        print(len(relief_cache),'cached relief runs:')\n",
        "\n",
        "        if len(relief_cache) != 0:\n",
        "            samedataset = [e for e in relief_cache if e.dataset_sha256 == dataset_sha256_hash]\n",
        "            print('('+str(len(samedataset))+'/'+str(len(relief_cache)), 'are from the same dataset)')\n",
        "            if len(samedataset) != len(relief_cache):\n",
        "                raise Exception('Some of the cached results are from a different dataset!')\n",
        "\n",
        "            for i,e in enumerate(relief_cache):\n",
        "                print(i,':',e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVkiDFjjztbM"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------------------------------------------------------- #\n",
        "\n",
        "if args['features'] == 'all':\n",
        "    FEATURE_SELECTION = FeatureSelection.NONE\n",
        "    AUTO_FEATURE_NUMBER = len(original_dataset_features.columns)\n",
        "else:\n",
        "    AUTO_FEATURE_NUMBER = args['features']    # If FEATURE_SELECTION is AUTO_ANOVA or AUTO_RELIEF, select this number of features automatically\n",
        "\n",
        "# ------------------------------------------------------------------------------------------------------------------------------- #\n",
        "\n",
        "if DO_NORMALIZE_FOR_FEATURE_SELECTION:\n",
        "    print('Normalizing data for feature selection...')\n",
        "    feature_dataset_for_selection = original_dataset_features.to_numpy()\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    feature_dataset_for_selection = StandardScaler().fit_transform(feature_dataset_for_selection)\n",
        "    feature_dataset_for_selection_D = pd.DataFrame(columns=original_dataset_features.columns, data=feature_dataset_for_selection)\n",
        "    print('type(feature_dataset_for_selection):',type(feature_dataset_for_selection))\n",
        "    # print('example row' + str(feature_dataset_for_selection[0]))\n",
        "    (relief_data_X,relief_data_y) = (feature_dataset_for_selection,dataset_labels.values.ravel())\n",
        "    print('Done.')\n",
        "else:\n",
        "    feature_dataset_for_selection_D = original_dataset_features\n",
        "    feature_dataset_for_selection = original_dataset_features.to_numpy()\n",
        "    (relief_data_X,relief_data_y) = (original_dataset_features.values,dataset_labels.values.ravel())\n",
        "\n",
        "\n",
        "selected_features = []\n",
        "if FEATURE_SELECTION == FeatureSelection.NONE:\n",
        "    selected_features = original_dataset_features.columns\n",
        "elif FEATURE_SELECTION == FeatureSelection.MANUAL_VARIABLES:\n",
        "    ''' Features '''\n",
        "    USE_ATTACKTIME_VALUE = True\n",
        "    USE_BARKSPECBRIGHTNESS = True\n",
        "    USE_PEAKSAMPLE_VALUE = True\n",
        "    USE_ZEROCROSSING = False\n",
        "\n",
        "    USE_BARKSPEC = 40 # Number in range [0-50]\n",
        "    USE_BFCC = 40     # Number in range [0-50]\n",
        "    USE_CEPSTRUM = 60 # Number in range [0-353]\n",
        "    USE_MFCC = 30     # Number in range [0-38]\n",
        "\n",
        "    if DATA_IS_WINDOWED:\n",
        "        window_indexes = sorted(list(set([int(e.split('_')[0]) for e in original_dataset_features.columns[original_dataset_features.columns.str.match('\\d+_')].to_list()])))\n",
        "        for index in window_indexes:\n",
        "            selected_features.extend(get_manual_selected_features(original_dataset_features,prefix=index+'_'))\n",
        "    else:\n",
        "        selected_features = get_manual_selected_features(original_dataset_features)\n",
        "elif FEATURE_SELECTION == FeatureSelection.MANUAL_LIST:\n",
        "    selected_features = ['attackTime_value', 'barkSpecBrightness', 'barkSpec_1', 'barkSpec_2', 'barkSpec_3', 'barkSpec_4', 'barkSpec_5', 'barkSpec_6', 'barkSpec_7', 'barkSpec_8', 'barkSpec_9', 'barkSpec_10', 'barkSpec_11', 'barkSpec_12', 'barkSpec_13', 'barkSpec_14', 'barkSpec_15', 'barkSpec_16', 'barkSpec_17', 'barkSpec_18', 'barkSpec_19', 'barkSpec_20', 'barkSpec_21', 'barkSpec_22', 'barkSpec_23', 'barkSpec_24', 'barkSpec_25', 'barkSpec_26', 'barkSpec_27', 'barkSpec_28', 'barkSpec_29', 'barkSpec_30', 'barkSpec_31', 'barkSpec_32', 'barkSpec_33', 'barkSpec_34', 'barkSpec_35', 'barkSpec_36', 'barkSpec_37', 'barkSpec_38', 'barkSpec_39', 'barkSpec_40', 'barkSpec_41', 'barkSpec_42', 'barkSpec_43', 'barkSpec_44', 'barkSpec_45', 'barkSpec_46', 'barkSpec_47', 'barkSpec_48', 'barkSpec_49', 'barkSpec_50', 'bfcc_2', 'bfcc_3', 'bfcc_4', 'bfcc_5', 'bfcc_6', 'bfcc_7', 'bfcc_8', 'bfcc_9', 'bfcc_10', 'bfcc_11', 'bfcc_12', 'bfcc_13', 'bfcc_15', 'bfcc_16', 'bfcc_17', 'bfcc_18', 'bfcc_19', 'bfcc_20', 'bfcc_21', 'bfcc_25', 'bfcc_26', 'bfcc_27', 'bfcc_28', 'bfcc_29', 'bfcc_30', 'bfcc_31', 'bfcc_35', 'bfcc_36', 'bfcc_37', 'bfcc_39', 'bfcc_40', 'bfcc_42', 'bfcc_43', 'bfcc_44', 'bfcc_45', 'bfcc_46', 'bfcc_48', 'cepstrum_1', 'cepstrum_2', 'cepstrum_3', 'cepstrum_4', 'cepstrum_5', 'cepstrum_6', 'cepstrum_7', 'cepstrum_8', 'cepstrum_9', 'cepstrum_10', 'cepstrum_11', 'cepstrum_12', 'cepstrum_13', 'cepstrum_14', 'cepstrum_15', 'cepstrum_16', 'cepstrum_17', 'cepstrum_18', 'cepstrum_19', 'cepstrum_20', 'cepstrum_21', 'cepstrum_22', 'cepstrum_23', 'cepstrum_24', 'cepstrum_25', 'cepstrum_26', 'cepstrum_27', 'cepstrum_28', 'cepstrum_29', 'cepstrum_30', 'cepstrum_31', 'cepstrum_32', 'cepstrum_33', 'cepstrum_34', 'cepstrum_35', 'cepstrum_36', 'cepstrum_37', 'cepstrum_41', 'cepstrum_42', 'cepstrum_43', 'cepstrum_44', 'cepstrum_45', 'cepstrum_46', 'cepstrum_47', 'cepstrum_48', 'cepstrum_49', 'cepstrum_54', 'cepstrum_56', 'cepstrum_59', 'cepstrum_60', 'cepstrum_67', 'cepstrum_72', 'cepstrum_86', 'cepstrum_87', 'cepstrum_108', 'cepstrum_164', 'cepstrum_205', 'cepstrum_206', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'mfcc_14', 'mfcc_15', 'mfcc_16', 'mfcc_17', 'mfcc_18', 'mfcc_19', 'mfcc_20', 'mfcc_21', 'mfcc_22', 'mfcc_23', 'mfcc_24', 'mfcc_25', 'mfcc_26', 'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36', 'peakSample_value', 'zeroCrossing']\n",
        "elif FEATURE_SELECTION == FeatureSelection.AUTO_ANOVA:\n",
        "    if original_dataset_features.shape[1] != original_feature_number:\n",
        "        raise ValueError(\"ERROR: please import dataset again since you are trying to subset an already processed feature set (\"+str(dataset_features.shape[1])+\"<\"+str(original_feature_number)+\")\")\n",
        "\n",
        "    # ANOVA feature selection for numeric input and categorical output (https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/#:~:text=Feature%20selection%20is%20the%20process,the%20performance%20of%20the%20model)\n",
        "    from sklearn.feature_selection import SelectKBest\n",
        "    from sklearn.feature_selection import f_classif\n",
        "    \n",
        "    if not DATA_IS_WINDOWED:\n",
        "        fs = SelectKBest(score_func=f_classif, k=AUTO_FEATURE_NUMBER) # Define feature selection\n",
        "        X_selected = fs.fit_transform(feature_dataset_for_selection, dataset_labels.to_numpy().ravel())                         # Apply feature selection\n",
        "        support = fs.get_support(indices=True)                      # Extract selected indexes\n",
        "        selected_features = original_dataset_features.columns[support].tolist()\n",
        "        print(str(AUTO_FEATURE_NUMBER)+\" best features:\" + str(selected_features))\n",
        "    else:\n",
        "        # For windowed data we select the best features for each window, rank the most used across all the windows and select the AUTO_FEATURE_NUMBER best ones\n",
        "        bestfeats_total_count = {}\n",
        "        window_indexes = sorted(list(set([int(e.split('_')[0]) for e in original_dataset_features.columns[original_dataset_features.columns.str.match('\\d+_')].to_list()])))\n",
        "        for wi in window_indexes:\n",
        "            fs = SelectKBest(score_func=f_classif, k=AUTO_FEATURE_NUMBER)\n",
        "            currentwindowdata = feature_dataset_for_selection_D[feature_dataset_for_selection_D.columns[feature_dataset_for_selection_D.columns.str.contains(wi+'_')]]\n",
        "            X_selected = fs.fit_transform(currentwindowdata.to_numpy(), dataset_labels.to_numpy().ravel())                         # Apply feature selection\n",
        "            current_window_best_features = currentwindowdata.columns[fs.get_support(indices=True) ].tolist()\n",
        "            # Increase occurences of best features but drop window index prefix\n",
        "            for f in current_window_best_features:\n",
        "                f = '_'.join(f.split('_')[1:])\n",
        "                if f in bestfeats_total_count:\n",
        "                    bestfeats_total_count[f] += 1\n",
        "                else:\n",
        "                    bestfeats_total_count[f] = 1\n",
        "        # sort best features by occurences\n",
        "        bestfeats_total_count = [k for k, v in sorted(bestfeats_total_count.items(), key=lambda item: item[1],reverse=True)]\n",
        "        #take first AUTO_FEATURE_NUMBER\n",
        "        bestfeats_total_count = bestfeats_total_count[:AUTO_FEATURE_NUMBER]\n",
        "        # add window index prefix and expand to all indexes\n",
        "        selected_features = []\n",
        "        for wi in window_indexes:\n",
        "            selected_features.extend([wi+'_'+f for f in bestfeats_total_count])\n",
        "elif FEATURE_SELECTION == FeatureSelection.AUTO_RELIEF:\n",
        "    support = relieff_selection(relief_data_X,relief_data_y,AUTO_FEATURE_NUMBER,n_neighbors=5,relief_cache_filepath=RELIEF_CACHE_FILEPATH,verbose_= True)\n",
        "    selected_features = original_dataset_features.columns[support].tolist()\n",
        "    print(str(AUTO_FEATURE_NUMBER)+\" best features:\" + str(selected_features))\n",
        "else:\n",
        "    raise Exception(\"ERROR! This type of feature selection is not supported\")\n",
        "\n",
        "dataset_features = original_dataset_features.copy().loc[:,selected_features]\n",
        "# if USE_AUGMENTED_DATA:\n",
        "#     features_aug = features_aug.copy().loc[:,selected_features]\n",
        "print(\"Features reduced \"+('manually' if (FEATURE_SELECTION == FeatureSelection.MANUAL_LIST or FEATURE_SELECTION == FeatureSelection.MANUAL_VARIABLES) else 'automatically')+\" (\"+str(FEATURE_SELECTION)+\") from \"+str(original_feature_number)+\" to : \"+str(dataset_features.shape[1]))\n",
        "print('%d features for each of the %d windows'%(AUTO_FEATURE_NUMBER,len(set([e.split('_')[0] for e in original_dataset_features.columns[original_dataset_features.columns.str.match('\\d_')].to_list()]))) if DATA_IS_WINDOWED else '')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxb5oNdswky3"
      },
      "source": [
        "## Evaluate class support\n",
        "(What percentage of dataset entries represent each class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qExZCK5ipvaa"
      },
      "source": [
        "F1-Score on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data_by_player = {}\n",
        "\n",
        "# players_meta_list = [re.findall('[A-Z][a-z][a-z][A-Z][a-z][a-z][0-2]?',el) for el in dataset_metadata['meta_audiofilePath']]\n",
        "# players_meta_list = [el[0] for el in players_meta_list]\n",
        "# players = np.unique(players_meta_list).tolist()\n",
        "\n",
        "# print(len(players),'players in the dataset')\n",
        "\n",
        "# for pix, p in enumerate(players):\n",
        "#     print(str(pix+1)+' - Player \"'+p+'\" \\thas '+str(players_meta_list.count(p))+' note entries')\n",
        "#     p_records = dataset_metadata[dataset_metadata['meta_audiofilePath'].str.contains('_'+p+'_')]\n",
        "#     a = dataset_features.iloc[p_records.index].copy()\n",
        "#     b = dataset_labels.iloc[p_records.index].copy()\n",
        "#     data_by_player[p] = (a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HOWMANYMAX = 8\n",
        "howmany = HOWMANYMAX if len(dataset_features) > HOWMANYMAX else len(dataset_features)\n",
        "data = dataset_features.iloc[range(howmany)].to_numpy()\n",
        "header = dataset_features.columns\n",
        "\n",
        "\n",
        "# Standardize data\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# scaler.fit(data)\n",
        "# data = scaler.transform(data)\n",
        "\n",
        "DO_SCALE_DATA = False\n",
        "\n",
        "if DO_SCALE_DATA:\n",
        "    # Normalize data\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(data)\n",
        "    data = scaler.transform(data)\n",
        "data_D = pd.DataFrame(data,columns=header)\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fs = sorted(list(set(['_'.join(h.split('_')[1:]) for h in header])))\n",
        "\n",
        "[f for f in fs if (not 'bark' in f) and (not 'bfcc' in f) and (not 'ceps' in f) and (not 'mfcc' in f)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %matplotlib qt\n",
        "%matplotlib inline \n",
        "\n",
        "SPACE_NOTES = 3\n",
        "\n",
        "\n",
        "def colorFader(c1,c2,mix=0): #fade (linear interpolate) from color c1 (at mix=0) to c2 (mix=1)\n",
        "    c1=np.array(mpl.colors.to_rgb(c1))\n",
        "    c2=np.array(mpl.colors.to_rgb(c2))\n",
        "    return mpl.colors.to_hex((1-mix)*c1 + mix*c2)\n",
        "\n",
        "c1='#99B6DB' #blue\n",
        "c2='#F42F37' #green\n",
        "zero_color = '#C9C9C9'\n",
        "# zero_color = '#ffffff'\n",
        "s = 16\n",
        "\n",
        "zero_threshold = -10e-100\n",
        "logscaled = True\n",
        "spacing = 1\n",
        "\n",
        "dataline = data[0]\n",
        "\n",
        "def plot_data(data, header, zero_threshold, min_color, max_color, zero_color,log_scale, ax, is_windowed, space_between_features = True):\n",
        "    def get_spaced_y(header,spaces = 8):\n",
        "        res_spaced = []\n",
        "        res_ticks_pos = []\n",
        "        res_ticks_names = []\n",
        "        counter = 0\n",
        "        last_prefix = header[0].split('_')[0]\n",
        "        startblock = 0\n",
        "        for idx,h in enumerate(header):\n",
        "            if h.split('_')[0] != last_prefix:\n",
        "                res_ticks_pos.append(((counter-startblock)/2 + startblock))\n",
        "                res_ticks_names.append(last_prefix)\n",
        "                startblock = counter+1+spaces\n",
        "                counter+=spaces\n",
        "            counter+=1\n",
        "            res_spaced.append(counter)\n",
        "            last_prefix = h.split('_')[0]\n",
        "        res_ticks_pos.append(((counter-startblock)/2 + startblock))\n",
        "        res_ticks_names.append(last_prefix)\n",
        "        return res_spaced, res_ticks_pos, res_ticks_names\n",
        "\n",
        "    def to_color (value, min, max, zero_threshold, min_color, max_color, zero_color,log_scale=False):\n",
        "        if value < zero_threshold:\n",
        "            return zero_color\n",
        "        \n",
        "        newvalue = (value - min) / (max - min)\n",
        "        newvalue = (newvalue - zero_threshold) / (1 - zero_threshold)\n",
        "\n",
        "        if log_scale:\n",
        "            # print('Going log scale')\n",
        "            newvalue = np.log(1+newvalue)/np.log(1+1)\n",
        "\n",
        "        return colorFader(min_color,max_color,mix=newvalue)\n",
        "\n",
        "    data = data.to_numpy()\n",
        "    dl_idx = 0\n",
        "    xticks_pos = []\n",
        "    xticks_names = []\n",
        "    for noteidx,dataline in enumerate(data):\n",
        "        # dataline = dataline/max(dataline)\n",
        "        if is_windowed:\n",
        "\n",
        "            uniqueheader = sorted(list(set(['_'.join(h.split('_')[1:]) for h in header])))\n",
        "            window_indexes = sorted(list(set([h.split('_')[0] for h in header])))\n",
        "            # print(window_indexes)\n",
        "            if space_between_features:\n",
        "                # print(header)\n",
        "                y_axis, y_ticks_pos, y_ticks_names = get_spaced_y(uniqueheader)\n",
        "                ax.set_yticks(y_ticks_pos)\n",
        "                ax.set_yticklabels(y_ticks_names)\n",
        "            else:\n",
        "                y_axis = list(range(len(dataline)))\n",
        "\n",
        "            put_tick_at = len(window_indexes)/2\n",
        "            tickput = False\n",
        "            for actidx, wi in enumerate(window_indexes): #TODO: fix this]\n",
        "                x_axis = [dl_idx*spacing]*len(uniqueheader)\n",
        "                if tickput == False and actidx >= put_tick_at:\n",
        "                    xticks_pos.append(dl_idx*spacing)\n",
        "                    xticks_names.append(noteidx)\n",
        "                    tickput = True\n",
        "                # print('dl_idx*spacing -> %d*%d = %d'%(dl_idx,spacing,dl_idx*spacing))\n",
        "                # print('plotting at X:%d'%x_axis[0])\n",
        "                current_indexes = [i for i, x in enumerate(header) if x.startswith(wi+'_')]\n",
        "                cur_dataline = [dataline[i] for i in current_indexes]\n",
        "                # print('cur_dataline (len: %d'%(len(cur_dataline)),cur_dataline)\n",
        "                # print('x_axis (len: %d'%(len(x_axis)),x_axis)\n",
        "                # print('y_axis (len: %d'%(len(y_axis)),y_axis)\n",
        "                # print('x_axis (len: %d)'%(len(x_axis)))\n",
        "                # print('y_axis (len: %d)'%(len(y_axis)))\n",
        "                # ax.scatter(x_axis,y_axis)\n",
        "                ax.scatter(x_axis,y_axis,c=[to_color(e,min(cur_dataline),max(cur_dataline),zero_threshold,c1,c2,zero_color,log_scale=log_scale) for e in cur_dataline],s=s,marker='s')\n",
        "                dl_idx+=1\n",
        "            if SPACE_NOTES:\n",
        "                dl_idx+=SPACE_NOTES\n",
        "        else:\n",
        "            x_axis = [dl_idx*spacing]*len(dataline)\n",
        "            if space_between_features:\n",
        "                y_axis, y_ticks_pos, y_ticks_names = get_spaced_y(header)\n",
        "                ax.set_yticks(y_ticks_pos)\n",
        "                ax.set_yticklabels(y_ticks_names)\n",
        "            else:\n",
        "                y_axis = list(range(len(dataline)))\n",
        "            ax.scatter(x_axis,y_axis,c=[to_color(e,min(dataline),max(dataline),zero_threshold,c1,c2,zero_color,log_scale=log_scale) for e in dataline],s=s,marker='s')\n",
        "        dl_idx+=1\n",
        "\n",
        "    ax.set_xticks(xticks_pos)\n",
        "    ax.set_xticklabels(xticks_names)\n",
        "    ax.set_xlabel('Musical note')\n",
        "    if FEATURE_SELECTION == FeatureSelection.NONE:\n",
        "        ax.set_ylabel('All extacted features')\n",
        "    else:\n",
        "        ax.set_ylabel('Best %d features'%AUTO_FEATURE_NUMBER)\n",
        "\n",
        "\n",
        "# fig = plt.figure(figsize=(7,25))\n",
        "fig = plt.figure(figsize=(32,25))\n",
        "ax = fig.add_subplot(111)\n",
        "# ax.set_facecolor(zero_color)\n",
        "plot_data(data_D, header, zero_threshold, c1, c2, zero_color, logscaled, ax, is_windowed=DATA_IS_WINDOWED)\n",
        "ax.set_title(DATASET_FILENAME + ' - ' + ('normalized' if DO_SCALE_DATA else 'not normalized' + ' - ' + 'logscale' if logscaled else 'linear scale'))\n",
        "# fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Learn scaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(dataset_features.to_numpy())\n",
        "None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print('(dataset_features.shape():',dataset_features.shape)\n",
        "# print('(dataset_labels.shape():',dataset_labels.shape)\n",
        "\n",
        "# print(dataset_labels==0)\n",
        "\n",
        "\n",
        "# print('(dataset_features.index:',dataset_features.index)\n",
        "# print('(dataset_labels.index:',dataset_labels.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "c1='#99B6DB' #blue\n",
        "c2='#F42F37' #green\n",
        "zero_color = '#C9C9C9'\n",
        "s = 16\n",
        "\n",
        "zero_threshold = 0.02\n",
        "logscaled = False\n",
        "spacing = 1\n",
        "\n",
        "# how many samples to plot\n",
        "samples_to_plot = 3\n",
        "\n",
        "\n",
        "# for technique in sorted(dataset_labels.unique()):\n",
        "#     # print(technique)\n",
        "#     features = dataset_features[dataset_labels==technique]\n",
        "#     # print(features.shape)\n",
        "\n",
        "#     data = features.iloc[range(samples_to_plot)].to_numpy()\n",
        "#     # data = features.sample(n=samples_to_plot).to_numpy()\n",
        "\n",
        "#     data = scaler.transform(data)\n",
        "\n",
        "\n",
        "#     fig = plt.figure(figsize=(24,8.9), tight_layout=True)\n",
        "#     ax = fig.add_subplot(111)\n",
        "#     ax.set_xlim(-5,320)\n",
        "#     fig.suptitle('First '+str(samples_to_plot)+' samples for technique '+str(technique)+' '+CLASSES_DESC[technique])\n",
        "#     plot_data(data, header, zero_threshold, c1, c2, zero_color, False, ax)\n",
        "\n",
        "#     fig.savefig('first_'+str(samples_to_plot)+'_samples_for_technique_'+str(technique)+'_'+CLASSES_DESC[technique]+'.png', dpi=300)\n",
        "\n",
        "#     # break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def to_color (value, min, max, zero_threshold, min_color, max_color, zero_color,log_scale=False):\n",
        "#     if value < zero_threshold:\n",
        "#         return zero_color\n",
        "    \n",
        "#     newvalue = (value - min) / (max - min)\n",
        "#     # print('value: ',value,' min: ',min,' max: ',max)\n",
        "#     # print('newvalue: ',newvalue)\n",
        "#     newvalue = (newvalue - zero_threshold) / (1 - zero_threshold)\n",
        "\n",
        "#     if log_scale:\n",
        "#         newvalue = np.log(1+newvalue)/np.log(1+1) \n",
        "\n",
        "#     # print('final newvalue',newvalue)\n",
        "\n",
        "#     return colorFader(min_color,max_color,mix=newvalue)\n",
        "\n",
        "\n",
        "# dd = list(range(120))\n",
        "\n",
        "# fig = plt.figure(figsize=(30,1))\n",
        "# ax = fig.add_subplot(111)\n",
        "# ax.set_ylim(-1,2)\n",
        "# zero_threshold = 0.0\n",
        "\n",
        "# for idx,dato in enumerate(dd):\n",
        "#     ax.scatter([dato],[0],\n",
        "#                c=to_color(dato,min(dd),max(dd),zero_threshold,c1,c2,zero_color,log_scale=False),\n",
        "#                s=200,\n",
        "#                marker='s')\n",
        "\n",
        "#     ax.scatter([dato],[1],\n",
        "#                c=to_color(dato,min(dd),max(dd),zero_threshold,c1,c2,zero_color,log_scale=True),\n",
        "#                s=200,\n",
        "#                marker='s')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # %matplotlib qt\n",
        "# %matplotlib inline \n",
        "\n",
        "\n",
        "# for player in data_by_player:\n",
        "#     X = data_by_player[player][0].to_numpy()\n",
        "\n",
        "#     fig = plt.figure(figsize=figsize,)\n",
        "#     ax1 = fig.add_subplot(131,projection='3d')\n",
        "#     ax2 = fig.add_subplot(132)\n",
        "#     ax3 = fig.add_subplot(133)\n",
        "\n",
        "    \n",
        "#         # fig.set_size_inches(30, 5)\n",
        "#     # fig.suptitle(player, fontsize=16)\n",
        "\n",
        "\n",
        "#     curtitle = \"PCA from \"+str(X.shape[1])+\" features of guitarist '\"+player+\"'\"\n",
        "#     plt.gcf().canvas.manager.set_window_title(curtitle)\n",
        "\n",
        "#     #set tight layout\n",
        "#     fig.tight_layout()\n",
        "\n",
        "\n",
        "#     # Compute PCA\n",
        "#     from sklearn.decomposition import PCA\n",
        "\n",
        "#     indexes = data_by_player[player][0].index\n",
        "#     translate_indexes = {indexes[i]:i for i in range(len(indexes))}\n",
        "\n",
        "\n",
        "#     # pca = PCA(n_components=3 if threed else 2)\n",
        "#     pca = PCA(n_components=6)\n",
        "#     X_pca = pca.fit_transform(X)\n",
        "    \n",
        "\n",
        "#     ax1.set_title(curtitle)\n",
        "\n",
        "#     # ax3.scatter(X_pca[:,0],X_pca[:,1],c=colors)\n",
        "\n",
        "#     features = data_by_player[player][0]\n",
        "#     labels = data_by_player[player][1]\n",
        "\n",
        "#     colors = [colorpalette[int(tech)] for tech in data_by_player[player][1].to_numpy()]\n",
        "#     techniques = np.unique(labels.to_numpy()).tolist()\n",
        "#     for technique_idx in techniques:\n",
        "#         indexes_for_tech = labels[labels == technique_idx].index\n",
        "#         translated_idxs = [translate_indexes[idx] for idx in indexes_for_tech]\n",
        "#         pca_for_tech = X_pca[translated_idxs]\n",
        "\n",
        "#         # print(pca_for_tech)\n",
        "#         colors = [colorpalette[technique_idx]]*len(pca_for_tech)\n",
        "#         #Set size of the points\n",
        "#         s = 100\n",
        "    \n",
        "        \n",
        "#         ax1.scatter(pca_for_tech[:,0],pca_for_tech[:,1],pca_for_tech[:,2],c=colors, alpha=alpha3d, s=s)\n",
        "#         ax1.set_xlabel('PC1')\n",
        "#         ax1.set_ylabel('PC2')\n",
        "#         ax1.set_zlabel('PC3')\n",
        "\n",
        "#         ax2.scatter(pca_for_tech[:,0],pca_for_tech[:,1],c=colors, alpha=alpha2d, s=s)\n",
        "#         ax2.set_xlabel('PC1')\n",
        "#         ax2.set_ylabel('PC2')\n",
        "\n",
        "#         #set tight layout\n",
        "#         fig.tight_layout()\n",
        "\n",
        "        \n",
        "#     ax1.legend([v for k,v in CLASSES_DESC.items()])\n",
        "\n",
        "\n",
        "#     PC_values = np.arange(pca.n_components_) + 1\n",
        "#     # ax.plot(PC_values, pca.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\n",
        "#     ax3.bar(PC_values, pca.explained_variance_ratio_, alpha=0.5, align='center', color='blue')\n",
        "#     ax3.set_title('Scree Plot')\n",
        "#     ax3.set_xlabel('Principal Component')\n",
        "#     ax3.set_ylabel('Variance Explained')\n",
        "#     plt.gcf().canvas.manager.set_window_title(' Scree Plot for '+curtitle)\n",
        "\n",
        "#     # plt.show()\n",
        "#     plt.savefig('PCA_'+player+'.png', dpi=300, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %matplotlib qt\n",
        "# # %matplotlib inline \n",
        "\n",
        "# side = 10\n",
        "# figsize = (side*3,side)\n",
        "# alpha3d = .7\n",
        "# alpha2d = .4\n",
        "\n",
        "\n",
        "# colorpalette = [\"#0c090d\",\"#ec5b81\",\"#f15946\",\"#f9c22e\",\"#53b3cb\",\"#5bc0eb\",\"#cfcfea\",\"#f7e1d7\"]\n",
        "# # colorpalette = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
        "# # colorpalette = ['#7fc97f', '#beaed4', '#fdc086', '#ffff99', '#386cb0', '#f0027f', '#bf5b17', '#666666']\n",
        "\n",
        "\n",
        "\n",
        "# fig = plt.figure(figsize=figsize,)\n",
        "# ax1 = fig.add_subplot(131,projection='3d')\n",
        "# ax2 = fig.add_subplot(132)\n",
        "# ax3 = fig.add_subplot(133)\n",
        "\n",
        "\n",
        "# curtitle = \"PCA from \"+str(X.shape[1])+\" features for all the \"+str(len(players))+\" guitarists\"\n",
        "# plt.gcf().canvas.manager.set_window_title(curtitle)\n",
        "\n",
        "# #set tight layout\n",
        "# fig.tight_layout()\n",
        "\n",
        "\n",
        "# # Compute PCA\n",
        "# from sklearn.decomposition import PCA\n",
        "\n",
        "# features = dataset_features\n",
        "# labels = dataset_labels\n",
        "\n",
        "\n",
        "# X = features.to_numpy()\n",
        "# # indexes = data_by_player[player][0].index\n",
        "# # translate_indexes = {indexes[i]:i for i in range(len(indexes))}\n",
        "\n",
        "\n",
        "# # pca = PCA(n_components=3 if threed else 2)\n",
        "# pca = PCA(n_components=6)\n",
        "# X_pca = pca.fit_transform(X)\n",
        "\n",
        "\n",
        "# ax1.set_title(curtitle)\n",
        "\n",
        "\n",
        "# for technique_idx in np.unique(labels.to_numpy()).tolist():\n",
        "#     indexes_for_tech = labels[labels == technique_idx].index\n",
        "#     # translated_idxs = [translate_indexes[idx] for idx in indexes_for_tech]\n",
        "#     translated_idxs = indexes_for_tech\n",
        "#     pca_for_tech = X_pca[translated_idxs]\n",
        "\n",
        "#     # print(pca_for_tech)\n",
        "#     colors = [colorpalette[technique_idx]]*len(pca_for_tech)\n",
        "#     #Set size of the points\n",
        "#     s = 100\n",
        "\n",
        "    \n",
        "#     ax1.scatter(pca_for_tech[:,0],pca_for_tech[:,1],pca_for_tech[:,2],c=colors, alpha=alpha3d, s=s)\n",
        "#     ax1.set_xlabel('PC1')\n",
        "#     ax1.set_ylabel('PC2')\n",
        "#     ax1.set_zlabel('PC3')\n",
        "\n",
        "#     ax2.scatter(pca_for_tech[:,0],pca_for_tech[:,1],c=colors, alpha=alpha2d, s=s)\n",
        "#     ax2.set_xlabel('PC1')\n",
        "#     ax2.set_ylabel('PC2')\n",
        "\n",
        "#     #set tight layout\n",
        "#     fig.tight_layout()\n",
        "\n",
        "    \n",
        "# ax1.legend([v for k,v in CLASSES_DESC.items()])\n",
        "\n",
        "\n",
        "# PC_values = np.arange(pca.n_components_) + 1\n",
        "# # ax.plot(PC_values, pca.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\n",
        "# ax3.bar(PC_values, pca.explained_variance_ratio_, alpha=0.5, align='center', color='blue')\n",
        "# ax3.set_title('Scree Plot')\n",
        "# ax3.set_xlabel('Principal Component')\n",
        "# ax3.set_ylabel('Variance Explained')\n",
        "# plt.gcf().canvas.manager.set_window_title(' Scree Plot for '+curtitle)\n",
        "\n",
        "# # plt.show()\n",
        "# plt.savefig('PCA_allplayers.png', dpi=300, bbox_inches='tight')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uLTufCRmlpIW",
        "4pBrSDphxyxL"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('tf-CLONE')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "959cb910f4c92fed33bcbb2d615fe10bd0473a33e22a9b4e00ebf3acf1e03643"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
